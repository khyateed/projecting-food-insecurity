{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projecting Food Insecurity Rates in the US by County\n",
    "## Data Collection and Preliminary Cleaning\n",
    "The following process imports and cleans 7 different datasets, each broken down into a yearly dataset, spanning years 2009-2020.\n",
    "### Flatiron School Data Science Capstone<br>By Khyatee Desai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import censusdata\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.precision', 2)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Food Insecurity Data\n",
    "This dataset contains data on food insecurity rates in the US by county, from 2009-2018.<br>**Source:** Feeding America [Map the Meal Gap Study](https://www.feedingamerica.org/research/map-the-meal-gap/how-we-got-the-map-data)\n",
    "### Import all the excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../datasets/feeding_america/\"\n",
    "\n",
    "df_FA_09 = pd.read_excel(directory+'FA_2011_2009.xlsx')\n",
    "df_FA_10 = pd.read_excel(directory+'FA_2012_2010.xlsx')\n",
    "df_FA_11 = pd.read_excel(directory+'FA_2013_2011.xlsx') # data only provided at the state level\n",
    "df_FA_12 = pd.read_excel(directory+'FA_2014_2012.xlsx') # data only provided at the state level\n",
    "df_FA_13 = pd.read_excel(directory+'FA_2015_2013.xlsx') ## data only provided at the state level\n",
    "df_FA_14 = pd.read_excel(directory+'FA_2016_2014.xlsx')\n",
    "df_FA_15 = pd.read_excel(directory+'FA_2017_2015.xlsx')\n",
    "df_FA_16 = pd.read_excel(directory+'FA_2018_2016.xlsx')\n",
    "df_FA_17 = pd.read_excel(directory+'FA_2019_2017.xlsx')\n",
    "df_FA_18 = pd.read_excel(directory+'FA_2020_2018.xlsx',header=1)\n",
    "\n",
    "# projected data for 2020 - ignoring this for project MVP\n",
    "# df_FAprojection_20 = pd.read_excel(directory+'projection_10.2020.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State</th>\n",
       "      <th>County, State</th>\n",
       "      <th>2010 Food Insecurity Rate</th>\n",
       "      <th>Number of Food Insecure Persons in 2010</th>\n",
       "      <th>Low Threshold in state</th>\n",
       "      <th>Low Threshold Type</th>\n",
       "      <th>High Threshold in state</th>\n",
       "      <th>High Threshold Type</th>\n",
       "      <th>% FI ≤ Low Threshold</th>\n",
       "      <th>% FI Btwn Thresholds</th>\n",
       "      <th>% FI &gt; High Threshold</th>\n",
       "      <th>2010 Child food insecurity rate</th>\n",
       "      <th>Number of Food Insecure Children in 2010</th>\n",
       "      <th>% food insecure children in HH w/ HH incomes below 185 FPL</th>\n",
       "      <th>% of food insecure children in HH w/ HH incomes above 185 FPL</th>\n",
       "      <th>2010 Cost Per Meal</th>\n",
       "      <th>2010 Weighted Annual Food Budget Shortfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>0.13</td>\n",
       "      <td>7140</td>\n",
       "      <td>1.3</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>1.85</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2980.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.58</td>\n",
       "      <td>3170830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin County, Alabama</td>\n",
       "      <td>0.13</td>\n",
       "      <td>23570</td>\n",
       "      <td>1.3</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>1.85</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.24</td>\n",
       "      <td>9720.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2.64</td>\n",
       "      <td>10710730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour County, Alabama</td>\n",
       "      <td>0.23</td>\n",
       "      <td>6440</td>\n",
       "      <td>1.3</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>1.85</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2804540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bibb County, Alabama</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3550</td>\n",
       "      <td>1.3</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>1.85</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1558200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>AL</td>\n",
       "      <td>Blount County, Alabama</td>\n",
       "      <td>0.13</td>\n",
       "      <td>7160</td>\n",
       "      <td>1.3</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>1.85</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3540.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3081120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>56037</td>\n",
       "      <td>WY</td>\n",
       "      <td>Sweetwater County, Wyoming</td>\n",
       "      <td>0.11</td>\n",
       "      <td>4720</td>\n",
       "      <td>1.3</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>1.85</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2063630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>56039</td>\n",
       "      <td>WY</td>\n",
       "      <td>Teton County, Wyoming</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2540</td>\n",
       "      <td>1.3</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>1.85</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.20</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1521490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>56041</td>\n",
       "      <td>WY</td>\n",
       "      <td>Uinta County, Wyoming</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2620</td>\n",
       "      <td>1.3</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>1.85</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1073330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>56043</td>\n",
       "      <td>WY</td>\n",
       "      <td>Washakie County, Wyoming</td>\n",
       "      <td>0.11</td>\n",
       "      <td>900</td>\n",
       "      <td>1.3</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>1.85</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.15</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2.44</td>\n",
       "      <td>378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>56045</td>\n",
       "      <td>WY</td>\n",
       "      <td>Weston County, Wyoming</td>\n",
       "      <td>0.12</td>\n",
       "      <td>820</td>\n",
       "      <td>1.3</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>1.85</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.17</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.39</td>\n",
       "      <td>337340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3143 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS State               County, State  2010 Food Insecurity Rate  Number of Food Insecure Persons in 2010  Low Threshold in state Low Threshold Type  High Threshold in state      High Threshold Type  % FI ≤ Low Threshold  % FI Btwn Thresholds  % FI > High Threshold  2010 Child food insecurity rate  Number of Food Insecure Children in 2010   % food insecure children in HH w/ HH incomes below 185 FPL  % of food insecure children in HH w/ HH incomes above 185 FPL  2010 Cost Per Meal  2010 Weighted Annual Food Budget Shortfall\n",
       "0      1001    AL     Autauga County, Alabama                       0.13                                     7140                     1.3               SNAP                     1.85  Other Nutrition Program                  0.33                  0.21                   0.47                             0.20                                     2980.0                                               0.51                                                        0.49                            2.58                                     3170830\n",
       "1      1003    AL     Baldwin County, Alabama                       0.13                                    23570                     1.3               SNAP                     1.85  Other Nutrition Program                  0.35                  0.29                   0.37                             0.24                                     9720.0                                               0.59                                                        0.41                            2.64                                    10710730\n",
       "2      1005    AL     Barbour County, Alabama                       0.23                                     6440                     1.3               SNAP                     1.85  Other Nutrition Program                  0.48                  0.17                   0.35                             0.26                                     1600.0                                               0.87                                                        0.13                            2.53                                     2804540\n",
       "3      1007    AL        Bibb County, Alabama                       0.16                                     3550                     1.3               SNAP                     1.85  Other Nutrition Program                  0.36                  0.29                   0.35                             0.25                                     1300.0                                               0.64                                                        0.36                            2.55                                     1558200\n",
       "4      1009    AL      Blount County, Alabama                       0.13                                     7160                     1.3               SNAP                     1.85  Other Nutrition Program                  0.41                  0.30                   0.28                             0.25                                     3540.0                                               0.53                                                        0.47                            2.50                                     3081120\n",
       "...     ...   ...                         ...                        ...                                      ...                     ...                ...                      ...                      ...                   ...                   ...                    ...                              ...                                        ...                                                ...                                                         ...                             ...                                         ...\n",
       "3138  56037    WY  Sweetwater County, Wyoming                       0.11                                     4720                     1.3               SNAP                     1.85  Other Nutrition Program                  0.27                  0.16                   0.56                             0.18                                     2040.0                                               0.40                                                        0.60                            2.54                                     2063630\n",
       "3139  56039    WY       Teton County, Wyoming                       0.12                                     2540                     1.3               SNAP                     1.85  Other Nutrition Program                  0.31                  0.21                   0.49                             0.20                                      840.0                                               0.55                                                        0.45                            3.48                                     1521490\n",
       "3140  56041    WY       Uinta County, Wyoming                       0.13                                     2620                     1.3               SNAP                     1.85  Other Nutrition Program                  0.37                  0.19                   0.44                             0.19                                     1160.0                                               0.48                                                        0.52                            2.38                                     1073330\n",
       "3141  56043    WY    Washakie County, Wyoming                       0.11                                      900                     1.3               SNAP                     1.85  Other Nutrition Program                  0.35                  0.29                   0.36                             0.15                                      300.0                                               0.59                                                        0.41                            2.44                                      378000\n",
       "3142  56045    WY      Weston County, Wyoming                       0.12                                      820                     1.3               SNAP                     1.85  Other Nutrition Program                  0.27                  0.19                   0.54                             0.17                                      240.0                                               0.48                                                        0.52                            2.39                                      337340\n",
       "\n",
       "[3143 rows x 18 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the 2010 data\n",
    "df_FA_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary features for each year\n",
    "These features are removed due to either being unnecessary for the model, or being highly correlated with the target variable, which would create data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_FA_09 = df_FA_09.drop(['State Name', 'County Code','Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "            '% FI Btwn Thresholds','% FI > High Threshold', '% of children in FI HH with HH incomes at or below 185% FPL',\n",
    "              'Number Food Insecure Children','% of children in FI HH with HH incomes above 185% FPL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_FA_10 = df_FA_10.drop(['County, State', 'State','Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "              '% FI Btwn Thresholds', 'Number of Food Insecure Children in 2010 ',\n",
    "              '% FI > High Threshold', '% food insecure children in HH w/ HH incomes below 185 FPL',\n",
    "               '% of food insecure children in HH w/ HH incomes above 185 FPL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_11 = df_FA_11.drop(['County, State', 'State','Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                          '% FI Btwn Thresholds', 'Number of Food Insecure Children in 2011',\n",
    "              '% FI > High Threshold', '% food insecure children in HH w/ HH incomes below 185 FPL',\n",
    "               '% of food insecure children in HH w/ HH incomes above 185 FPL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_12 = df_FA_12.drop(['State Name', 'State','Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds','% FI > High Threshold', '# of Food Insecure Children in 2012',\n",
    "               '% food insecure Children in HH w/HH Incomes Below 185 FPL in 2012',\n",
    "               '% food insecure Children in HH w/HH Incomes Above 185 FPL in 2012'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_13 = df_FA_13.drop(['State Name', 'State','Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds','% FI > High Threshold', '# of Food Insecure Children in 2013',\n",
    "               '% food insecure Children in HH w/HH Incomes Below 185 FPL in 2013',\n",
    "               '% food insecure Children in HH w/HH Incomes Above 185 FPL in 2013'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_14 = df_FA_14.drop(['County, State', 'State','Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds', '% FI > High Threshold', '# of Food Insecure Children in 2014',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2014',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2014'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_15 = df_FA_15.drop(['County, State', 'State','Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds','% FI > High Threshold', '# of Food Insecure Children in 2015',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2015',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2015'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_16 = df_FA_16.drop(['County, State', 'State','Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds','% FI > High Threshold', '# of Food Insecure Children in 2016',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2016',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2016'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_17 = df_FA_17.drop(['County, State', 'State','Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds', '% FI > High Threshold', '# of Food Insecure Children in 2017',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2017',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2017'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_FA_18 = df_FA_18.drop(['County, State', 'State','Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds', '% FI > High Threshold', '# of Food Insecure Children in 2018',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2018',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2018'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat FIPS Column\n",
    "FIPS, also referred to as GEOID, is a unique code assigned to each County/State combination. FIPS sometimes contains a leading 0, which was ommitted during csv to pandas conversion, so the following process is used to re-add the leading zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "# drop null rows at the end\n",
    "df_FA_09.drop(df_FA_09[df_FA_09['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "# change FIPS to string and add leading zeros if needed\n",
    "df_FA_09['FIPS'] = np.where(df_FA_09['FIPS']<10000, \n",
    "                        '0'+df_FA_09['FIPS'].astype(int).astype(str), df_FA_09['FIPS'].astype(int).astype(str))\n",
    "# 2010\n",
    "df_FA_10.drop(df_FA_10[df_FA_10['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_10['FIPS'] = np.where(df_FA_10['FIPS']<10000, \n",
    "                        '0'+df_FA_10['FIPS'].astype(int).astype(str), df_FA_10['FIPS'].astype(int).astype(str))\n",
    "# 2011\n",
    "df_FA_11.drop(df_FA_11[df_FA_11['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_11['FIPS'] = np.where(df_FA_11['FIPS']<10000, \n",
    "                        '0'+df_FA_11['FIPS'].astype(int).astype(str), df_FA_11['FIPS'].astype(int).astype(str))\n",
    "# 2012\n",
    "df_FA_12.drop(df_FA_12[df_FA_12['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_12['FIPS'] = np.where(df_FA_12['FIPS']<10000, \n",
    "                        '0'+df_FA_12['FIPS'].astype(int).astype(str), df_FA_12['FIPS'].astype(int).astype(str))\n",
    "# 2013\n",
    "df_FA_13.drop(df_FA_13[df_FA_13['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_13['FIPS'] = np.where(df_FA_13['FIPS']<10000, \n",
    "                        '0'+df_FA_13['FIPS'].astype(int).astype(str), df_FA_13['FIPS'].astype(int).astype(str))\n",
    "# 2014\n",
    "df_FA_14.drop(df_FA_14[df_FA_14['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_14['FIPS'] = np.where(df_FA_14['FIPS']<10000, \n",
    "                        '0'+df_FA_14['FIPS'].astype(int).astype(str), df_FA_14['FIPS'].astype(int).astype(str))\n",
    "# 2015\n",
    "df_FA_15.drop(df_FA_15[df_FA_15['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_15['FIPS'] = np.where(df_FA_15['FIPS']<10000, \n",
    "                        '0'+df_FA_15['FIPS'].astype(int).astype(str), df_FA_15['FIPS'].astype(int).astype(str))\n",
    "# 2016\n",
    "df_FA_16.drop(df_FA_16[df_FA_16['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_16['FIPS'] = np.where(df_FA_16['FIPS']<10000, \n",
    "                        '0'+df_FA_16['FIPS'].astype(int).astype(str), df_FA_16['FIPS'].astype(int).astype(str))\n",
    "# 2017\n",
    "df_FA_17.drop(df_FA_17[df_FA_17['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_17['FIPS'] = np.where(df_FA_17['FIPS']<10000, \n",
    "                        '0'+df_FA_17['FIPS'].astype(int).astype(str), df_FA_17['FIPS'].astype(int).astype(str))\n",
    "# 2018\n",
    "df_FA_18.drop(df_FA_18[df_FA_18['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_18['FIPS'] = np.where(df_FA_18['FIPS']<10000, \n",
    "                        '0'+df_FA_18['FIPS'].astype(int).astype(str), df_FA_18['FIPS'].astype(int).astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Year column for each df\n",
    "This will be relevant further on, when the datasets are vertically concatenated together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_09['Year'] = '2009'\n",
    "df_FA_10['Year'] = '2010'\n",
    "df_FA_11['Year'] = '2011'\n",
    "df_FA_12['Year'] = '2012'\n",
    "df_FA_13['Year'] = '2013'\n",
    "df_FA_14['Year'] = '2014'\n",
    "df_FA_15['Year'] = '2015'\n",
    "df_FA_16['Year'] = '2016'\n",
    "df_FA_17['Year'] = '2017'\n",
    "df_FA_18['Year'] = '2018'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for uniformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_10.rename(columns={'2010 Food Insecurity Rate':'FI Rate', 'Number of Food Insecure Persons in 2010':'Number Food Insecure Individuals',\n",
    "       '2010 Weighted Annual Food Budget Shortfall':'Weighted Annual Dollars', '2010 Cost Per Meal':'Cost Per Meal', \n",
    "                         '2010 Child food insecurity rate':'Child FI Rate'}, inplace=True)\n",
    "df_FA_11.rename(columns={'2011 Food Insecurity Rate':'FI Rate', 'Number of Food Insecure Persons in 2011':'Number Food Insecure Individuals',\n",
    "       '2011 Weighted Annual Food Budget Shortfall':'Weighted Annual Dollars', '2011 Cost Per Meal':'Cost Per Meal', \n",
    "                         '2011 Child Food Insecurity Rate':'Child FI Rate'}, inplace=True)\n",
    "df_FA_12.rename(columns={'2012 Food Insecurity Rate':'FI Rate', '# of Food Insecure Persons in 2012 ':'Number Food Insecure Individuals',\n",
    "       '2012 Weighted Annual Food Budget Shortfall':'Weighted Annual Dollars', '2012 Cost Per Meal':'Cost Per Meal', \n",
    "                         '2012 Child Food Insecurity Rate':'Child FI Rate'}, inplace=True)\n",
    "df_FA_13.rename(columns={'2013 Food Insecurity Rate':'FI Rate', '# of Food Insecure Persons in 2013 ':'Number Food Insecure Individuals',\n",
    "       '2013 Weighted Annual Food Budget Shortfall':'Weighted Annual Dollars', '2013 Cost Per Meal':'Cost Per Meal', \n",
    "                         '2013 Child Food Insecurity Rate':'Child FI Rate'}, inplace=True)\n",
    "df_FA_14.rename(columns={'2014 Food Insecurity Rate':'FI Rate', '# of Food Insecure Persons in 2014':'Number Food Insecure Individuals',\n",
    "       '2014 Weighted Annual Food Budget Shortfall':'Weighted Annual Dollars', '2014 Cost Per Meal':'Cost Per Meal', \n",
    "                         '2014 Child food insecurity rate':'Child FI Rate'}, inplace=True)\n",
    "df_FA_15.rename(columns={'2015 Food Insecurity Rate':'FI Rate', '# of Food Insecure Persons in 2015':'Number Food Insecure Individuals',\n",
    "       '2015 Weighted Annual Food Budget Shortfall':'Weighted Annual Dollars', '2015 Cost Per Meal':'Cost Per Meal', \n",
    "                         '2015 Child food insecurity rate':'Child FI Rate'}, inplace=True)\n",
    "df_FA_16.rename(columns={'2016 Food Insecurity Rate':'FI Rate', '# of Food Insecure Persons in 2016':'Number Food Insecure Individuals',\n",
    "       '2016 Weighted Annual Food Budget Shortfall':'Weighted Annual Dollars', '2016 Cost Per Meal':'Cost Per Meal', \n",
    "                         '2016 Child food insecurity rate':'Child FI Rate'}, inplace=True)\n",
    "df_FA_17.rename(columns={'2017 Food Insecurity Rate':'FI Rate', '# of Food Insecure Persons in 2017':'Number Food Insecure Individuals',\n",
    "       '2017 Weighted Annual Food Budget Shortfall':'Weighted Annual Dollars', '2017 Cost Per Meal':'Cost Per Meal', \n",
    "                         '2017 Child food insecurity rate':'Child FI Rate'}, inplace=True)\n",
    "df_FA_18.rename(columns={'2018 Food Insecurity Rate':'FI Rate', '# of Food Insecure Persons in 2018':'Number Food Insecure Individuals',\n",
    "       '2018 Weighted Annual Food Budget Shortfall':'Weighted Annual Dollars', '2018 Cost Per Meal':'Cost Per Meal', \n",
    "                         '2018 Child food insecurity rate':'Child FI Rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate all df's to create master dataframe for all years\n",
    "df_FA is the cleaned Food Insecurity data, from all years of the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>FI Rate</th>\n",
       "      <th>Low Threshold Type</th>\n",
       "      <th>High Threshold Type</th>\n",
       "      <th>Cost Per Meal</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02013</td>\n",
       "      <td>0.15</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>other nutrition pgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02016</td>\n",
       "      <td>0.14</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>other nutrition pgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02020</td>\n",
       "      <td>0.12</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>other nutrition pgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02050</td>\n",
       "      <td>0.21</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>other nutrition pgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02060</td>\n",
       "      <td>0.10</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>other nutrition pgm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>56037</td>\n",
       "      <td>0.12</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>3.29</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>56039</td>\n",
       "      <td>0.10</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>4.52</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>56041</td>\n",
       "      <td>0.14</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>3.07</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>56043</td>\n",
       "      <td>0.13</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>56045</td>\n",
       "      <td>0.14</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22143 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS  FI Rate Low Threshold Type      High Threshold Type  Cost Per Meal  Year\n",
       "0     02013     0.15               SNAP      other nutrition pgm            NaN  2009\n",
       "1     02016     0.14               SNAP      other nutrition pgm            NaN  2009\n",
       "2     02020     0.12               SNAP      other nutrition pgm            NaN  2009\n",
       "3     02050     0.21               SNAP      other nutrition pgm            NaN  2009\n",
       "4     02060     0.10               SNAP      other nutrition pgm            NaN  2009\n",
       "...     ...      ...                ...                      ...            ...   ...\n",
       "3137  56037     0.12               SNAP  Other Nutrition Program           3.29  2018\n",
       "3138  56039     0.10               SNAP  Other Nutrition Program           4.52  2018\n",
       "3139  56041     0.14               SNAP  Other Nutrition Program           3.07  2018\n",
       "3140  56043     0.13               SNAP  Other Nutrition Program           3.26  2018\n",
       "3141  56045     0.14               SNAP  Other Nutrition Program           3.16  2018\n",
       "\n",
       "[22143 rows x 6 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FA = pd.concat([df_FA_09, df_FA_10,df_FA_11,df_FA_12,df_FA_13,df_FA_14,df_FA_15,df_FA_16,df_FA_17,\n",
    "    df_FA_18 ]).drop(['Weighted Annual Dollars', 'Number Food Insecure Individuals','Child FI Rate'],axis=1)\n",
    "df_FA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Unemployment Data\n",
    "This dataset contains yearly data on the Labor Force of each US county, for the years 2009-2019. The files include data on total workforce, and unemployment rates.<br>\n",
    "**Source:** [Bureau of Labor Statistics](https://www.bls.gov/lau/#tables)\n",
    "### Import the datasets for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../datasets/unemployment/\"\n",
    "\n",
    "df_unemp_09 = pd.read_excel(directory + 'laucnty09.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_10 = pd.read_excel(directory + 'laucnty10.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_11 = pd.read_excel(directory + 'laucnty11.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_12 = pd.read_excel(directory + 'laucnty12.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_13 = pd.read_excel(directory + 'laucnty13.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_14 = pd.read_excel(directory + 'laucnty14.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_15 = pd.read_excel(directory + 'laucnty15.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_16 = pd.read_excel(directory + 'laucnty16.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_17 = pd.read_excel(directory + 'laucnty17.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_18 = pd.read_excel(directory + 'laucnty18.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_19 = pd.read_excel(directory + 'laucnty19.xlsx', header=4).drop(0,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Code.1</th>\n",
       "      <th>Code.2</th>\n",
       "      <th>County Name/State Abbreviation</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Force</th>\n",
       "      <th>Employed</th>\n",
       "      <th>Unemployed</th>\n",
       "      <th>(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN0100100000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Autauga County, AL</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25713.0</td>\n",
       "      <td>23431.0</td>\n",
       "      <td>2282.0</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN0100300000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Baldwin County, AL</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83459.0</td>\n",
       "      <td>75120.0</td>\n",
       "      <td>8339.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN0100500000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Barbour County, AL</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10221.0</td>\n",
       "      <td>8959.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>12.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Code  Code.1  Code.2 County Name/State Abbreviation    Year  Unnamed: 5    Force  Employed  Unemployed   (%)\n",
       "1  CN0100100000000     1.0     1.0             Autauga County, AL  2010.0         NaN  25713.0   23431.0      2282.0   8.9\n",
       "2  CN0100300000000     1.0     3.0             Baldwin County, AL  2010.0         NaN  83459.0   75120.0      8339.0  10.0\n",
       "3  CN0100500000000     1.0     5.0             Barbour County, AL  2010.0         NaN  10221.0    8959.0      1262.0  12.3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect one of the files\n",
    "df_unemp_10.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_09.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_10.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_11.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_12.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_13.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_14.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_15.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_16.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_17.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_18.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_19.rename(columns = {'LAUS Code':'CN', 'Code':'FIPS_state', 'Code.1':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', \n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop null rows, drop some columns, and reformat year column\n",
    "Drop null rows (created during excel conversion,) drop columns that wont be used during modeling, and reformat the year column as a string, to match the other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "# drop last three rows which were null\n",
    "df_unemp_09.drop(df_unemp_09[df_unemp_09['FIPS_state'].isnull()].index, inplace=True)\n",
    "# change year column to string\n",
    "df_unemp_09['Year'] = df_unemp_09['Year'].astype(int).astype(str)\n",
    "# drop unneeded columns\n",
    "df_unemp_09.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2010\n",
    "df_unemp_10.drop(df_unemp_10[df_unemp_10['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_10['Year'] = df_unemp_10['Year'].astype(int).astype(str)\n",
    "df_unemp_10.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2011\n",
    "df_unemp_11.drop(df_unemp_11[df_unemp_11['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_11['Year'] = df_unemp_11['Year'].astype(int).astype(str)\n",
    "df_unemp_11.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2012\n",
    "df_unemp_12.drop(df_unemp_12[df_unemp_12['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_12['Year'] = df_unemp_12['Year'].astype(int).astype(str)\n",
    "df_unemp_12.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2013\n",
    "df_unemp_13.drop(df_unemp_13[df_unemp_13['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_13['Year'] = df_unemp_13['Year'].astype(int).astype(str)\n",
    "df_unemp_13.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2014\n",
    "df_unemp_14.drop(df_unemp_14[df_unemp_14['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_14['Year'] = df_unemp_14['Year'].astype(int).astype(str)\n",
    "df_unemp_14.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2015\n",
    "df_unemp_15.drop(df_unemp_15[df_unemp_15['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_15['Year'] = df_unemp_15['Year'].astype(int).astype(str)\n",
    "df_unemp_15.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2016\n",
    "df_unemp_16.drop(df_unemp_16[df_unemp_16['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_16['Year'] = df_unemp_16['Year'].astype(int).astype(str)\n",
    "df_unemp_16.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2017\n",
    "df_unemp_17.drop(df_unemp_17[df_unemp_17['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_17['Year'] = df_unemp_17['Year'].astype(int).astype(str)\n",
    "df_unemp_17.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2018\n",
    "df_unemp_18.drop(df_unemp_18[df_unemp_18['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_18['Year'] = df_unemp_18['Year'].astype(int).astype(str)\n",
    "df_unemp_18.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2019\n",
    "# drop last three rows which were null\n",
    "df_unemp_19.drop(df_unemp_19[df_unemp_19['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_19.drop(['CN'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat FIPS\n",
    "Complete FIPS are a combination of a State FIPS + County FIPS code. The following process creates the complete code for each observation, by adding together the values from both columns. Similarly to above, a leading zero is also added in where needed, as it was dropped during the CSV to Pandas conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2009\n",
    "# add leading zeros to FIPS codes and convert to string\n",
    "df_unemp_09['FIPS_county'] = np.select([df_unemp_09['FIPS_county']<10, df_unemp_09['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_09['FIPS_county'].astype(int).astype(str), '0'+df_unemp_09['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_09['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_09['FIPS_state'] = np.where(df_unemp_09['FIPS_state']<10, \n",
    "                        '0'+df_unemp_09['FIPS_state'].astype(int).astype(str), df_unemp_09['FIPS_state'].astype(int).astype(str))\n",
    "# Create main fips code\n",
    "df_unemp_09['FIPS'] = df_unemp_09['FIPS_state'] + df_unemp_09['FIPS_county']\n",
    "\n",
    "# 2010\n",
    "df_unemp_10['FIPS_county'] = np.select([df_unemp_10['FIPS_county']<10, df_unemp_10['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_10['FIPS_county'].astype(int).astype(str), '0'+df_unemp_10['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_10['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_10['FIPS_state'] = np.where(df_unemp_10['FIPS_state']<10, \n",
    "                        '0'+df_unemp_10['FIPS_state'].astype(int).astype(str), df_unemp_10['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_10['FIPS'] = df_unemp_10['FIPS_state'] + df_unemp_10['FIPS_county']\n",
    "\n",
    "# 2011\n",
    "df_unemp_11['FIPS_county'] = np.select([df_unemp_11['FIPS_county']<10, df_unemp_11['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_11['FIPS_county'].astype(int).astype(str), '0'+df_unemp_11['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_11['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_11['FIPS_state'] = np.where(df_unemp_11['FIPS_state']<10, \n",
    "                        '0'+df_unemp_11['FIPS_state'].astype(int).astype(str), df_unemp_11['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_11['FIPS'] = df_unemp_11['FIPS_state'] + df_unemp_11['FIPS_county']\n",
    "\n",
    "# 2012\n",
    "df_unemp_12['FIPS_county'] = np.select([df_unemp_12['FIPS_county']<10, df_unemp_12['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_12['FIPS_county'].astype(int).astype(str), '0'+df_unemp_12['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_12['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_12['FIPS_state'] = np.where(df_unemp_12['FIPS_state']<10, \n",
    "                        '0'+df_unemp_12['FIPS_state'].astype(int).astype(str), df_unemp_12['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_12['FIPS'] = df_unemp_12['FIPS_state'] + df_unemp_12['FIPS_county']\n",
    "\n",
    "# 2013\n",
    "df_unemp_13['FIPS_county'] = np.select([df_unemp_13['FIPS_county']<10, df_unemp_13['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_13['FIPS_county'].astype(int).astype(str), '0'+df_unemp_13['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_13['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_13['FIPS_state'] = np.where(df_unemp_13['FIPS_state']<10, \n",
    "                        '0'+df_unemp_13['FIPS_state'].astype(int).astype(str), df_unemp_13['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_13['FIPS'] = df_unemp_13['FIPS_state'] + df_unemp_13['FIPS_county']\n",
    "\n",
    "# 2014\n",
    "df_unemp_14['FIPS_county'] = np.select([df_unemp_14['FIPS_county']<10, df_unemp_14['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_14['FIPS_county'].astype(int).astype(str), '0'+df_unemp_14['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_14['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_14['FIPS_state'] = np.where(df_unemp_14['FIPS_state']<10, \n",
    "                        '0'+df_unemp_14['FIPS_state'].astype(int).astype(str), df_unemp_14['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_14['FIPS'] = df_unemp_14['FIPS_state'] + df_unemp_14['FIPS_county']\n",
    "\n",
    "# 2015\n",
    "df_unemp_15['FIPS_county'] = np.select([df_unemp_15['FIPS_county']<10, df_unemp_15['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_15['FIPS_county'].astype(int).astype(str), '0'+df_unemp_15['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_15['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_15['FIPS_state'] = np.where(df_unemp_15['FIPS_state']<10, \n",
    "                        '0'+df_unemp_15['FIPS_state'].astype(int).astype(str), df_unemp_15['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_15['FIPS'] = df_unemp_15['FIPS_state'] + df_unemp_15['FIPS_county']\n",
    "\n",
    "# 2016\n",
    "df_unemp_16['FIPS_county'] = np.select([df_unemp_16['FIPS_county']<10, df_unemp_16['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_16['FIPS_county'].astype(int).astype(str), '0'+df_unemp_16['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_16['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_16['FIPS_state'] = np.where(df_unemp_16['FIPS_state']<10, \n",
    "                        '0'+df_unemp_16['FIPS_state'].astype(int).astype(str), df_unemp_16['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_16['FIPS'] = df_unemp_16['FIPS_state'] + df_unemp_16['FIPS_county']\n",
    "\n",
    "# 2017\n",
    "df_unemp_17['FIPS_county'] = np.select([df_unemp_17['FIPS_county']<10, df_unemp_17['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_17['FIPS_county'].astype(int).astype(str), '0'+df_unemp_17['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_17['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_17['FIPS_state'] = np.where(df_unemp_17['FIPS_state']<10, \n",
    "                        '0'+df_unemp_17['FIPS_state'].astype(int).astype(str), df_unemp_17['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_17['FIPS'] = df_unemp_17['FIPS_state'] + df_unemp_17['FIPS_county']\n",
    "\n",
    "# 2018\n",
    "df_unemp_18['FIPS_county'] = np.select([df_unemp_18['FIPS_county']<10, df_unemp_18['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_18['FIPS_county'].astype(int).astype(str), '0'+df_unemp_18['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_18['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_18['FIPS_state'] = np.where(df_unemp_18['FIPS_state']<10, \n",
    "                        '0'+df_unemp_18['FIPS_state'].astype(int).astype(str), df_unemp_18['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_18['FIPS'] = df_unemp_18['FIPS_state'] + df_unemp_18['FIPS_county']\n",
    "\n",
    "# 2019\n",
    "df_unemp_19['FIPS_county'] = np.select([df_unemp_19['FIPS_county']<10, df_unemp_19['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_19['FIPS_county'].astype(int).astype(str), '0'+df_unemp_19['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_19['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_19['FIPS_state'] = np.where(df_unemp_19['FIPS_state']<10, \n",
    "                        '0'+df_unemp_19['FIPS_state'].astype(int).astype(str), df_unemp_19['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_19['FIPS'] = df_unemp_19['FIPS_state'] + df_unemp_19['FIPS_county']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break down 2019 dataset into 2019 and 2020 dataframes\n",
    "The file for 2019 contains data on both 2019 and 2020, so this is broken down into separate dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add year column for each, derived from Period column, and then drop period column\n",
    "df_unemp_20 = df_unemp_19[df_unemp_19['Period'].str.contains('20')]\n",
    "df_unemp_20['Year'] = '2020'\n",
    "df_unemp_20.drop('Period', axis=1, inplace=True)\n",
    "\n",
    "df_unemp_19 = df_unemp_19[df_unemp_19['Period'].str.contains('19')]\n",
    "df_unemp_19['Year'] = '2019'\n",
    "df_unemp_19.drop('Period', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate all df's to create master dataframe of all years\n",
    "df_unemployment is the final cleaned dataframe on unemployment data from all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_state</th>\n",
       "      <th>FIPS_county</th>\n",
       "      <th>State/County</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total_workforce</th>\n",
       "      <th>Employed</th>\n",
       "      <th>Unemployed</th>\n",
       "      <th>Unemployment_rate</th>\n",
       "      <th>FIPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Autauga County, AL</td>\n",
       "      <td>2009</td>\n",
       "      <td>2.5e+04</td>\n",
       "      <td>2.2e+04</td>\n",
       "      <td>2.4e+03</td>\n",
       "      <td>9.7</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>003</td>\n",
       "      <td>Baldwin County, AL</td>\n",
       "      <td>2009</td>\n",
       "      <td>8.2e+04</td>\n",
       "      <td>7.4e+04</td>\n",
       "      <td>8e+03</td>\n",
       "      <td>9.8</td>\n",
       "      <td>01003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>005</td>\n",
       "      <td>Barbour County, AL</td>\n",
       "      <td>2009</td>\n",
       "      <td>1e+04</td>\n",
       "      <td>8.6e+03</td>\n",
       "      <td>1.4e+03</td>\n",
       "      <td>14</td>\n",
       "      <td>01005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>007</td>\n",
       "      <td>Bibb County, AL</td>\n",
       "      <td>2009</td>\n",
       "      <td>8.7e+03</td>\n",
       "      <td>7.6e+03</td>\n",
       "      <td>1.2e+03</td>\n",
       "      <td>13</td>\n",
       "      <td>01007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01</td>\n",
       "      <td>009</td>\n",
       "      <td>Blount County, AL</td>\n",
       "      <td>2009</td>\n",
       "      <td>2.6e+04</td>\n",
       "      <td>2.4e+04</td>\n",
       "      <td>2.6e+03</td>\n",
       "      <td>10</td>\n",
       "      <td>01009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45062</th>\n",
       "      <td>72</td>\n",
       "      <td>145</td>\n",
       "      <td>Vega Baja Municipio, PR</td>\n",
       "      <td>2020</td>\n",
       "      <td>12543</td>\n",
       "      <td>11146</td>\n",
       "      <td>1397</td>\n",
       "      <td>11</td>\n",
       "      <td>72145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45063</th>\n",
       "      <td>72</td>\n",
       "      <td>147</td>\n",
       "      <td>Vieques Municipio, PR</td>\n",
       "      <td>2020</td>\n",
       "      <td>2386</td>\n",
       "      <td>2133</td>\n",
       "      <td>253</td>\n",
       "      <td>11</td>\n",
       "      <td>72147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45064</th>\n",
       "      <td>72</td>\n",
       "      <td>149</td>\n",
       "      <td>Villalba Municipio, PR</td>\n",
       "      <td>2020</td>\n",
       "      <td>6603</td>\n",
       "      <td>5969</td>\n",
       "      <td>634</td>\n",
       "      <td>9.6</td>\n",
       "      <td>72149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45065</th>\n",
       "      <td>72</td>\n",
       "      <td>151</td>\n",
       "      <td>Yabucoa Municipio, PR</td>\n",
       "      <td>2020</td>\n",
       "      <td>7961</td>\n",
       "      <td>7168</td>\n",
       "      <td>793</td>\n",
       "      <td>10</td>\n",
       "      <td>72151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45066</th>\n",
       "      <td>72</td>\n",
       "      <td>153</td>\n",
       "      <td>Yauco Municipio, PR</td>\n",
       "      <td>2020</td>\n",
       "      <td>9250</td>\n",
       "      <td>8321</td>\n",
       "      <td>929</td>\n",
       "      <td>10</td>\n",
       "      <td>72153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77254 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS_state FIPS_county             State/County  Year Total_workforce Employed Unemployed Unemployment_rate   FIPS\n",
       "1             01         001       Autauga County, AL  2009         2.5e+04  2.2e+04    2.4e+03               9.7  01001\n",
       "2             01         003       Baldwin County, AL  2009         8.2e+04  7.4e+04      8e+03               9.8  01003\n",
       "3             01         005       Barbour County, AL  2009           1e+04  8.6e+03    1.4e+03                14  01005\n",
       "4             01         007          Bibb County, AL  2009         8.7e+03  7.6e+03    1.2e+03                13  01007\n",
       "5             01         009        Blount County, AL  2009         2.6e+04  2.4e+04    2.6e+03                10  01009\n",
       "...          ...         ...                      ...   ...             ...      ...        ...               ...    ...\n",
       "45062         72         145  Vega Baja Municipio, PR  2020           12543    11146       1397                11  72145\n",
       "45063         72         147    Vieques Municipio, PR  2020            2386     2133        253                11  72147\n",
       "45064         72         149   Villalba Municipio, PR  2020            6603     5969        634               9.6  72149\n",
       "45065         72         151    Yabucoa Municipio, PR  2020            7961     7168        793                10  72151\n",
       "45066         72         153      Yauco Municipio, PR  2020            9250     8321        929                10  72153\n",
       "\n",
       "[77254 rows x 9 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unemployment = pd.concat([df_unemp_09, df_unemp_10,df_unemp_11,df_unemp_12,df_unemp_13,df_unemp_14,df_unemp_15,df_unemp_16,\n",
    "          df_unemp_17,df_unemp_18,df_unemp_19,df_unemp_20])\n",
    "df_unemployment.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a. Current Population Survey Data\n",
    "The CPS survey is an annual survey run by the Census Bureau to gather information on household income, demographics, and other attributes. Currently, the data has only been collected for 2019 and 2020, ***therefore this data will not be used in the MVP modeling process.*<br>\n",
    "[Data Dictionary 2019](https://www2.census.gov/programs-surveys/cps/techdocs/cpsmar19.pdf)<br>\n",
    "[Data Dictionary 2020](https://www2.census.gov/programs-surveys/cps/datasets/2020/march/ASEC2020ddl_pub_full.pdf)<br>\n",
    "\n",
    "**Source:** United States Census Bureau [Current Population Survey](https://www.census.gov/data/datasets/time-series/demo/cps/cps-asec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets\n",
    "# df_household_19 = pd.read_csv('../datasets/household/hhpub19.csv')\n",
    "df_household_20 = pd.read_csv('../datasets/household/hhpub20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map column values to data dictionary\n",
    "A data dictionary is provided to map survey response codes to their meanings. The following cells map these codes using np.select:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np.select to map values on 2020 data\n",
    "conditions=[df_household_20['GTMETSTA'] ==1,df_household_20['GTMETSTA'] ==2, df_household_20['GTMETSTA'] ==3]\n",
    "choices = ['HH_Metrop', 'HH_Non-Metrop','N/A']\n",
    "df_household_20['GTMETSTA'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['H_TENURE'] ==0,df_household_20['H_TENURE'] ==1,df_household_20['H_TENURE'] ==2, df_household_20['H_TENURE'] ==3]\n",
    "choices = ['N/A', 'HH_owned', 'HH_rented','HH_rented_noCash']\n",
    "df_household_20['H_TENURE'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['HDIS_YN'] ==0,df_household_20['HDIS_YN'] ==1,df_household_20['HDIS_YN'] ==2]\n",
    "choices = ['N/A',  'HH_disabled','HH_not_disabled' ]\n",
    "df_household_20['HDIS_YN'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['HCSP_YN'] ==0,df_household_20['HCSP_YN'] ==1,df_household_20['HCSP_YN'] ==2]\n",
    "choices = ['N/A','HH_Child_support', 'HH_no_child_support' ]\n",
    "df_household_20['HCSP_YN'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['HINC_UC'] ==0,df_household_20['HINC_UC'] ==1,df_household_20['HINC_UC'] ==2]\n",
    "choices = ['N/A','HH_unemployment_pay', 'HH_no_unemployment_pay' ]\n",
    "df_household_20['HINC_UC'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['NOW_HCOV'] ==1,df_household_20['NOW_HCOV'] ==2,df_household_20['NOW_HCOV'] ==3]\n",
    "choices = [ 'HH_health_insured','HH_some_health_insured','HH_no_health_insured' ]\n",
    "df_household_20['NOW_HCOV'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['NOW_HPUB'] ==1,df_household_20['NOW_HPUB'] ==2,df_household_20['NOW_HPUB'] ==3]\n",
    "choices = [ 'HH_health_pub','HH_some_health_pub','HH_no_health_pub' ]\n",
    "df_household_20['NOW_HPUB'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['NOW_HPRIV'] ==1,df_household_20['NOW_HPRIV'] ==2,df_household_20['NOW_HPRIV'] ==3]\n",
    "choices = [ 'HH_health_priv','HH_some_health_priv','HH_no_health_priv' ]\n",
    "df_household_20['NOW_HPRIV'] = np.select(conditions, choices,default='N/A')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_state</th>\n",
       "      <th>FIPS_county</th>\n",
       "      <th>Metro_status</th>\n",
       "      <th>HH_income</th>\n",
       "      <th>HH_size</th>\n",
       "      <th>Num_minors</th>\n",
       "      <th>Rent_vs_Owned</th>\n",
       "      <th>Disability</th>\n",
       "      <th>Child_support</th>\n",
       "      <th>Unemployment_payments</th>\n",
       "      <th>Health_insurance</th>\n",
       "      <th>Public_insurance</th>\n",
       "      <th>Priv_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>127449</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "      <td>HH_some_health_pub</td>\n",
       "      <td>HH_health_priv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>64680</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "      <td>HH_some_health_pub</td>\n",
       "      <td>HH_health_priv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>40002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "      <td>HH_no_health_pub</td>\n",
       "      <td>HH_health_priv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>8424</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_rented</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "      <td>HH_health_pub</td>\n",
       "      <td>HH_no_health_priv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>59114</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "      <td>HH_no_health_pub</td>\n",
       "      <td>HH_health_priv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS_state  FIPS_county   Metro_status  HH_income  HH_size  Num_minors Rent_vs_Owned       Disability        Child_support   Unemployment_payments   Health_insurance    Public_insurance     Priv_insurance\n",
       "0          23            0  HH_Non-Metrop     127449        2           0      HH_owned  HH_not_disabled  HH_no_child_support  HH_no_unemployment_pay  HH_health_insured  HH_some_health_pub     HH_health_priv\n",
       "1          23            0  HH_Non-Metrop      64680        2           0      HH_owned  HH_not_disabled  HH_no_child_support  HH_no_unemployment_pay  HH_health_insured  HH_some_health_pub     HH_health_priv\n",
       "2          23            0  HH_Non-Metrop      40002        1           0      HH_owned  HH_not_disabled  HH_no_child_support  HH_no_unemployment_pay  HH_health_insured    HH_no_health_pub     HH_health_priv\n",
       "3          23            0  HH_Non-Metrop       8424        2           0     HH_rented  HH_not_disabled  HH_no_child_support  HH_no_unemployment_pay  HH_health_insured       HH_health_pub  HH_no_health_priv\n",
       "4          23            0  HH_Non-Metrop      59114        4           0      HH_owned  HH_not_disabled  HH_no_child_support  HH_no_unemployment_pay  HH_health_insured    HH_no_health_pub     HH_health_priv"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename 2020 data\n",
    "df_household_20 = df_household_20.loc[:,['GESTFIPS', 'GTCO', 'GTMETSTA', 'HTOTVAL','H_NUMPER', 'HUNDER18',\n",
    "                 'H_TENURE','HDIS_YN', 'HCSP_YN', 'HINC_UC','NOW_HCOV','NOW_HPUB','NOW_HPRIV']]\n",
    "df_household_20 = df_household_20.rename(columns={'GESTFIPS':'FIPS_state', 'GTCO':'FIPS_county', 'GTMETSTA':'Metro_status',\n",
    "                                'HTOTVAL':'HH_income',\n",
    "                                'H_NUMPER':'HH_size', 'HUNDER18':'Num_minors','H_TENURE':'Rent_vs_Owned',\n",
    "                               'HDIS_YN':'Disability', 'HCSP_YN':'Child_support', 'HINC_UC':'Unemployment_payments',\n",
    "                               'NOW_HCOV':'Health_insurance', 'NOW_HPUB': 'Public_insurance', 'NOW_HPRIV':'Priv_insurance'})\n",
    "df_household_20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create FIPS column from State FIPS and County FIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household_20['FIPS_county'] = np.select([df_household_20['FIPS_county']<10, df_household_20['FIPS_county']<100],\n",
    "        ['00'+df_household_20['FIPS_county'].astype(int).astype(str), '0'+df_household_20['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_household_20['FIPS_county'].astype(int).astype(str))\n",
    "df_household_20['FIPS_state'] = np.where(df_household_20['FIPS_state']<10, \n",
    "            '0'+df_household_20['FIPS_state'].astype(int).astype(str), df_household_20['FIPS_state'].astype(int).astype(str))\n",
    "df_household_20['FIPS'] = df_household_20['FIPS_state'] + df_household_20['FIPS_county']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unstack Columns\n",
    "Turn values into new columns for `Disability` and `Health_insurance` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get population for each FIPS\n",
    "pop_per_county = df_household_20['FIPS'].value_counts().reset_index().rename(columns={'FIPS':'Num_respondants_a','index':'FIPS'}).set_index('FIPS')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by County Code (FIPS) and count the values for Disability and Health Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstack values into new columns for Disability column, group by FIPS and count\n",
    "to_count = df_household_20.loc[:,['FIPS','Disability','Health_insurance','Public_insurance', 'Priv_insurance']]\n",
    "\n",
    "not_disabled = to_count[to_count['Disability']=='HH_not_disabled'].groupby('FIPS')[['Disability' ]].count().rename(columns={'Disability':'HH_not_disabled'})\n",
    "nan_disabled = to_count[to_count['Disability']=='N/A'].groupby('FIPS')[['Disability' ]].count().rename(columns={'Disability':'HH_nan_disabled'})\n",
    "disabled = to_count[to_count['Disability']=='HH_disabled'].groupby('FIPS')[['Disability' ]].count().rename(columns={'Disability':'HH_disabled'})\n",
    "\n",
    "df_disability = pd.concat([not_disabled,nan_disabled, disabled ],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstack values into new columns for Health Insurance column, group by FIPS and count\n",
    "insured = to_count[to_count['Health_insurance']=='HH_health_insured'].groupby('FIPS')[['Health_insurance' ]].count().rename(columns={'Health_insurance':'HH_health_insured'})\n",
    "nan_insured = to_count[to_count['Health_insurance']=='N/A'].groupby('FIPS')[['Health_insurance' ]].count().rename(columns={'Health_insurance':'HH_nan_insured'})\n",
    "some_insured =to_count[to_count['Health_insurance']=='HH_some_health_insured'].groupby('FIPS')[['Health_insurance' ]].count().rename(columns={'Health_insurance':'HH_some_insured'})\n",
    "not_insured =to_count[to_count['Health_insurance']=='HH_no_health_insured'].groupby('FIPS')[['Health_insurance' ]].count().rename(columns={'Health_insurance':'HH_not_insured'})\n",
    "\n",
    "df_insurance = pd.concat([insured,nan_insured, some_insured,not_insured ],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstack values into new columns for Public Health Insurance column, group by FIPS and count\n",
    "insured = to_count[to_count['Public_insurance']=='HH_no_health_pub'].groupby('FIPS')[['Public_insurance' ]].count().rename(columns={'Public_insurance':'HH_no_health_pub'})\n",
    "nan_insured = to_count[to_count['Public_insurance']=='N/A'].groupby('FIPS')[['Public_insurance' ]].count().rename(columns={'Public_insurance':'HH_nan_insured_pub'})\n",
    "some_insured =to_count[to_count['Public_insurance']=='HH_health_pub'].groupby('FIPS')[['Public_insurance' ]].count().rename(columns={'Public_insurance':'HH_insured_pub'})\n",
    "not_insured =to_count[to_count['Public_insurance']=='HH_some_health_pub'].groupby('FIPS')[['Public_insurance' ]].count().rename(columns={'Public_insurance':'HH_some_insured_pub'})\n",
    "\n",
    "df_insurance_pub = pd.concat([insured,nan_insured, some_insured,not_insured ],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstack values into new columns for Private Health Insurance column, group by FIPS and count\n",
    "insured = to_count[to_count['Priv_insurance']=='HH_health_priv'].groupby('FIPS')[['Priv_insurance' ]].count().rename(columns={'Priv_insurance':'HH_health_priv'})\n",
    "nan_insured = to_count[to_count['Priv_insurance']=='N/A'].groupby('FIPS')[['Priv_insurance' ]].count().rename(columns={'Priv_insurance':'HH_nan_insured_priv'})\n",
    "some_insured =to_count[to_count['Priv_insurance']=='HH_no_health_priv'].groupby('FIPS')[['Priv_insurance' ]].count().rename(columns={'Priv_insurance':'HH_not_insured_priv'})\n",
    "not_insured =to_count[to_count['Priv_insurance']=='HH_some_health_priv'].groupby('FIPS')[['Priv_insurance' ]].count().rename(columns={'Priv_insurance':'HH_some_insured_priv'})\n",
    "\n",
    "df_insurance_priv = pd.concat([insured,nan_insured, some_insured,not_insured ],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by County Code (FIPS) and average the values for HH income and HH size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate columns that need to be grouped by FIPS and averaged\n",
    "to_avg = df_household_20.loc[:,['FIPS','HH_income','HH_size']]\n",
    "df_income_size = to_avg.groupby('FIPS')[['HH_income','HH_size']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat new columns together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HH_health_insured</th>\n",
       "      <th>HH_nan_insured</th>\n",
       "      <th>HH_some_insured</th>\n",
       "      <th>HH_not_insured</th>\n",
       "      <th>HH_no_health_pub</th>\n",
       "      <th>HH_nan_insured_pub</th>\n",
       "      <th>HH_insured_pub</th>\n",
       "      <th>HH_some_insured_pub</th>\n",
       "      <th>HH_health_priv</th>\n",
       "      <th>HH_nan_insured_priv</th>\n",
       "      <th>HH_not_insured_priv</th>\n",
       "      <th>HH_some_insured_priv</th>\n",
       "      <th>HH_not_disabled</th>\n",
       "      <th>HH_nan_disabled</th>\n",
       "      <th>HH_disabled</th>\n",
       "      <th>HH_income</th>\n",
       "      <th>HH_size</th>\n",
       "      <th>Num_respondants_a</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01000</th>\n",
       "      <td>889</td>\n",
       "      <td>490</td>\n",
       "      <td>110.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>504</td>\n",
       "      <td>490</td>\n",
       "      <td>315.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>582</td>\n",
       "      <td>490</td>\n",
       "      <td>273.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1002</td>\n",
       "      <td>490</td>\n",
       "      <td>29.0</td>\n",
       "      <td>53980.42</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1521</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01003</th>\n",
       "      <td>86</td>\n",
       "      <td>58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>58</td>\n",
       "      <td>42.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>51</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52303.19</td>\n",
       "      <td>1.35</td>\n",
       "      <td>149</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01081</th>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>57</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53911.45</td>\n",
       "      <td>1.61</td>\n",
       "      <td>94</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01097</th>\n",
       "      <td>97</td>\n",
       "      <td>44</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>71</td>\n",
       "      <td>44</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>76</td>\n",
       "      <td>44</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>113</td>\n",
       "      <td>44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50787.05</td>\n",
       "      <td>1.72</td>\n",
       "      <td>159</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02000</th>\n",
       "      <td>570</td>\n",
       "      <td>374</td>\n",
       "      <td>95.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>403</td>\n",
       "      <td>374</td>\n",
       "      <td>187.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>399</td>\n",
       "      <td>374</td>\n",
       "      <td>213.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>694</td>\n",
       "      <td>374</td>\n",
       "      <td>20.0</td>\n",
       "      <td>67311.89</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1088</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HH_health_insured  HH_nan_insured  HH_some_insured  HH_not_insured  HH_no_health_pub  HH_nan_insured_pub  HH_insured_pub  HH_some_insured_pub  HH_health_priv  HH_nan_insured_priv  HH_not_insured_priv  HH_some_insured_priv  HH_not_disabled  HH_nan_disabled  HH_disabled  HH_income  HH_size  Num_respondants_a  Year\n",
       "01000                889             490            110.0            32.0               504                 490           315.0                212.0             582                  490                273.0                 176.0             1002              490         29.0   53980.42     1.70               1521  2020\n",
       "01003                 86              58              3.0             2.0                36                  58            42.0                 13.0              51                   58                 29.0                  11.0               88               58          3.0   52303.19     1.35                149  2020\n",
       "01081                 49              36              7.0             2.0                29                  36            16.0                 13.0              31                   36                 15.0                  12.0               57               36          1.0   53911.45     1.61                 94  2020\n",
       "01097                 97              44             11.0             7.0                71                  44            22.0                 22.0              76                   44                 24.0                  15.0              113               44          2.0   50787.05     1.72                159  2020\n",
       "02000                570             374             95.0            49.0               403                 374           187.0                124.0             399                  374                213.0                 102.0              694              374         20.0   67311.89     1.92               1088  2020"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat together the unstacked columns with value counts for each County\n",
    "df_cps_20a = pd.concat([df_insurance, df_insurance_pub, df_insurance_priv, df_disability, df_income_size,pop_per_county], axis=1).fillna(0)\n",
    "\n",
    "# # Rename FIPS column\n",
    "# df_cps_20a.rename(columns={'index':'FIPS'},inplace=True)\n",
    "\n",
    "# Add Year column\n",
    "df_cps_20a['Year'] = '2020'\n",
    "df_cps_20a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3b. Basic CPS Data\n",
    "The Basic CPS survey is a monthly survey of income, labor force participation, and demographic information, conducted by the U.S. Government and the US Census Bureau.\n",
    "[Data Dictionary](https://www2.census.gov/programs-surveys/cps/datasets/2020/basic/2020_Basic_CPS_Public_Use_Record_Layout_plus_IO_Code_list.txt)<br>\n",
    "\n",
    "**Source:** National Bureau of Economic Research [Current Population Survey - Basic Monthly](http://www2.nber.org/data/cps-basic2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cps_09 = pd.read_csv('../datasets/cps/cpsb200910.csv')\n",
    "# df_cps_11 = pd.read_csv('..datasets/cps/cpsb201110.csv')\n",
    "# df_cps_12 = pd.read_csv('..datasets/cps/cpsb201210.csv')\n",
    "# df_cps_13 = pd.read_csv('..datasets/cps/cpsb201310.csv')\n",
    "# df_cps_14 = pd.read_csv('..datasets/cps/cpsb201410.csv')\n",
    "# df_cps_15 = pd.read_csv('..datasets/cps/cpsb201510.csv')\n",
    "# df_cps_16 = pd.read_csv('..datasets/cps/cpsb201610.csv')\n",
    "# df_cps_17 = pd.read_csv('..datasets/cps/cpsb201710.csv')\n",
    "# df_cps_18 = pd.read_csv('..datasets/cps/cpsb201810.csv')\n",
    "# df_cps_19 = pd.read_csv('..datasets/cps/cpsb201910.csv')\n",
    "df_cps_20b = pd.read_csv('../datasets/cps/cpsb202010.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate required columns and rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cps_20b = df_cps_20b.loc[:,['gestfips','gtco','hryear4','hefaminc','penlfact','pudis','prcitshp','peeduca']].rename(columns={'gestfips':'FIPS_state',\n",
    "                             'hryear4':'Year', 'gtco':'FIPS_county','hefaminc':'HH_income',\n",
    "                        'penlfact':'Disability','pudis':'Disabled','prcitshp':'Citizenship','peeduca':'Education', })\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive FIPS Code for each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cps_20b['FIPS_county'] = np.select([df_cps_20b['FIPS_county']<10, df_cps_20b['FIPS_county']<100],\n",
    "        ['00'+df_cps_20b['FIPS_county'].astype(int).astype(str), '0'+df_cps_20b['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_cps_20b['FIPS_county'].astype(int).astype(str))\n",
    "df_cps_20b['FIPS_state'] = np.where(df_cps_20b['FIPS_state']<10, \n",
    "            '0'+df_cps_20b['FIPS_state'].astype(int).astype(str), df_cps_20b['FIPS_state'].astype(int).astype(str))\n",
    "df_cps_20b['FIPS'] = df_cps_20b['FIPS_state'] + df_cps_20b['FIPS_county']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get population for each FIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_per_county = df_cps_20b['FIPS'].value_counts().reset_index().rename(columns={'FIPS':'Num_respondants_b','index':'FIPS'}).set_index('FIPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unstack Columns\n",
    "Turn values into columns for `Citizenship` and `Education`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Citizenship status\n",
    "conditions=[ df_cps_20b['Citizenship']==5]\n",
    "\n",
    "choices = [ 'pop_non_citizen' ]\n",
    "\n",
    "df_cps_20b['Citizenship'] = np.select(conditions, choices,default= 'Pop_citizen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Education Level\n",
    "\n",
    "conditions=[df_cps_20b['Education'] ==39,df_cps_20b['Education'] ==40,df_cps_20b['Education'] ==41,\n",
    "            df_cps_20b['Education']==42, df_cps_20b['Education']==43, df_cps_20b['Education']==44,\n",
    "            df_cps_20b['Education']==45, df_cps_20b['Education']==46]\n",
    "\n",
    "choices = [ 'pop_hs_grad','pop_hs_grad', 'pop_hs_grad', 'pop_hs_grad','pop_bachelors','pop_grad_degree',\n",
    "           'pop_grad_degree', 'pop_grad_degree' ]\n",
    "\n",
    "df_cps_20b['Education'] = np.select(conditions, choices,default='Nan_degree')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group By County Code, and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_count = df_cps_20b.loc[:,['FIPS','Citizenship','Education']]\n",
    "\n",
    "not_citizen = to_count[to_count['Citizenship']=='pop_non_citizen'].groupby('FIPS')[['Citizenship' ]].count().rename(columns={'Citizenship':'pop_non_citizen'})\n",
    "citizen = to_count[to_count['Citizenship']=='Pop_citizen'].groupby('FIPS')[['Citizenship' ]].count().rename(columns={'Citizenship':'Pop_citizen'})\n",
    "nan_degree = to_count[to_count['Education']=='Nan_degree'].groupby('FIPS')[['Education' ]].count().rename(columns={'Education':'Nan_degree'})\n",
    "hs_grad = to_count[to_count['Education']=='pop_hs_grad'].groupby('FIPS')[['Education' ]].count().rename(columns={'Education':'pop_hs_grad'})\n",
    "bachelors_grad = to_count[to_count['Education']=='pop_bachelors'].groupby('FIPS')[['Education' ]].count().rename(columns={'Education':'pop_bachelors'})\n",
    "grad_degree = to_count[to_count['Education']=='pop_grad_degree'].groupby('FIPS')[['Education' ]].count().rename(columns={'Education':'pop_grad_degree'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat new columns together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat together the unstacked columns with value counts for each County\n",
    "df_cps_20b = pd.concat([pop_per_county,not_citizen, citizen, nan_degree,hs_grad,bachelors_grad,grad_degree], axis=1).fillna(0)\n",
    "\n",
    "# Rename FIPS column\n",
    "# df_cps_20b.rename(columns={'index':'FIPS'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat CPSa and CPSb Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HH_health_insured</th>\n",
       "      <th>HH_nan_insured</th>\n",
       "      <th>HH_some_insured</th>\n",
       "      <th>HH_not_insured</th>\n",
       "      <th>HH_no_health_pub</th>\n",
       "      <th>HH_nan_insured_pub</th>\n",
       "      <th>HH_insured_pub</th>\n",
       "      <th>HH_some_insured_pub</th>\n",
       "      <th>HH_health_priv</th>\n",
       "      <th>HH_nan_insured_priv</th>\n",
       "      <th>HH_not_insured_priv</th>\n",
       "      <th>HH_some_insured_priv</th>\n",
       "      <th>HH_not_disabled</th>\n",
       "      <th>HH_nan_disabled</th>\n",
       "      <th>HH_disabled</th>\n",
       "      <th>HH_income</th>\n",
       "      <th>HH_size</th>\n",
       "      <th>Num_respondants_a</th>\n",
       "      <th>Year</th>\n",
       "      <th>Num_respondants_b</th>\n",
       "      <th>pop_non_citizen</th>\n",
       "      <th>Pop_citizen</th>\n",
       "      <th>Nan_degree</th>\n",
       "      <th>pop_hs_grad</th>\n",
       "      <th>pop_bachelors</th>\n",
       "      <th>pop_grad_degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01000</th>\n",
       "      <td>889</td>\n",
       "      <td>490</td>\n",
       "      <td>110.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>504</td>\n",
       "      <td>490</td>\n",
       "      <td>315.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>582</td>\n",
       "      <td>490</td>\n",
       "      <td>273.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1002</td>\n",
       "      <td>490</td>\n",
       "      <td>29.0</td>\n",
       "      <td>53980.42</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1521</td>\n",
       "      <td>2020</td>\n",
       "      <td>2185</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2158</td>\n",
       "      <td>903</td>\n",
       "      <td>870</td>\n",
       "      <td>261.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01003</th>\n",
       "      <td>86</td>\n",
       "      <td>58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>58</td>\n",
       "      <td>42.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>51</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52303.19</td>\n",
       "      <td>1.35</td>\n",
       "      <td>149</td>\n",
       "      <td>2020</td>\n",
       "      <td>212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212</td>\n",
       "      <td>69</td>\n",
       "      <td>82</td>\n",
       "      <td>43.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01081</th>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>57</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53911.45</td>\n",
       "      <td>1.61</td>\n",
       "      <td>94</td>\n",
       "      <td>2020</td>\n",
       "      <td>155</td>\n",
       "      <td>7.0</td>\n",
       "      <td>148</td>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01097</th>\n",
       "      <td>97</td>\n",
       "      <td>44</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>71</td>\n",
       "      <td>44</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>76</td>\n",
       "      <td>44</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>113</td>\n",
       "      <td>44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50787.05</td>\n",
       "      <td>1.72</td>\n",
       "      <td>159</td>\n",
       "      <td>2020</td>\n",
       "      <td>248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>31.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02000</th>\n",
       "      <td>570</td>\n",
       "      <td>374</td>\n",
       "      <td>95.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>403</td>\n",
       "      <td>374</td>\n",
       "      <td>187.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>399</td>\n",
       "      <td>374</td>\n",
       "      <td>213.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>694</td>\n",
       "      <td>374</td>\n",
       "      <td>20.0</td>\n",
       "      <td>67311.89</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1088</td>\n",
       "      <td>2020</td>\n",
       "      <td>1655</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1624</td>\n",
       "      <td>719</td>\n",
       "      <td>623</td>\n",
       "      <td>187.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HH_health_insured  HH_nan_insured  HH_some_insured  HH_not_insured  HH_no_health_pub  HH_nan_insured_pub  HH_insured_pub  HH_some_insured_pub  HH_health_priv  HH_nan_insured_priv  HH_not_insured_priv  HH_some_insured_priv  HH_not_disabled  HH_nan_disabled  HH_disabled  HH_income  HH_size  Num_respondants_a  Year  Num_respondants_b  pop_non_citizen  Pop_citizen  Nan_degree  pop_hs_grad  pop_bachelors  pop_grad_degree\n",
       "01000                889             490            110.0            32.0               504                 490           315.0                212.0             582                  490                273.0                 176.0             1002              490         29.0   53980.42     1.70               1521  2020               2185             27.0         2158         903          870          261.0            151.0\n",
       "01003                 86              58              3.0             2.0                36                  58            42.0                 13.0              51                   58                 29.0                  11.0               88               58          3.0   52303.19     1.35                149  2020                212              0.0          212          69           82           43.0             18.0\n",
       "01081                 49              36              7.0             2.0                29                  36            16.0                 13.0              31                   36                 15.0                  12.0               57               36          1.0   53911.45     1.61                 94  2020                155              7.0          148          62           57           24.0             12.0\n",
       "01097                 97              44             11.0             7.0                71                  44            22.0                 22.0              76                   44                 24.0                  15.0              113               44          2.0   50787.05     1.72                159  2020                248              0.0          248          96           97           31.0             24.0\n",
       "02000                570             374             95.0            49.0               403                 374           187.0                124.0             399                  374                213.0                 102.0              694              374         20.0   67311.89     1.92               1088  2020               1655             31.0         1624         719          623          187.0            126.0"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cps_20 = pd.concat([df_cps_20a, df_cps_20b], axis=1)\n",
    "df_cps_20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe with pickle for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../pickled/cps_20_data.pickle', \"wb\") as output_file:\n",
    "    pickle.dump(df_cps_20, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. American Community Survey Data\n",
    "The American Community Survey is a demographics survey program conducted by the U.S. Census Bureau. ACS 1-year estimate data is available through a Python API wrapper, called [censusdata](https://pypi.org/project/CensusData/).<br>\n",
    "**Source:** United States Census Bureau [ACS Survey](https://www.census.gov/programs-surveys/acs/data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DP02PR_0070E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population'),\n",
       " ('DP02PR_0070M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population'),\n",
       " ('DP02PR_0070PE',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population'),\n",
       " ('DP02PR_0070PM',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population'),\n",
       " ('DP02PR_0071E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population!!With a disability'),\n",
       " ('DP02PR_0071M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population!!With a disability'),\n",
       " ('DP02PR_0071PE',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population!!With a disability'),\n",
       " ('DP02PR_0071PM',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population!!With a disability'),\n",
       " ('DP02PR_0072E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years'),\n",
       " ('DP02PR_0072M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years'),\n",
       " ('DP02PR_0072PE',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years'),\n",
       " ('DP02PR_0072PM',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years'),\n",
       " ('DP02PR_0073E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years!!With a disability'),\n",
       " ('DP02PR_0073M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years!!With a disability'),\n",
       " ('DP02PR_0073PE',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years!!With a disability'),\n",
       " ('DP02PR_0073PM',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years!!With a disability'),\n",
       " ('DP02PR_0074E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!18 to 64 years'),\n",
       " ('DP02PR_0074M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!18 to 64 years'),\n",
       " ('DP02PR_0074PE',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!18 to 64 years'),\n",
       " ('DP02PR_0074PM',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!18 to 64 years'),\n",
       " ('DP02PR_0075E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!18 to 64 years!!With a disability'),\n",
       " ('DP02PR_0075M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!18 to 64 years!!With a disability'),\n",
       " ('DP02PR_0075PE',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!18 to 64 years!!With a disability'),\n",
       " ('DP02PR_0075PM',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!18 to 64 years!!With a disability'),\n",
       " ('DP02PR_0076E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!65 years and over'),\n",
       " ('DP02PR_0076M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!65 years and over'),\n",
       " ('DP02PR_0076PE',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!65 years and over'),\n",
       " ('DP02PR_0076PM',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!65 years and over'),\n",
       " ('DP02PR_0077E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!65 years and over!!With a disability'),\n",
       " ('DP02PR_0077M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!65 years and over!!With a disability'),\n",
       " ('DP02PR_0077PE',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!65 years and over!!With a disability'),\n",
       " ('DP02PR_0077PM',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN PUERTO RICO',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!65 years and over!!With a disability'),\n",
       " ('DP02_0070E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population'),\n",
       " ('DP02_0070M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population'),\n",
       " ('DP02_0070PE',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population'),\n",
       " ('DP02_0070PM',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population'),\n",
       " ('DP02_0071E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population!!With a disability'),\n",
       " ('DP02_0071M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population!!With a disability'),\n",
       " ('DP02_0071PE',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population!!With a disability'),\n",
       " ('DP02_0071PM',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Total Civilian Noninstitutionalized Population!!With a disability'),\n",
       " ('DP02_0072E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years'),\n",
       " ('DP02_0072M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years'),\n",
       " ('DP02_0072PE',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years'),\n",
       " ('DP02_0072PM',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years'),\n",
       " ('DP02_0073E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years!!With a disability'),\n",
       " ('DP02_0073M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years!!With a disability'),\n",
       " ('DP02_0073PE',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years!!With a disability'),\n",
       " ('DP02_0073PM',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!Under 18 years!!With a disability'),\n",
       " ('DP02_0074E',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!18 to 64 years'),\n",
       " ('DP02_0074M',\n",
       "  'SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES',\n",
       "  'DISABILITY STATUS OF THE CIVILIAN NONINSTITUTIONALIZED POPULATION!!18 to 64 years')]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censusdata.search('acs5', 2015, 'label', 'disab', tabletype='profile')[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median HH Income - DP03_0062E<br>\n",
    "Avg HH Size - DP02_0015E<br>\n",
    "Non citezen and foreign - DP02_0095E<br>\n",
    "Population disabled - DP02_0071M<br>\n",
    "population 65+ - DP02_0076E<br>\n",
    "hh's with snap or food stamps - DP03_0074E<br>\n",
    "hh's with no vehicle access - DP04_0058E<br>\n",
    "num labor force 16+ employed - DP03_0004E<br>\n",
    "Percent of fam/hh with income below poverty level - DP03_0119PE<br>\n",
    "total num hh - DP02_0001E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cps(year):\n",
    "    df_cps = censusdata.download('acs5', year, censusdata.censusgeo([('county', '*')]),\n",
    "                                   ['DP03_0062E', 'DP02_0071E','DP02_0061E', 'DP02_0064E', 'DP02_0065E',\n",
    "                                    'DP03_0097E','DP03_0098E','DP03_0099E','DP02_0122E','DP03_0119PE', 'DP02_0015E',\n",
    "                                    'DP02_0076E', 'DP04_0058E','DP02_0001E','DP02_0095E','DP03_0074E'],\n",
    "                                   tabletype='profile')\n",
    "    df_cps= df_cps.rename(columns={'DP03_0062E':'hh_med_income', 'DP02_0015E':'hh_avg_size', 'DP02_0095E':'pop_non_citizen',\n",
    "                       'DP02_0071E': 'pop_disabled', 'DP02_0076E':'pop_65+', 'DP02_0061E':'pop_hs_grad',\n",
    "                       'DP02_0064E': 'pop_bachelors', 'DP02_0065E':'pop_grad_degree','DP03_0074E':'hh_SNAP',\n",
    "                       'DP02_0001E': 'num_hh', 'DP04_0058E': 'hh_no_vehicle', \n",
    "                       'DP03_0097E': 'pop_priv_health', 'DP03_0098E': 'pop_public_health', 'DP03_0099E':'pop_no_health',\n",
    "                       'DP02_0122E': 'pop_total', 'DP03_0004E': 'pop_employed', 'DP03_0005E':'pop_unemployed',\n",
    "                       'DP03_0119PE': 'percent_hh_poverty'}).reset_index()\n",
    "    fips=[]\n",
    "    for c in df_cps['index'].tolist():\n",
    "        fips.append(c.geo[0][1] +c.geo[1][1])\n",
    "    df_cps['FIPS'] = fips\n",
    "    df_cps.drop('index',axis=1,inplace=True)\n",
    "    df_cps['Year'] = str(year)\n",
    "    return(df_cps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hh_med_income</th>\n",
       "      <th>pop_disabled</th>\n",
       "      <th>pop_hs_grad</th>\n",
       "      <th>pop_bachelors</th>\n",
       "      <th>pop_grad_degree</th>\n",
       "      <th>pop_priv_health</th>\n",
       "      <th>pop_public_health</th>\n",
       "      <th>pop_no_health</th>\n",
       "      <th>pop_total</th>\n",
       "      <th>percent_hh_poverty</th>\n",
       "      <th>hh_avg_size</th>\n",
       "      <th>pop_65+</th>\n",
       "      <th>hh_no_vehicle</th>\n",
       "      <th>num_hh</th>\n",
       "      <th>pop_non_citizen</th>\n",
       "      <th>hh_SNAP</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38376</td>\n",
       "      <td>-8.89e+08</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>9642.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>2.51</td>\n",
       "      <td>-8.89e+08</td>\n",
       "      <td>684</td>\n",
       "      <td>3339.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>468</td>\n",
       "      <td>13155</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51506</td>\n",
       "      <td>-8.89e+08</td>\n",
       "      <td>13982.0</td>\n",
       "      <td>3868.0</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>58347.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>2.73</td>\n",
       "      <td>-8.89e+08</td>\n",
       "      <td>5386</td>\n",
       "      <td>20917.0</td>\n",
       "      <td>1779.0</td>\n",
       "      <td>2333</td>\n",
       "      <td>13157</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42081</td>\n",
       "      <td>-8.89e+08</td>\n",
       "      <td>3674.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>13695.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.73</td>\n",
       "      <td>-8.89e+08</td>\n",
       "      <td>1392</td>\n",
       "      <td>4998.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>828</td>\n",
       "      <td>13159</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32928</td>\n",
       "      <td>-8.89e+08</td>\n",
       "      <td>4032.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>14558.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>2.58</td>\n",
       "      <td>-8.89e+08</td>\n",
       "      <td>1903</td>\n",
       "      <td>5567.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>619</td>\n",
       "      <td>13161</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29268</td>\n",
       "      <td>-8.89e+08</td>\n",
       "      <td>4808.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>-888888888</td>\n",
       "      <td>16919.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>-8.89e+08</td>\n",
       "      <td>1963</td>\n",
       "      <td>6281.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>1040</td>\n",
       "      <td>13163</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>44717</td>\n",
       "      <td>1.42e+04</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>8415</td>\n",
       "      <td>6378</td>\n",
       "      <td>1575</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1788.00</td>\n",
       "      <td>1.39e+03</td>\n",
       "      <td>272</td>\n",
       "      <td>5491.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>959</td>\n",
       "      <td>47033</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>35191</td>\n",
       "      <td>4.60e+03</td>\n",
       "      <td>966.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>2327</td>\n",
       "      <td>2399</td>\n",
       "      <td>521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>746.00</td>\n",
       "      <td>6.87e+02</td>\n",
       "      <td>259</td>\n",
       "      <td>2243.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>847</td>\n",
       "      <td>47095</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>57470</td>\n",
       "      <td>4.57e+05</td>\n",
       "      <td>17443.0</td>\n",
       "      <td>25676.0</td>\n",
       "      <td>69085.0</td>\n",
       "      <td>331009</td>\n",
       "      <td>143403</td>\n",
       "      <td>35777</td>\n",
       "      <td>963.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>51283.00</td>\n",
       "      <td>2.76e+04</td>\n",
       "      <td>11109</td>\n",
       "      <td>187319.0</td>\n",
       "      <td>9861.0</td>\n",
       "      <td>20359</td>\n",
       "      <td>47093</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>69023</td>\n",
       "      <td>1.96e+05</td>\n",
       "      <td>5961.0</td>\n",
       "      <td>12994.0</td>\n",
       "      <td>24206.0</td>\n",
       "      <td>132402</td>\n",
       "      <td>78477</td>\n",
       "      <td>14248</td>\n",
       "      <td>586.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>20040.00</td>\n",
       "      <td>1.42e+04</td>\n",
       "      <td>3377</td>\n",
       "      <td>72121.0</td>\n",
       "      <td>8145.0</td>\n",
       "      <td>9610</td>\n",
       "      <td>53005</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>75253</td>\n",
       "      <td>4.70e+05</td>\n",
       "      <td>16697.0</td>\n",
       "      <td>35022.0</td>\n",
       "      <td>64098.0</td>\n",
       "      <td>340754</td>\n",
       "      <td>165785</td>\n",
       "      <td>27214</td>\n",
       "      <td>515.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>49829.00</td>\n",
       "      <td>2.88e+04</td>\n",
       "      <td>7905</td>\n",
       "      <td>174661.0</td>\n",
       "      <td>28264.0</td>\n",
       "      <td>21407</td>\n",
       "      <td>53011</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32204 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hh_med_income  pop_disabled  pop_hs_grad  pop_bachelors  pop_grad_degree  pop_priv_health  pop_public_health  pop_no_health  pop_total  percent_hh_poverty  hh_avg_size   pop_65+  hh_no_vehicle    num_hh  pop_non_citizen  hh_SNAP   FIPS  Year\n",
       "0             38376     -8.89e+08       2376.0          260.0            330.0       -888888888         -888888888     -888888888     9642.0                14.9         2.51 -8.89e+08            684    3339.0            181.0      468  13155  2010\n",
       "1             51506     -8.89e+08      13982.0         3868.0           2898.0       -888888888         -888888888     -888888888    58347.0                11.7         2.73 -8.89e+08           5386   20917.0           1779.0     2333  13157  2010\n",
       "2             42081     -8.89e+08       3674.0          687.0            506.0       -888888888         -888888888     -888888888    13695.0                13.2         2.73 -8.89e+08           1392    4998.0            373.0      828  13159  2010\n",
       "3             32928     -8.89e+08       4032.0          721.0            333.0       -888888888         -888888888     -888888888    14558.0                14.9         2.58 -8.89e+08           1903    5567.0            567.0      619  13161  2010\n",
       "4             29268     -8.89e+08       4808.0          674.0            277.0       -888888888         -888888888     -888888888    16919.0                19.0         2.64 -8.89e+08           1963    6281.0            218.0     1040  13163  2010\n",
       "...             ...           ...          ...            ...              ...              ...                ...            ...        ...                 ...          ...       ...            ...       ...              ...      ...    ...   ...\n",
       "3215          44717      1.42e+04       1252.0          669.0            841.0             8415               6378           1575        5.0                13.1      1788.00  1.39e+03            272    5491.0            214.0      959  47033  2019\n",
       "3216          35191      4.60e+03        966.0          217.0            346.0             2327               2399            521        0.0                25.6       746.00  6.87e+02            259    2243.0             33.0      847  47095  2019\n",
       "3217          57470      4.57e+05      17443.0        25676.0          69085.0           331009             143403          35777      963.0                 9.5     51283.00  2.76e+04          11109  187319.0           9861.0    20359  47093  2019\n",
       "3218          69023      1.96e+05       5961.0        12994.0          24206.0           132402              78477          14248      586.0                 8.6     20040.00  1.42e+04           3377   72121.0           8145.0     9610  53005  2019\n",
       "3219          75253      4.70e+05      16697.0        35022.0          64098.0           340754             165785          27214      515.0                 5.8     49829.00  2.88e+04           7905  174661.0          28264.0    21407  53011  2019\n",
       "\n",
       "[32204 rows x 18 columns]"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cps = get_cps(2010)\n",
    "for yr in [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]:\n",
    "    df_cps = pd.concat([df_cps, get_cps(yr)])\n",
    "df_cps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Demographic Data\n",
    "This dataset contains columns on demographic information such as gender, race, and age, for each US county, for years 2010-2019.<br>\n",
    "[Data Dictionary](https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2010-2019/cc-est2019-alldata.pdf)<br>\n",
    "**Source:** United States Census Bureau [County Population Estimates](https://www.census.gov/data/tables/time-series/demo/popest/2010s-counties-detail.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>AGEGRP</th>\n",
       "      <th>TOT_POP</th>\n",
       "      <th>TOT_MALE</th>\n",
       "      <th>TOT_FEMALE</th>\n",
       "      <th>WA_MALE</th>\n",
       "      <th>WA_FEMALE</th>\n",
       "      <th>BA_MALE</th>\n",
       "      <th>BA_FEMALE</th>\n",
       "      <th>IA_MALE</th>\n",
       "      <th>IA_FEMALE</th>\n",
       "      <th>AA_MALE</th>\n",
       "      <th>AA_FEMALE</th>\n",
       "      <th>NA_MALE</th>\n",
       "      <th>NA_FEMALE</th>\n",
       "      <th>TOM_MALE</th>\n",
       "      <th>TOM_FEMALE</th>\n",
       "      <th>WAC_MALE</th>\n",
       "      <th>WAC_FEMALE</th>\n",
       "      <th>BAC_MALE</th>\n",
       "      <th>BAC_FEMALE</th>\n",
       "      <th>IAC_MALE</th>\n",
       "      <th>IAC_FEMALE</th>\n",
       "      <th>AAC_MALE</th>\n",
       "      <th>AAC_FEMALE</th>\n",
       "      <th>NAC_MALE</th>\n",
       "      <th>NAC_FEMALE</th>\n",
       "      <th>NH_MALE</th>\n",
       "      <th>NH_FEMALE</th>\n",
       "      <th>NHWA_MALE</th>\n",
       "      <th>NHWA_FEMALE</th>\n",
       "      <th>NHBA_MALE</th>\n",
       "      <th>NHBA_FEMALE</th>\n",
       "      <th>NHIA_MALE</th>\n",
       "      <th>NHIA_FEMALE</th>\n",
       "      <th>NHAA_MALE</th>\n",
       "      <th>NHAA_FEMALE</th>\n",
       "      <th>NHNA_MALE</th>\n",
       "      <th>NHNA_FEMALE</th>\n",
       "      <th>NHTOM_MALE</th>\n",
       "      <th>NHTOM_FEMALE</th>\n",
       "      <th>NHWAC_MALE</th>\n",
       "      <th>NHWAC_FEMALE</th>\n",
       "      <th>NHBAC_MALE</th>\n",
       "      <th>NHBAC_FEMALE</th>\n",
       "      <th>NHIAC_MALE</th>\n",
       "      <th>NHIAC_FEMALE</th>\n",
       "      <th>NHAAC_MALE</th>\n",
       "      <th>NHAAC_FEMALE</th>\n",
       "      <th>NHNAC_MALE</th>\n",
       "      <th>NHNAC_FEMALE</th>\n",
       "      <th>H_MALE</th>\n",
       "      <th>H_FEMALE</th>\n",
       "      <th>HWA_MALE</th>\n",
       "      <th>HWA_FEMALE</th>\n",
       "      <th>HBA_MALE</th>\n",
       "      <th>HBA_FEMALE</th>\n",
       "      <th>HIA_MALE</th>\n",
       "      <th>HIA_FEMALE</th>\n",
       "      <th>HAA_MALE</th>\n",
       "      <th>HAA_FEMALE</th>\n",
       "      <th>HNA_MALE</th>\n",
       "      <th>HNA_FEMALE</th>\n",
       "      <th>HTOM_MALE</th>\n",
       "      <th>HTOM_FEMALE</th>\n",
       "      <th>HWAC_MALE</th>\n",
       "      <th>HWAC_FEMALE</th>\n",
       "      <th>HBAC_MALE</th>\n",
       "      <th>HBAC_FEMALE</th>\n",
       "      <th>HIAC_MALE</th>\n",
       "      <th>HIAC_FEMALE</th>\n",
       "      <th>HAAC_MALE</th>\n",
       "      <th>HAAC_FEMALE</th>\n",
       "      <th>HNAC_MALE</th>\n",
       "      <th>HNAC_FEMALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54571</td>\n",
       "      <td>26569</td>\n",
       "      <td>28002</td>\n",
       "      <td>21295</td>\n",
       "      <td>22002</td>\n",
       "      <td>4559</td>\n",
       "      <td>5130</td>\n",
       "      <td>119</td>\n",
       "      <td>139</td>\n",
       "      <td>200</td>\n",
       "      <td>284</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>367</td>\n",
       "      <td>429</td>\n",
       "      <td>21633</td>\n",
       "      <td>22391</td>\n",
       "      <td>4704</td>\n",
       "      <td>5306</td>\n",
       "      <td>277</td>\n",
       "      <td>314</td>\n",
       "      <td>300</td>\n",
       "      <td>409</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>25875</td>\n",
       "      <td>27386</td>\n",
       "      <td>20709</td>\n",
       "      <td>21485</td>\n",
       "      <td>4512</td>\n",
       "      <td>5091</td>\n",
       "      <td>103</td>\n",
       "      <td>115</td>\n",
       "      <td>194</td>\n",
       "      <td>280</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>344</td>\n",
       "      <td>406</td>\n",
       "      <td>21026</td>\n",
       "      <td>21853</td>\n",
       "      <td>4647</td>\n",
       "      <td>5258</td>\n",
       "      <td>251</td>\n",
       "      <td>282</td>\n",
       "      <td>291</td>\n",
       "      <td>398</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>694</td>\n",
       "      <td>616</td>\n",
       "      <td>586</td>\n",
       "      <td>517</td>\n",
       "      <td>47</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>607</td>\n",
       "      <td>538</td>\n",
       "      <td>57</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3579</td>\n",
       "      <td>1866</td>\n",
       "      <td>1713</td>\n",
       "      <td>1411</td>\n",
       "      <td>1316</td>\n",
       "      <td>362</td>\n",
       "      <td>317</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>1479</td>\n",
       "      <td>1368</td>\n",
       "      <td>405</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1778</td>\n",
       "      <td>1651</td>\n",
       "      <td>1337</td>\n",
       "      <td>1260</td>\n",
       "      <td>356</td>\n",
       "      <td>313</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>61</td>\n",
       "      <td>1402</td>\n",
       "      <td>1312</td>\n",
       "      <td>396</td>\n",
       "      <td>357</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3991</td>\n",
       "      <td>2001</td>\n",
       "      <td>1990</td>\n",
       "      <td>1521</td>\n",
       "      <td>1526</td>\n",
       "      <td>399</td>\n",
       "      <td>374</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>1570</td>\n",
       "      <td>1583</td>\n",
       "      <td>425</td>\n",
       "      <td>403</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1933</td>\n",
       "      <td>1916</td>\n",
       "      <td>1460</td>\n",
       "      <td>1465</td>\n",
       "      <td>398</td>\n",
       "      <td>372</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>1506</td>\n",
       "      <td>1517</td>\n",
       "      <td>423</td>\n",
       "      <td>400</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>74</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4290</td>\n",
       "      <td>2171</td>\n",
       "      <td>2119</td>\n",
       "      <td>1658</td>\n",
       "      <td>1620</td>\n",
       "      <td>431</td>\n",
       "      <td>406</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>62</td>\n",
       "      <td>1694</td>\n",
       "      <td>1681</td>\n",
       "      <td>453</td>\n",
       "      <td>436</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2105</td>\n",
       "      <td>2055</td>\n",
       "      <td>1613</td>\n",
       "      <td>1570</td>\n",
       "      <td>421</td>\n",
       "      <td>403</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>1643</td>\n",
       "      <td>1624</td>\n",
       "      <td>440</td>\n",
       "      <td>429</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4290</td>\n",
       "      <td>2213</td>\n",
       "      <td>2077</td>\n",
       "      <td>1628</td>\n",
       "      <td>1585</td>\n",
       "      <td>502</td>\n",
       "      <td>424</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>1664</td>\n",
       "      <td>1624</td>\n",
       "      <td>525</td>\n",
       "      <td>444</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2153</td>\n",
       "      <td>2026</td>\n",
       "      <td>1580</td>\n",
       "      <td>1543</td>\n",
       "      <td>495</td>\n",
       "      <td>420</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>1616</td>\n",
       "      <td>1580</td>\n",
       "      <td>518</td>\n",
       "      <td>439</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUMLEV  STATE  COUNTY   STNAME         CTYNAME  YEAR  AGEGRP  TOT_POP  TOT_MALE  TOT_FEMALE  WA_MALE  WA_FEMALE  BA_MALE  BA_FEMALE  IA_MALE  IA_FEMALE  AA_MALE  AA_FEMALE  NA_MALE  NA_FEMALE  TOM_MALE  TOM_FEMALE  WAC_MALE  WAC_FEMALE  BAC_MALE  BAC_FEMALE  IAC_MALE  IAC_FEMALE  AAC_MALE  AAC_FEMALE  NAC_MALE  NAC_FEMALE  NH_MALE  NH_FEMALE  NHWA_MALE  NHWA_FEMALE  NHBA_MALE  NHBA_FEMALE  NHIA_MALE  NHIA_FEMALE  NHAA_MALE  NHAA_FEMALE  NHNA_MALE  NHNA_FEMALE  NHTOM_MALE  NHTOM_FEMALE  NHWAC_MALE  NHWAC_FEMALE  NHBAC_MALE  NHBAC_FEMALE  NHIAC_MALE  NHIAC_FEMALE  NHAAC_MALE  NHAAC_FEMALE  NHNAC_MALE  NHNAC_FEMALE  H_MALE  H_FEMALE  HWA_MALE  HWA_FEMALE  HBA_MALE  HBA_FEMALE  HIA_MALE  HIA_FEMALE  HAA_MALE  HAA_FEMALE  HNA_MALE  HNA_FEMALE  HTOM_MALE  HTOM_FEMALE  HWAC_MALE  HWAC_FEMALE  HBAC_MALE  HBAC_FEMALE  HIAC_MALE  HIAC_FEMALE  HAAC_MALE  HAAC_FEMALE  HNAC_MALE  HNAC_FEMALE\n",
       "0      50      1       1  Alabama  Autauga County     1       0    54571     26569       28002    21295      22002     4559       5130      119        139      200        284       29         18       367         429     21633       22391      4704        5306       277         314       300         409        42          37    25875      27386      20709        21485       4512         5091        103          115        194          280         13            9         344           406       21026         21853        4647          5258         251           282         291           398          23            27     694       616       586         517        47          39        16          24         6           4        16           9         23           23        607          538         57           48         26           32          9           11         19           10\n",
       "1      50      1       1  Alabama  Autauga County     1       1     3579      1866        1713     1411       1316      362        317        5          3       13         15        1          0        74          62      1479        1368       405         362        23          18        34          28         3           1     1778       1651       1337         1260        356          313          2            2         13           15          0            0          70            61        1402          1312         396           357          19            17          34            28           1             0      88        62        74          56         6           4         3           1         0           0         1           0          4            1         77           56          9            5          4            1          0            0          2            1\n",
       "2      50      1       1  Alabama  Autauga County     1       2     3991      2001        1990     1521       1526      399        374       14          8       17         21        1          3        49          58      1570        1583       425         403        27          19        32          42         3           4     1933       1916       1460         1465        398          372         12            2         17           21          0            3          46            53        1506          1517         423           400          25            12          30            39           1             4      68        74        61          61         1           2         2           6         0           0         1           0          3            5         64           66          2            3          2            7          2            3          2            0\n",
       "3      50      1       1  Alabama  Autauga County     1       3     4290      2171        2119     1658       1620      431        406       15         12       23         18        4          1        40          62      1694        1681       453         436        29          27        32          37         4           5     2105       2055       1613         1570        421          403         12            9         22           18          3            0          34            55        1643          1624         440           429          24            22          30            36           3             4      66        64        45          50        10           3         3           3         1           0         1           1          6            7         51           57         13            7          5            5          2            1          1            1\n",
       "4      50      1       1  Alabama  Autauga County     1       4     4290      2213        2077     1628       1585      502        424       12          7       25         14        4          2        42          45      1664        1624       525         444        23          20        39          31         6           5     2153       2026       1580         1543        495          420         12            5         23           14          1            1          42            43        1616          1580         518           439          23            18          37            30           3             4      60        51        48          42         7           4         0           2         2           0         3           1          0            2         48           44          7            5          0            2          2            1          3            1"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset and inspect\n",
    "df_demographics = pd.read_csv('../datasets/demographics/demographics.csv',encoding='iso-8859-1')\n",
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map categorical variables to values from data dictionary\n",
    "Many features in the dataset are coded, and must be mapped to their actual values using a data dictionary using np.select statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate features to be incorporated into model\n",
    "df_demographics = df_demographics.loc[:,['STATE', 'COUNTY', 'STNAME', 'CTYNAME', 'YEAR', 'AGEGRP', 'TOT_POP','TOT_MALE', 'TOT_FEMALE',\n",
    "    'WA_MALE','WA_FEMALE','BA_MALE','BA_FEMALE','IA_MALE','IA_FEMALE','AA_MALE','AA_FEMALE','NA_MALE','NA_FEMALE','H_MALE','H_FEMALE']]\n",
    "\n",
    "# Map coded Year column to actual years\n",
    "conditions=[((df_demographics['YEAR'] ==1) | (df_demographics['YEAR'] ==2) | (df_demographics['YEAR'] ==3)),\n",
    "            df_demographics['YEAR'] ==4, df_demographics['YEAR'] ==5, df_demographics['YEAR'] ==6, \n",
    "            df_demographics['YEAR'] ==7, df_demographics['YEAR'] ==8, df_demographics['YEAR'] ==9,\n",
    "            df_demographics['YEAR'] ==10, df_demographics['YEAR'] ==11, df_demographics['YEAR'] ==12]\n",
    "choices = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "df_demographics['YEAR'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "# Only retain 'All Ages' rows (where AGEGRP==0)\n",
    "df_demographics = df_demographics[df_demographics['AGEGRP']==0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new columns for totals\n",
    "The dataset provides data on number of males and females for each demographic, which are added together to produce a total column for each demographic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics['TOT_WHITE'] = df_demographics['WA_MALE'] + df_demographics['WA_FEMALE']\n",
    "df_demographics['TOT_BLACK'] = df_demographics['BA_MALE'] + df_demographics['BA_FEMALE']\n",
    "df_demographics['TOT_NATIVE'] = df_demographics['IA_MALE'] + df_demographics['IA_FEMALE']\n",
    "df_demographics['TOT_ASIAN'] = df_demographics['AA_MALE'] + df_demographics['AA_FEMALE']\n",
    "df_demographics['TOT_PACIFIC'] = df_demographics['NA_MALE'] + df_demographics['NA_FEMALE']\n",
    "df_demographics['TOT_LATINX'] = df_demographics['H_MALE'] + df_demographics['H_FEMALE']\n",
    "\n",
    "\n",
    "# drop unnecessary cols\n",
    "df_demographics.drop(['AGEGRP','WA_MALE','WA_FEMALE','BA_MALE','BA_FEMALE','IA_MALE','IA_FEMALE',\n",
    "                      'AA_MALE','AA_FEMALE','NA_MALE','NA_FEMALE','H_FEMALE','H_MALE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics.rename(columns={'YEAR':'Year','STATE':'FIPS_state', 'COUNTY':'FIPS_county', \n",
    "                                'STNAME': 'State', 'CTYNAME':'County'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix format of FIPS columns\n",
    "As seen in the previous datasets, FIPS state & county columns are used to create a complete FIPS column, and leading zeroes are added due to being dropped in the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_state</th>\n",
       "      <th>FIPS_county</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Year</th>\n",
       "      <th>TOT_POP</th>\n",
       "      <th>TOT_MALE</th>\n",
       "      <th>TOT_FEMALE</th>\n",
       "      <th>TOT_WHITE</th>\n",
       "      <th>TOT_BLACK</th>\n",
       "      <th>TOT_NATIVE</th>\n",
       "      <th>TOT_ASIAN</th>\n",
       "      <th>TOT_PACIFIC</th>\n",
       "      <th>TOT_LATINX</th>\n",
       "      <th>FIPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>54571</td>\n",
       "      <td>26569</td>\n",
       "      <td>28002</td>\n",
       "      <td>43297</td>\n",
       "      <td>9689</td>\n",
       "      <td>258</td>\n",
       "      <td>484</td>\n",
       "      <td>47</td>\n",
       "      <td>1310</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>54597</td>\n",
       "      <td>26584</td>\n",
       "      <td>28013</td>\n",
       "      <td>43313</td>\n",
       "      <td>9699</td>\n",
       "      <td>258</td>\n",
       "      <td>484</td>\n",
       "      <td>47</td>\n",
       "      <td>1310</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>54773</td>\n",
       "      <td>26672</td>\n",
       "      <td>28101</td>\n",
       "      <td>43420</td>\n",
       "      <td>9750</td>\n",
       "      <td>251</td>\n",
       "      <td>497</td>\n",
       "      <td>46</td>\n",
       "      <td>1313</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2011</td>\n",
       "      <td>55227</td>\n",
       "      <td>26981</td>\n",
       "      <td>28246</td>\n",
       "      <td>43699</td>\n",
       "      <td>9883</td>\n",
       "      <td>261</td>\n",
       "      <td>514</td>\n",
       "      <td>51</td>\n",
       "      <td>1339</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2012</td>\n",
       "      <td>54954</td>\n",
       "      <td>26826</td>\n",
       "      <td>28128</td>\n",
       "      <td>43315</td>\n",
       "      <td>9949</td>\n",
       "      <td>275</td>\n",
       "      <td>552</td>\n",
       "      <td>44</td>\n",
       "      <td>1315</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716281</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2015</td>\n",
       "      <td>7208</td>\n",
       "      <td>3799</td>\n",
       "      <td>3409</td>\n",
       "      <td>6835</td>\n",
       "      <td>39</td>\n",
       "      <td>107</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>285</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716300</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2016</td>\n",
       "      <td>7220</td>\n",
       "      <td>3788</td>\n",
       "      <td>3432</td>\n",
       "      <td>6826</td>\n",
       "      <td>38</td>\n",
       "      <td>108</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>296</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716319</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2017</td>\n",
       "      <td>6968</td>\n",
       "      <td>3660</td>\n",
       "      <td>3308</td>\n",
       "      <td>6558</td>\n",
       "      <td>44</td>\n",
       "      <td>114</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716338</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2018</td>\n",
       "      <td>6924</td>\n",
       "      <td>3627</td>\n",
       "      <td>3297</td>\n",
       "      <td>6474</td>\n",
       "      <td>47</td>\n",
       "      <td>125</td>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "      <td>273</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716357</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2019</td>\n",
       "      <td>6927</td>\n",
       "      <td>3624</td>\n",
       "      <td>3303</td>\n",
       "      <td>6454</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>285</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37704 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS_state FIPS_county    State          County  Year  TOT_POP  TOT_MALE  TOT_FEMALE  TOT_WHITE  TOT_BLACK  TOT_NATIVE  TOT_ASIAN  TOT_PACIFIC  TOT_LATINX   FIPS\n",
       "0              01         001  Alabama  Autauga County  2010    54571     26569       28002      43297       9689         258        484           47        1310  01001\n",
       "19             01         001  Alabama  Autauga County  2010    54597     26584       28013      43313       9699         258        484           47        1310  01001\n",
       "38             01         001  Alabama  Autauga County  2010    54773     26672       28101      43420       9750         251        497           46        1313  01001\n",
       "57             01         001  Alabama  Autauga County  2011    55227     26981       28246      43699       9883         261        514           51        1339  01001\n",
       "76             01         001  Alabama  Autauga County  2012    54954     26826       28128      43315       9949         275        552           44        1315  01001\n",
       "...           ...         ...      ...             ...   ...      ...       ...         ...        ...        ...         ...        ...          ...         ...    ...\n",
       "716281         56         045  Wyoming   Weston County  2015     7208      3799        3409       6835         39         107         81            2         285  56045\n",
       "716300         56         045  Wyoming   Weston County  2016     7220      3788        3432       6826         38         108         88            2         296  56045\n",
       "716319         56         045  Wyoming   Weston County  2017     6968      3660        3308       6558         44         114         97            2         287  56045\n",
       "716338         56         045  Wyoming   Weston County  2018     6924      3627        3297       6474         47         125        109            2         273  56045\n",
       "716357         56         045  Wyoming   Weston County  2019     6927      3624        3303       6454         48         131        117            2         285  56045\n",
       "\n",
       "[37704 rows x 15 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics['FIPS_county'] = np.select([df_demographics['FIPS_county']<10, df_demographics['FIPS_county']<100],\n",
    "                    ['00'+df_demographics['FIPS_county'].astype(str), '0'+df_demographics['FIPS_county'].astype(str)],\n",
    "                    default= df_demographics['FIPS_county'].astype(str))\n",
    "df_demographics['FIPS_state'] = np.where(df_demographics['FIPS_state']<10, \n",
    "                        '0'+df_demographics['FIPS_state'].astype(str), df_demographics['FIPS_state'].astype(str))\n",
    "\n",
    "# Create main fips code and inspect the cleaned dataset\n",
    "df_demographics['FIPS'] = df_demographics['FIPS_state'] + df_demographics['FIPS_county']\n",
    "df_demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Houselessness Data\n",
    "This dataset contains data on houselessness rates in the US by Continuum of Care (CoC,) for the years 2009-2019.<br>\n",
    "**Source:** US Dept. Housing & Urban Development (HUD) [Point in Time Estimates](https://www.hud.gov/2019-point-in-time-estimates-of-homelessness-in-US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the datasets\n",
    "df_houseless_19 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2019')\n",
    "df_houseless_18 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2018')\n",
    "df_houseless_17 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2017')\n",
    "df_houseless_16 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2016')\n",
    "df_houseless_15 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2015')\n",
    "df_houseless_14 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2014')\n",
    "df_houseless_13 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2013')\n",
    "df_houseless_12 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2012')\n",
    "df_houseless_11 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2011')\n",
    "df_houseless_10 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2010')\n",
    "df_houseless_09 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2009')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CoC Number</th>\n",
       "      <th>CoC Name</th>\n",
       "      <th>Overall Homeless, 2010</th>\n",
       "      <th>Sheltered ES Homeless, 2010</th>\n",
       "      <th>Sheltered TH Homeless, 2010</th>\n",
       "      <th>Sheltered SH Homeless, 2010</th>\n",
       "      <th>Sheltered Total Homeless, 2010</th>\n",
       "      <th>Unsheltered Homeless, 2010</th>\n",
       "      <th>Homeless Individuals, 2010</th>\n",
       "      <th>Sheltered ES Homeless Individuals, 2010</th>\n",
       "      <th>Sheltered TH Homeless Individuals, 2010</th>\n",
       "      <th>Sheltered SH Homeless Individuals, 2010</th>\n",
       "      <th>Sheltered Total Homeless Individuals, 2010</th>\n",
       "      <th>Unsheltered Homeless Individuals, 2010</th>\n",
       "      <th>Homeless People in Families, 2010</th>\n",
       "      <th>Sheltered ES Homeless People in Families, 2010</th>\n",
       "      <th>Sheltered TH Homeless People in Families, 2010</th>\n",
       "      <th>Sheltered Total Homeless People in Families, 2010</th>\n",
       "      <th>Unsheltered Homeless People in Families, 2010</th>\n",
       "      <th>Homeless Family Households, 2010</th>\n",
       "      <th>Sheltered ES Homeless Family Households, 2010</th>\n",
       "      <th>Sheltered TH Homeless Family Households, 2010</th>\n",
       "      <th>Sheltered Total Homeless Family Households, 2010</th>\n",
       "      <th>Unsheltered Homeless Family Households, 2010</th>\n",
       "      <th>Sheltered SH Chronically Homeless, 2010</th>\n",
       "      <th>Chronically Homeless Individuals, 2010</th>\n",
       "      <th>Sheltered ES Chronically Homeless Individuals, 2010</th>\n",
       "      <th>Sheltered SH Chronically Homeless Individuals, 2010</th>\n",
       "      <th>Sheltered Total Chronically Homeless Individuals, 2010</th>\n",
       "      <th>Unsheltered Chronically Homeless Individuals, 2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK-500</td>\n",
       "      <td>Anchorage CoC</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>Alaska Balance of State CoC</td>\n",
       "      <td>632.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL-500</td>\n",
       "      <td>Birmingham/Jefferson, St. Clair, Shelby Counti...</td>\n",
       "      <td>2273.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CoC Number                                           CoC Name  Overall Homeless, 2010  Sheltered ES Homeless, 2010  Sheltered TH Homeless, 2010  Sheltered SH Homeless, 2010  Sheltered Total Homeless, 2010  Unsheltered Homeless, 2010  Homeless Individuals, 2010  Sheltered ES Homeless Individuals, 2010  Sheltered TH Homeless Individuals, 2010  Sheltered SH Homeless Individuals, 2010  Sheltered Total Homeless Individuals, 2010  Unsheltered Homeless Individuals, 2010  Homeless People in Families, 2010  Sheltered ES Homeless People in Families, 2010  Sheltered TH Homeless People in Families, 2010  Sheltered Total Homeless People in Families, 2010  Unsheltered Homeless People in Families, 2010  Homeless Family Households, 2010  Sheltered ES Homeless Family Households, 2010  Sheltered TH Homeless Family Households, 2010  Sheltered Total Homeless Family Households, 2010  Unsheltered Homeless Family Households, 2010  Sheltered SH Chronically Homeless, 2010  Chronically Homeless Individuals, 2010  Sheltered ES Chronically Homeless Individuals, 2010  Sheltered SH Chronically Homeless Individuals, 2010  Sheltered Total Chronically Homeless Individuals, 2010  Unsheltered Chronically Homeless Individuals, 2010\n",
       "0     AK-500                                      Anchorage CoC                  1231.0                        667.0                        446.0                          0.0                          1113.0                       118.0                       740.0                                    440.0                                    193.0                                      0.0                                       633.0                                   107.0                              491.0                                           227.0                                           253.0                                              480.0                                           11.0                             151.0                                           67.0                                           80.0                                             147.0                                           4.0                                      0.0                                    56.0                                               43.0                                                  0.0                                                 43.0                                                    13.0 \n",
       "1     AK-501                        Alaska Balance of State CoC                   632.0                        346.0                        212.0                          0.0                           558.0                        74.0                       378.0                                    201.0                                    119.0                                      0.0                                       320.0                                    58.0                              254.0                                           145.0                                            93.0                                              238.0                                           16.0                              93.0                                           46.0                                           43.0                                              89.0                                           4.0                                      0.0                                   108.0                                               76.0                                                  0.0                                                 76.0                                                    32.0 \n",
       "2     AL-500  Birmingham/Jefferson, St. Clair, Shelby Counti...                  2273.0                        372.0                        697.0                          0.0                          1069.0                      1204.0                      1645.0                                    287.0                                    469.0                                      0.0                                       756.0                                   889.0                              628.0                                            85.0                                           228.0                                              313.0                                          315.0                             235.0                                           31.0                                           86.0                                             117.0                                         118.0                                      0.0                                   611.0                                              285.0                                                  0.0                                                285.0                                                   326.0 "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect one of the datasets\n",
    "df_houseless_10.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim down columns not needed for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houseless_19 = df_houseless_19.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2019', 'Sheltered Total Homeless, 2019', 'Unsheltered Homeless, 2019']]\n",
    "df_houseless_18 = df_houseless_18.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2018', 'Sheltered Total Homeless, 2018', 'Unsheltered Homeless, 2018']]\n",
    "df_houseless_17 = df_houseless_17.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2017', 'Sheltered Total Homeless, 2017', 'Unsheltered Homeless, 2017']]\n",
    "df_houseless_16 = df_houseless_16.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2016', 'Sheltered Total Homeless, 2016', 'Unsheltered Homeless, 2016']]\n",
    "df_houseless_15 = df_houseless_15.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2015', 'Sheltered Total Homeless, 2015', 'Unsheltered Homeless, 2015']]\n",
    "df_houseless_14 = df_houseless_14.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2014', 'Sheltered Total Homeless, 2014', 'Unsheltered Homeless, 2014']]\n",
    "df_houseless_13 = df_houseless_13.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2013', 'Sheltered Total Homeless, 2013', 'Unsheltered Homeless, 2013']]\n",
    "df_houseless_12 = df_houseless_12.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2012', 'Sheltered Total Homeless, 2012', 'Unsheltered Homeless, 2012']]\n",
    "df_houseless_11 = df_houseless_11.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2011', 'Sheltered Total Homeless, 2011', 'Unsheltered Homeless, 2011']]\n",
    "df_houseless_10 = df_houseless_10.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2010', 'Sheltered Total Homeless, 2010', 'Unsheltered Homeless, 2010']]\n",
    "df_houseless_09 = df_houseless_09.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2009', 'Sheltered Total Homeless, 2009', 'Unsheltered Homeless, 2009']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houseless_19.rename(columns={'Overall Homeless, 2019':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2019': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2019': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_18.rename(columns={'Overall Homeless, 2018':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2018': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2018': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_17.rename(columns={'Overall Homeless, 2017':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2017': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2017': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_16.rename(columns={'Overall Homeless, 2016':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2016': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2016': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_15.rename(columns={'Overall Homeless, 2015':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2015': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2015': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_14.rename(columns={'Overall Homeless, 2014':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2014': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2014': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_13.rename(columns={'Overall Homeless, 2013':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2013': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2013': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_12.rename(columns={'Overall Homeless, 2012':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2012': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2012': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_11.rename(columns={'Overall Homeless, 2011':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2011': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2011': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_10.rename(columns={'Overall Homeless, 2010':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2010': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2010': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_09.rename(columns={'Overall Homeless, 2009':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2009': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2009': 'Unsheltered_houseless'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask: Derive houselessness at the County level using CoC's\n",
    "A CoC is a regional planning body that coordinates housing and services funding for homeless families and individuals. A CoC often encompasses several counties within a State. For the sake of standardizing to all other datasets, the following process will derive a houselessness rate per CoC, and then extend apply those rates to the population of each County, to derive houselessness counts at the County level.<br>\n",
    "**Method:**<br>\n",
    "- Merge CoC column to demographics df to get population perCoC.<br>\n",
    "- Join that with houseless df to derive houseless rate per CoC.<br>\n",
    "- Join that to CoC_county to get houseless rate per county.<br>\n",
    "- (optional) Join rates back with demographic df to get number of houseless, per county<br>\n",
    "\n",
    "**Source:** [CoC-to-County Mappings](https://github.com/tomhbyrne/HUD-CoC-Geography-Crosswalk/blob/master/output/county_coc_match.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import csv that maps counties to a CoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoC_county = pd.read_csv('../datasets/houseless/county_coc_match.csv', encoding='ISO-8859-1')\n",
    "CoC_county = CoC_county.loc[:,['county_fips','coc_number']]\n",
    "\n",
    "# rename columns\n",
    "CoC_county.rename(columns={'county_fips':'FIPS'}, inplace=True)\n",
    "\n",
    "# drop 2 rows with no FIPS\n",
    "CoC_county.drop(CoC_county[CoC_county['FIPS'].isnull()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix format of FIPS column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change FIPS to string and add leading zeros if needed\n",
    "CoC_county['FIPS'] = np.where(CoC_county['FIPS']<10000, \n",
    "                        '0'+CoC_county['FIPS'].astype(int).astype(str), CoC_county['FIPS'].astype(int).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get population count per CoC\n",
    "Data from the demographics dataset is used to get population per County. This is mapped with CoC's, to get population per CoC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get total population by county\n",
    "avg = df_demographics[df_demographics['Year']=='2010'].groupby('FIPS').mean()\n",
    "# merge with CoC_county to get pop count per CoC\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_10 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# repeat for each year\n",
    "avg = df_demographics[df_demographics['Year']=='2011'].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_11 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2012\n",
    "avg = df_demographics[df_demographics['Year']=='2012'].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_12 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2013\n",
    "avg = df_demographics[df_demographics['Year']=='2013'].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_13 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2014\n",
    "avg = df_demographics[df_demographics['Year']=='2014'].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_14 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2015\n",
    "avg = df_demographics[df_demographics['Year']=='2015'].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_15 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2016\n",
    "avg = df_demographics[df_demographics['Year']=='2016'].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_16 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2017\n",
    "avg = df_demographics[df_demographics['Year']=='2017'].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_17 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2018\n",
    "avg = df_demographics[df_demographics['Year']=='2018'].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_18 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2019\n",
    "avg = df_demographics[df_demographics['Year']=='2019'].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_19 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get houselessness rate per CoC\n",
    "Population count per CoC is merged with th houselessness df to derive houselessness rate per CoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get houseless rate per CoC \n",
    "# 2010\n",
    "merged = pop_per_coc_10.merge(df_houseless_10, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_10 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2011\n",
    "merged = pop_per_coc_11.merge(df_houseless_11, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_11 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2012\n",
    "merged = pop_per_coc_12.merge(df_houseless_12, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_12 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2013\n",
    "merged = pop_per_coc_13.merge(df_houseless_13, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_13 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2014\n",
    "merged = pop_per_coc_14.merge(df_houseless_14, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_14 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2015\n",
    "merged = pop_per_coc_15.merge(df_houseless_15, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_15 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2016\n",
    "merged = pop_per_coc_16.merge(df_houseless_16, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_16 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2017\n",
    "merged = pop_per_coc_17.merge(df_houseless_17, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_17 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2018\n",
    "merged = pop_per_coc_18.merge(df_houseless_18, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_18 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2019\n",
    "merged = pop_per_coc_19.merge(df_houseless_19, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_19 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Houselessness rates per County\n",
    "Houseless rate per CoC is mapped back to Counties, to get houseless rates per county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get houseless rate per county, for each year\n",
    "df_houseless_10 = rates_10.merge(CoC_county, on='coc_number')\n",
    "df_houseless_11 = rates_11.merge(CoC_county, on='coc_number')\n",
    "df_houseless_12 = rates_12.merge(CoC_county, on='coc_number')\n",
    "df_houseless_13 = rates_13.merge(CoC_county, on='coc_number')\n",
    "df_houseless_14 = rates_14.merge(CoC_county, on='coc_number')\n",
    "df_houseless_15 = rates_15.merge(CoC_county, on='coc_number')\n",
    "df_houseless_16 = rates_16.merge(CoC_county, on='coc_number')\n",
    "df_houseless_17 = rates_17.merge(CoC_county, on='coc_number')\n",
    "df_houseless_18 = rates_18.merge(CoC_county, on='coc_number')\n",
    "df_houseless_19 = rates_19.merge(CoC_county, on='coc_number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Year column to each df\n",
    "Year column is added so that each df can be vertically concatenated together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houseless_10['Year'] = '2010'\n",
    "df_houseless_11['Year'] = '2011'\n",
    "df_houseless_12['Year'] = '2012'\n",
    "df_houseless_13['Year'] = '2013'\n",
    "df_houseless_14['Year'] = '2014'\n",
    "df_houseless_15['Year'] = '2015'\n",
    "df_houseless_16['Year'] = '2016'\n",
    "df_houseless_17['Year'] = '2017'\n",
    "df_houseless_18['Year'] = '2018'\n",
    "df_houseless_19['Year'] = '2019'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate all df's to create master dataframe of all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coc_number</th>\n",
       "      <th>Houseless_rate</th>\n",
       "      <th>Sheltered_rate</th>\n",
       "      <th>Unsheltered_rate</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK-500</td>\n",
       "      <td>4.00e-02</td>\n",
       "      <td>3.62e-02</td>\n",
       "      <td>3.83e-03</td>\n",
       "      <td>02020</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>1.43e-02</td>\n",
       "      <td>1.26e-02</td>\n",
       "      <td>1.68e-03</td>\n",
       "      <td>02013</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>1.43e-02</td>\n",
       "      <td>1.26e-02</td>\n",
       "      <td>1.68e-03</td>\n",
       "      <td>02016</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>1.43e-02</td>\n",
       "      <td>1.26e-02</td>\n",
       "      <td>1.68e-03</td>\n",
       "      <td>02050</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>1.43e-02</td>\n",
       "      <td>1.26e-02</td>\n",
       "      <td>1.68e-03</td>\n",
       "      <td>02060</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>9.00e-03</td>\n",
       "      <td>6.94e-03</td>\n",
       "      <td>2.05e-03</td>\n",
       "      <td>56037</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>9.00e-03</td>\n",
       "      <td>6.94e-03</td>\n",
       "      <td>2.05e-03</td>\n",
       "      <td>56039</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>9.00e-03</td>\n",
       "      <td>6.94e-03</td>\n",
       "      <td>2.05e-03</td>\n",
       "      <td>56041</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>9.00e-03</td>\n",
       "      <td>6.94e-03</td>\n",
       "      <td>2.05e-03</td>\n",
       "      <td>56043</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>9.00e-03</td>\n",
       "      <td>6.94e-03</td>\n",
       "      <td>2.05e-03</td>\n",
       "      <td>56045</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31698 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coc_number  Houseless_rate  Sheltered_rate  Unsheltered_rate   FIPS  Year\n",
       "0        AK-500        4.00e-02        3.62e-02          3.83e-03  02020  2010\n",
       "1        AK-501        1.43e-02        1.26e-02          1.68e-03  02013  2010\n",
       "2        AK-501        1.43e-02        1.26e-02          1.68e-03  02016  2010\n",
       "3        AK-501        1.43e-02        1.26e-02          1.68e-03  02050  2010\n",
       "4        AK-501        1.43e-02        1.26e-02          1.68e-03  02060  2010\n",
       "...         ...             ...             ...               ...    ...   ...\n",
       "3158     WY-500        9.00e-03        6.94e-03          2.05e-03  56037  2019\n",
       "3159     WY-500        9.00e-03        6.94e-03          2.05e-03  56039  2019\n",
       "3160     WY-500        9.00e-03        6.94e-03          2.05e-03  56041  2019\n",
       "3161     WY-500        9.00e-03        6.94e-03          2.05e-03  56043  2019\n",
       "3162     WY-500        9.00e-03        6.94e-03          2.05e-03  56045  2019\n",
       "\n",
       "[31698 rows x 6 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_houseless = pd.concat([df_houseless_10, df_houseless_11,df_houseless_12,df_houseless_13,df_houseless_14,df_houseless_15,\n",
    "          df_houseless_16,df_houseless_17,df_houseless_18,df_houseless_19])\n",
    "\n",
    "# Inspect cleaned houselessness df\n",
    "df_houseless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Rent Prices Data\n",
    "This dataset contains *monthly* data from Zillow.com on 1-bedroom rent prices *by zipcode*, for the years 2014-2020.\n",
    "The data is produced using the **Zillow Observed Rent Index** (ZORI,) which is a smoothed measure of the typical observed market rate rent across a given region.<br>\n",
    "\n",
    "\"ZORI is a repeat-rent index that is weighted to the rental housing stock to ensure representativeness across the entire market, not just those homes currently listed for-rent. The index is dollar-denominated by computing the mean of listed rents that fall into the 40th to 60th percentile range for all homes and apartments in a given region, which is once again weighted to reflect the rental housing stock.\"<br>\n",
    "\n",
    "**Source:** [Zillow Observed Rent Index](https://www.zillow.com/research/data/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>MsaName</th>\n",
       "      <th>2014-01</th>\n",
       "      <th>2014-02</th>\n",
       "      <th>2014-03</th>\n",
       "      <th>2014-04</th>\n",
       "      <th>2014-05</th>\n",
       "      <th>2014-06</th>\n",
       "      <th>2014-07</th>\n",
       "      <th>2014-08</th>\n",
       "      <th>2014-09</th>\n",
       "      <th>2014-10</th>\n",
       "      <th>2014-11</th>\n",
       "      <th>2014-12</th>\n",
       "      <th>2015-01</th>\n",
       "      <th>2015-02</th>\n",
       "      <th>2015-03</th>\n",
       "      <th>2015-04</th>\n",
       "      <th>2015-05</th>\n",
       "      <th>2015-06</th>\n",
       "      <th>2015-07</th>\n",
       "      <th>2015-08</th>\n",
       "      <th>2015-09</th>\n",
       "      <th>2015-10</th>\n",
       "      <th>2015-11</th>\n",
       "      <th>2015-12</th>\n",
       "      <th>2016-01</th>\n",
       "      <th>2016-02</th>\n",
       "      <th>2016-03</th>\n",
       "      <th>2016-04</th>\n",
       "      <th>2016-05</th>\n",
       "      <th>2016-06</th>\n",
       "      <th>2016-07</th>\n",
       "      <th>2016-08</th>\n",
       "      <th>2016-09</th>\n",
       "      <th>2016-10</th>\n",
       "      <th>2016-11</th>\n",
       "      <th>2016-12</th>\n",
       "      <th>2017-01</th>\n",
       "      <th>2017-02</th>\n",
       "      <th>2017-03</th>\n",
       "      <th>2017-04</th>\n",
       "      <th>2017-05</th>\n",
       "      <th>2017-06</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "      <th>2018-05</th>\n",
       "      <th>2018-06</th>\n",
       "      <th>2018-07</th>\n",
       "      <th>2018-08</th>\n",
       "      <th>2018-09</th>\n",
       "      <th>2018-10</th>\n",
       "      <th>2018-11</th>\n",
       "      <th>2018-12</th>\n",
       "      <th>2019-01</th>\n",
       "      <th>2019-02</th>\n",
       "      <th>2019-03</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "      <th>2019-10</th>\n",
       "      <th>2019-11</th>\n",
       "      <th>2019-12</th>\n",
       "      <th>2020-01</th>\n",
       "      <th>2020-02</th>\n",
       "      <th>2020-03</th>\n",
       "      <th>2020-04</th>\n",
       "      <th>2020-05</th>\n",
       "      <th>2020-06</th>\n",
       "      <th>2020-07</th>\n",
       "      <th>2020-08</th>\n",
       "      <th>2020-09</th>\n",
       "      <th>2020-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61639</td>\n",
       "      <td>10025</td>\n",
       "      <td>1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>3008.0</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>3045.0</td>\n",
       "      <td>3057.0</td>\n",
       "      <td>3069.0</td>\n",
       "      <td>3082.0</td>\n",
       "      <td>3094.0</td>\n",
       "      <td>3106.0</td>\n",
       "      <td>3118.0</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>3141.0</td>\n",
       "      <td>3153.0</td>\n",
       "      <td>3162.0</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>3185.0</td>\n",
       "      <td>3190.0</td>\n",
       "      <td>3194.0</td>\n",
       "      <td>3198.0</td>\n",
       "      <td>3202.0</td>\n",
       "      <td>3206.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3213.0</td>\n",
       "      <td>3217.0</td>\n",
       "      <td>3219.0</td>\n",
       "      <td>3222.0</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>3226.0</td>\n",
       "      <td>3227.0</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>3223.0</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>3219.0</td>\n",
       "      <td>3218.0</td>\n",
       "      <td>3219.0</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>3219.0</td>\n",
       "      <td>3217.0</td>\n",
       "      <td>3216.0</td>\n",
       "      <td>3214.0</td>\n",
       "      <td>3213.0</td>\n",
       "      <td>3211.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3209.0</td>\n",
       "      <td>3207.0</td>\n",
       "      <td>3207.0</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3211.0</td>\n",
       "      <td>3213.0</td>\n",
       "      <td>3216.0</td>\n",
       "      <td>3218.0</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>3229.0</td>\n",
       "      <td>3233.0</td>\n",
       "      <td>3239.0</td>\n",
       "      <td>3245.0</td>\n",
       "      <td>3252.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>3271.0</td>\n",
       "      <td>3281.0</td>\n",
       "      <td>3289.0</td>\n",
       "      <td>3298.0</td>\n",
       "      <td>3306.0</td>\n",
       "      <td>3296.0</td>\n",
       "      <td>3287.0</td>\n",
       "      <td>3277.0</td>\n",
       "      <td>3249.0</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>3193.0</td>\n",
       "      <td>3164.0</td>\n",
       "      <td>3134.0</td>\n",
       "      <td>3104.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>3038.0</td>\n",
       "      <td>3005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>2</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>1583.0</td>\n",
       "      <td>1588.0</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>1628.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>1647.0</td>\n",
       "      <td>1652.0</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>1673.0</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>1693.0</td>\n",
       "      <td>1698.0</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>1708.0</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>1741.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>1751.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>1754.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>1763.0</td>\n",
       "      <td>1763.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>1765.0</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1767.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>1772.0</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>1779.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>1801.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>1818.0</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>1806.0</td>\n",
       "      <td>1801.0</td>\n",
       "      <td>1797.0</td>\n",
       "      <td>1792.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>1781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61637</td>\n",
       "      <td>10023</td>\n",
       "      <td>3</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>3136.0</td>\n",
       "      <td>3145.0</td>\n",
       "      <td>3154.0</td>\n",
       "      <td>3163.0</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>3179.0</td>\n",
       "      <td>3187.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>3202.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3215.0</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>3229.0</td>\n",
       "      <td>3233.0</td>\n",
       "      <td>3236.0</td>\n",
       "      <td>3242.0</td>\n",
       "      <td>3248.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>3267.0</td>\n",
       "      <td>3274.0</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>3290.0</td>\n",
       "      <td>3290.0</td>\n",
       "      <td>3291.0</td>\n",
       "      <td>3291.0</td>\n",
       "      <td>3288.0</td>\n",
       "      <td>3284.0</td>\n",
       "      <td>3281.0</td>\n",
       "      <td>3278.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3273.0</td>\n",
       "      <td>3274.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>3278.0</td>\n",
       "      <td>3279.0</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>3281.0</td>\n",
       "      <td>3281.0</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>3279.0</td>\n",
       "      <td>3279.0</td>\n",
       "      <td>3278.0</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>3277.0</td>\n",
       "      <td>3278.0</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>3284.0</td>\n",
       "      <td>3288.0</td>\n",
       "      <td>3292.0</td>\n",
       "      <td>3296.0</td>\n",
       "      <td>3301.0</td>\n",
       "      <td>3305.0</td>\n",
       "      <td>3310.0</td>\n",
       "      <td>3315.0</td>\n",
       "      <td>3320.0</td>\n",
       "      <td>3327.0</td>\n",
       "      <td>3333.0</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>3355.0</td>\n",
       "      <td>3362.0</td>\n",
       "      <td>3368.0</td>\n",
       "      <td>3374.0</td>\n",
       "      <td>3380.0</td>\n",
       "      <td>3370.0</td>\n",
       "      <td>3360.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>3324.0</td>\n",
       "      <td>3298.0</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3244.0</td>\n",
       "      <td>3217.0</td>\n",
       "      <td>3189.0</td>\n",
       "      <td>3158.0</td>\n",
       "      <td>3128.0</td>\n",
       "      <td>3097.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RegionID  RegionName  SizeRank       MsaName  2014-01  2014-02  2014-03  2014-04  2014-05  2014-06  2014-07  2014-08  2014-09  2014-10  2014-11  2014-12  2015-01  2015-02  2015-03  2015-04  2015-05  2015-06  2015-07  2015-08  2015-09  2015-10  2015-11  2015-12  2016-01  2016-02  2016-03  2016-04  2016-05  2016-06  2016-07  2016-08  2016-09  2016-10  2016-11  2016-12  2017-01  2017-02  2017-03  2017-04  2017-05  2017-06  2017-07  2017-08  2017-09  2017-10  2017-11  2017-12  2018-01  2018-02  2018-03  2018-04  2018-05  2018-06  2018-07  2018-08  2018-09  2018-10  2018-11  2018-12  2019-01  2019-02  2019-03  2019-04  2019-05  2019-06  2019-07  2019-08  2019-09  2019-10  2019-11  2019-12  2020-01  2020-02  2020-03  2020-04  2020-05  2020-06  2020-07  2020-08  2020-09  2020-10\n",
       "0     61639       10025         1  New York, NY   3008.0   3020.0   3032.0   3045.0   3057.0   3069.0   3082.0   3094.0   3106.0   3118.0   3129.0   3141.0   3153.0   3162.0   3171.0   3180.0   3185.0   3190.0   3194.0   3198.0   3202.0   3206.0   3210.0   3213.0   3217.0   3219.0   3222.0   3225.0   3225.0   3226.0   3227.0   3225.0   3223.0   3221.0   3220.0   3219.0   3218.0   3219.0   3220.0   3220.0   3219.0   3217.0   3216.0   3214.0   3213.0   3211.0   3210.0   3209.0   3207.0   3207.0   3208.0   3208.0   3210.0   3211.0   3213.0   3216.0   3218.0   3221.0   3225.0   3229.0   3233.0   3239.0   3245.0   3252.0   3261.0   3271.0   3281.0   3289.0   3298.0   3306.0   3296.0   3287.0   3277.0   3249.0   3221.0   3193.0   3164.0   3134.0   3104.0   3071.0   3038.0   3005.0\n",
       "1     84654       60657         2   Chicago, IL   1577.0   1583.0   1588.0   1593.0   1598.0   1603.0   1608.0   1613.0   1618.0   1623.0   1628.0   1633.0   1638.0   1643.0   1647.0   1652.0   1656.0   1660.0   1664.0   1669.0   1673.0   1678.0   1683.0   1688.0   1693.0   1698.0   1703.0   1708.0   1712.0   1717.0   1722.0   1726.0   1731.0   1735.0   1738.0   1741.0   1744.0   1746.0   1747.0   1749.0   1751.0   1752.0   1754.0   1756.0   1757.0   1759.0   1760.0   1762.0   1763.0   1763.0   1764.0   1764.0   1764.0   1764.0   1764.0   1765.0   1766.0   1767.0   1769.0   1772.0   1774.0   1779.0   1784.0   1788.0   1795.0   1801.0   1807.0   1812.0   1817.0   1822.0   1822.0   1822.0   1822.0   1818.0   1814.0   1810.0   1806.0   1801.0   1797.0   1792.0   1786.0   1781.0\n",
       "2     61637       10023         3  New York, NY   3136.0   3145.0   3154.0   3163.0   3171.0   3179.0   3187.0   3195.0   3202.0   3210.0   3215.0   3220.0   3225.0   3229.0   3233.0   3236.0   3242.0   3248.0   3254.0   3261.0   3267.0   3274.0   3280.0   3285.0   3290.0   3290.0   3291.0   3291.0   3288.0   3284.0   3281.0   3278.0   3275.0   3272.0   3273.0   3274.0   3275.0   3276.0   3278.0   3279.0   3280.0   3281.0   3281.0   3280.0   3279.0   3279.0   3278.0   3276.0   3275.0   3277.0   3278.0   3280.0   3284.0   3288.0   3292.0   3296.0   3301.0   3305.0   3310.0   3315.0   3320.0   3327.0   3333.0   3340.0   3347.0   3355.0   3362.0   3368.0   3374.0   3380.0   3370.0   3360.0   3350.0   3324.0   3298.0   3272.0   3244.0   3217.0   3189.0   3158.0   3128.0   3097.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import Zillow dataset\n",
    "df_rent = pd.read_csv('../datasets/rent_prices/rent_prices.csv')\n",
    "df_rent.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take averages of months in each year\n",
    "Data is only needed at yearly intervals, so monthly averages are calculated in a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate columns corresponding to each year, and make new column\n",
    "drop_14 = df_rent.columns[df_rent.columns.str.contains('2014')]\n",
    "df_rent['2014'] = df_rent.loc[:,drop_14].mean(axis=1)\n",
    "\n",
    "drop_15 = df_rent.columns[df_rent.columns.str.contains('2015')]\n",
    "df_rent['2015'] = df_rent.loc[:,drop_15].mean(axis=1)\n",
    "\n",
    "drop_16 = df_rent.columns[df_rent.columns.str.contains('2016')]\n",
    "df_rent['2016'] = df_rent.loc[:,drop_16].mean(axis=1)\n",
    "\n",
    "drop_17 = df_rent.columns[df_rent.columns.str.contains('2017')]\n",
    "df_rent['2017'] = df_rent.loc[:,drop_17].mean(axis=1)\n",
    "\n",
    "drop_18 = df_rent.columns[df_rent.columns.str.contains('2018')]\n",
    "df_rent['2018'] = df_rent.loc[:,drop_18].mean(axis=1)\n",
    "\n",
    "drop_19 = df_rent.columns[df_rent.columns.str.contains('2019')]\n",
    "df_rent['2019'] = df_rent.loc[:,drop_19].mean(axis=1)\n",
    "\n",
    "drop_20 = df_rent.columns[df_rent.columns.str.contains('2020')]\n",
    "df_rent['2020'] = df_rent.loc[:,drop_20].mean(axis=1)\n",
    "\n",
    "# drop all monthly data \n",
    "to_drop = drop_14.append(drop_15).append(drop_16).append(drop_17).append(drop_18).append(drop_19).append(drop_20)\n",
    "df_rent.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rent.rename(columns={'RegionName':'Zipcode', 'MsaName':'City/State'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask: Map Zipcodes to Counties\n",
    "Data is provided by zipcode, so it is converted to the County level using the following process:<br>\n",
    "**Method:** join county data to each zipcode, then groupby county and take mean\n",
    "### Import a dataset with zipcode-to-county mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zips = pd.read_csv('../datasets/rent_prices/uszips.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Zipcode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns and rename some\n",
    "zips =zips.loc[:,['zip', 'county_fips']]\n",
    "zips.rename(columns={'zip': 'Zipcode', 'county_fips': 'FIPS'},inplace=True)\n",
    "\n",
    "# add leading zero to FIPS values where needed\n",
    "zips['FIPS'] = np.where(zips['FIPS']<10000, \n",
    "                        '0'+zips['FIPS'].astype(str), zips['FIPS'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge Zillow dataset with zipcodes dataset\n",
    "merged = df_rent.merge(zips, on='Zipcode', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Data by County\n",
    "drop zipcode column, then group by FIPS so that there is one row per County, taking the mean of each of the zipcodes within that county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01073</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>1049.23</td>\n",
       "      <td>1070.13</td>\n",
       "      <td>1090.53</td>\n",
       "      <td>1127.70</td>\n",
       "      <td>1165.38</td>\n",
       "      <td>1199.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01117</td>\n",
       "      <td>1229.76</td>\n",
       "      <td>1265.13</td>\n",
       "      <td>1282.00</td>\n",
       "      <td>1296.61</td>\n",
       "      <td>1334.00</td>\n",
       "      <td>1380.59</td>\n",
       "      <td>1416.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04003</td>\n",
       "      <td>1051.25</td>\n",
       "      <td>1047.46</td>\n",
       "      <td>1035.08</td>\n",
       "      <td>1033.00</td>\n",
       "      <td>1084.79</td>\n",
       "      <td>1151.58</td>\n",
       "      <td>1217.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04013</td>\n",
       "      <td>1095.67</td>\n",
       "      <td>1164.84</td>\n",
       "      <td>1224.38</td>\n",
       "      <td>1274.52</td>\n",
       "      <td>1349.59</td>\n",
       "      <td>1443.69</td>\n",
       "      <td>1537.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04019</td>\n",
       "      <td>928.55</td>\n",
       "      <td>947.02</td>\n",
       "      <td>974.15</td>\n",
       "      <td>1015.56</td>\n",
       "      <td>1070.98</td>\n",
       "      <td>1135.42</td>\n",
       "      <td>1206.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>53061</td>\n",
       "      <td>1390.78</td>\n",
       "      <td>1490.70</td>\n",
       "      <td>1610.37</td>\n",
       "      <td>1717.01</td>\n",
       "      <td>1793.83</td>\n",
       "      <td>1868.80</td>\n",
       "      <td>1924.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>53063</td>\n",
       "      <td>808.36</td>\n",
       "      <td>844.68</td>\n",
       "      <td>900.67</td>\n",
       "      <td>959.86</td>\n",
       "      <td>1031.23</td>\n",
       "      <td>1086.46</td>\n",
       "      <td>1146.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>55025</td>\n",
       "      <td>1280.04</td>\n",
       "      <td>1348.67</td>\n",
       "      <td>1388.86</td>\n",
       "      <td>1418.14</td>\n",
       "      <td>1437.54</td>\n",
       "      <td>1468.61</td>\n",
       "      <td>1506.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>55059</td>\n",
       "      <td>689.00</td>\n",
       "      <td>695.40</td>\n",
       "      <td>741.27</td>\n",
       "      <td>782.42</td>\n",
       "      <td>818.42</td>\n",
       "      <td>872.10</td>\n",
       "      <td>921.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>55079</td>\n",
       "      <td>968.36</td>\n",
       "      <td>986.25</td>\n",
       "      <td>997.40</td>\n",
       "      <td>1009.58</td>\n",
       "      <td>1024.45</td>\n",
       "      <td>1049.13</td>\n",
       "      <td>1072.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS     2014     2015     2016     2017     2018     2019     2020\n",
       "0    01073  1020.00  1049.23  1070.13  1090.53  1127.70  1165.38  1199.08\n",
       "1    01117  1229.76  1265.13  1282.00  1296.61  1334.00  1380.59  1416.27\n",
       "2    04003  1051.25  1047.46  1035.08  1033.00  1084.79  1151.58  1217.49\n",
       "3    04013  1095.67  1164.84  1224.38  1274.52  1349.59  1443.69  1537.92\n",
       "4    04019   928.55   947.02   974.15  1015.56  1070.98  1135.42  1206.15\n",
       "..     ...      ...      ...      ...      ...      ...      ...      ...\n",
       "307  53061  1390.78  1490.70  1610.37  1717.01  1793.83  1868.80  1924.69\n",
       "308  53063   808.36   844.68   900.67   959.86  1031.23  1086.46  1146.72\n",
       "309  55025  1280.04  1348.67  1388.86  1418.14  1437.54  1468.61  1506.96\n",
       "310  55059   689.00   695.40   741.27   782.42   818.42   872.10   921.80\n",
       "311  55079   968.36   986.25   997.40  1009.58  1024.45  1049.13  1072.60\n",
       "\n",
       "[312 rows x 8 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rent = merged.groupby('FIPS').mean().drop(['RegionID', 'Zipcode', 'SizeRank'],axis=1).reset_index()\n",
    "df_rent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break down into separate df's by year, and add year column\n",
    "Dataset must be reformatted to follow the same pattern as all others, so that they can ultimately be concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014\n",
    "# isolate relevant columns, rename, and creat year column\n",
    "df_rent_14 = df_rent[['FIPS', '2014']]\n",
    "df_rent_14.rename(columns={'2014':'Rent'}, inplace=True)\n",
    "df_rent_14['Year'] = '2014'\n",
    "\n",
    "# 2015\n",
    "df_rent_15 = df_rent[['FIPS', '2015']]\n",
    "df_rent_15.rename(columns={'2015':'Rent'}, inplace=True)\n",
    "df_rent_15['Year'] = '2015'\n",
    "\n",
    "# 2016\n",
    "df_rent_16 = df_rent[['FIPS', '2016']]\n",
    "df_rent_16.rename(columns={'2016':'Rent'}, inplace=True)\n",
    "df_rent_16['Year'] = '2016'\n",
    "\n",
    "\n",
    "# 2017\n",
    "df_rent_17 = df_rent[['FIPS', '2017']]\n",
    "df_rent_17.rename(columns={'2017':'Rent'}, inplace=True)\n",
    "df_rent_17['Year'] = '2017'\n",
    "\n",
    "# 2018\n",
    "df_rent_18 = df_rent[['FIPS', '2018']]\n",
    "df_rent_18.rename(columns={'2018':'Rent'}, inplace=True)\n",
    "df_rent_18['Year'] = '2018'\n",
    "\n",
    "# 2019\n",
    "df_rent_19 = df_rent[['FIPS', '2019']]\n",
    "df_rent_19.rename(columns={'2019':'Rent'}, inplace=True)\n",
    "df_rent_19['Year'] = '2019'\n",
    "\n",
    "# 2020\n",
    "df_rent_20 = df_rent[['FIPS', '2020']]\n",
    "df_rent_20.rename(columns={'2020':'Rent'}, inplace=True)\n",
    "df_rent_20['Year'] = '2020'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate all df's to create master dataframe of all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Rent</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01073</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01117</td>\n",
       "      <td>1229.76</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04003</td>\n",
       "      <td>1051.25</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04013</td>\n",
       "      <td>1095.67</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04019</td>\n",
       "      <td>928.55</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>53061</td>\n",
       "      <td>1924.69</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>53063</td>\n",
       "      <td>1146.72</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>55025</td>\n",
       "      <td>1506.96</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>55059</td>\n",
       "      <td>921.80</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>55079</td>\n",
       "      <td>1072.60</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2184 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS     Rent  Year\n",
       "0    01073  1020.00  2014\n",
       "1    01117  1229.76  2014\n",
       "2    04003  1051.25  2014\n",
       "3    04013  1095.67  2014\n",
       "4    04019   928.55  2014\n",
       "..     ...      ...   ...\n",
       "307  53061  1924.69  2020\n",
       "308  53063  1146.72  2020\n",
       "309  55025  1506.96  2020\n",
       "310  55059   921.80  2020\n",
       "311  55079  1072.60  2020\n",
       "\n",
       "[2184 rows x 3 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rent = pd.concat([df_rent_14,df_rent_15,df_rent_16,df_rent_17,df_rent_18,df_rent_19,df_rent_20])\n",
    "df_rent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Businesses Data\n",
    "This dataset contains data on all businesses in the US at the County level, for years 2009-2018. The dataset is used below to get Food Retail data, which includes grocery stores, wholesalers, and restaraunts.<br>\n",
    "[Data Dictionary](https://www2.census.gov/programs-surveys/cbp/technical-documentation/records-layouts/2018_record_layouts/county-layout-2018.txt)<br>\n",
    "[Industry (naics) Conversion](https://www2.census.gov/programs-surveys/cbp/technical-documentation/reference/naics-descriptions/naics2017.txt)<br>\n",
    "\n",
    "**Source:** US Census Bureau [County Business Patterns](https://www.census.gov/programs-surveys/cbp/data/datasets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fipstate</th>\n",
       "      <th>fipscty</th>\n",
       "      <th>naics</th>\n",
       "      <th>empflag</th>\n",
       "      <th>emp_nf</th>\n",
       "      <th>emp</th>\n",
       "      <th>qp1_nf</th>\n",
       "      <th>qp1</th>\n",
       "      <th>ap_nf</th>\n",
       "      <th>ap</th>\n",
       "      <th>est</th>\n",
       "      <th>n1_4</th>\n",
       "      <th>n5_9</th>\n",
       "      <th>n10_19</th>\n",
       "      <th>n20_49</th>\n",
       "      <th>n50_99</th>\n",
       "      <th>n100_249</th>\n",
       "      <th>n250_499</th>\n",
       "      <th>n500_999</th>\n",
       "      <th>n1000</th>\n",
       "      <th>n1000_1</th>\n",
       "      <th>n1000_2</th>\n",
       "      <th>n1000_3</th>\n",
       "      <th>n1000_4</th>\n",
       "      <th>censtate</th>\n",
       "      <th>cencty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>------</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>10167</td>\n",
       "      <td>G</td>\n",
       "      <td>63783</td>\n",
       "      <td>G</td>\n",
       "      <td>273052</td>\n",
       "      <td>871</td>\n",
       "      <td>447</td>\n",
       "      <td>181</td>\n",
       "      <td>128</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11----</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>33</td>\n",
       "      <td>H</td>\n",
       "      <td>226</td>\n",
       "      <td>H</td>\n",
       "      <td>1097</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113///</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>27</td>\n",
       "      <td>G</td>\n",
       "      <td>188</td>\n",
       "      <td>G</td>\n",
       "      <td>945</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fipstate  fipscty   naics empflag emp_nf    emp qp1_nf    qp1 ap_nf      ap  est  n1_4  n5_9  n10_19  n20_49  n50_99  n100_249  n250_499  n500_999  n1000  n1000_1  n1000_2  n1000_3  n1000_4  censtate  cencty\n",
       "0         1        1  ------     NaN      G  10167      G  63783     G  273052  871   447   181     128      72      32         9         1         1      0        0        0        0        0        63       1\n",
       "1         1        1  11----     NaN      H     33      H    226     H    1097    6     3     2       1       0       0         0         0         0      0        0        0        0        0        63       1\n",
       "2         1        1  113///     NaN      G     27      G    188     G     945    5     3     1       1       0       0         0         0         0      0        0        0        0        0        63       1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business_09 = pd.read_csv('../datasets/businesses/bus_09.txt')\n",
    "df_business_10 = pd.read_csv('../datasets/businesses/bus_10.txt')\n",
    "df_business_11 = pd.read_csv('../datasets/businesses/bus_11.txt')\n",
    "df_business_12 = pd.read_csv('../datasets/businesses/bus_12.txt')\n",
    "df_business_13 = pd.read_csv('../datasets/businesses/bus_13.txt')\n",
    "df_business_14 = pd.read_csv('../datasets/businesses/bus_14.txt')\n",
    "df_business_15 = pd.read_csv('../datasets/businesses/bus_15.txt')\n",
    "df_business_16 = pd.read_csv('../datasets/businesses/bus_16.txt')\n",
    "df_business_17 = pd.read_csv('../datasets/businesses/bus_17.txt')\n",
    "df_business_18 = pd.read_csv('../datasets/businesses/bus_18.txt')\n",
    "\n",
    "# inspect features\n",
    "df_business_10.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unneeded columns and rename for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "df_business_09 = df_business_09.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_09 = df_business_09.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2010\n",
    "df_business_10 = df_business_10.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_10 = df_business_10.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2011\n",
    "df_business_11 = df_business_11.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_11 = df_business_11.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2012\n",
    "df_business_12 = df_business_12.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_12 = df_business_12.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2013\n",
    "df_business_13 = df_business_13.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_13 = df_business_13.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2014\n",
    "df_business_14 = df_business_14.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_14 = df_business_14.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2015\n",
    "df_business_15 = df_business_15.loc[:,['FIPSTATE', 'FIPSCTY', 'NAICS', 'EST']]\n",
    "df_business_15 = df_business_15.rename(columns={'FIPSTATE': 'FIPS_state', 'FIPSCTY':'FIPS_county', \n",
    "                                'NAICS':'Industry','EST':'Num_establishments'})\n",
    "# 2016\n",
    "df_business_16 = df_business_16.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_16 = df_business_16.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2017\n",
    "df_business_17 = df_business_17.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_17 = df_business_17.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2018\n",
    "df_business_18 = df_business_18.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_18 = df_business_18.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat FIPS codes and join together state+county codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add leading zeros to FIPS codes, and concat state and county FIPS codes\n",
    "# 2009\n",
    "df_business_09['FIPS_county'] = np.select([df_business_09['FIPS_county']<10, df_business_09['FIPS_county']<100],\n",
    "                    ['00'+df_business_09['FIPS_county'].astype(str), '0'+df_business_09['FIPS_county'].astype(str)],\n",
    "                    default= df_business_09['FIPS_county'].astype(str))\n",
    "df_business_09['FIPS_state'] = np.where(df_business_09['FIPS_state']<10, \n",
    "                        '0'+df_business_09['FIPS_state'].astype(str), df_business_09['FIPS_state'].astype(str))\n",
    "df_business_09['FIPS'] = df_business_09['FIPS_state'] + df_business_09['FIPS_county']\n",
    "\n",
    "# 2010\n",
    "df_business_10['FIPS_county'] = np.select([df_business_10['FIPS_county']<10, df_business_10['FIPS_county']<100],\n",
    "                    ['00'+df_business_10['FIPS_county'].astype(str), '0'+df_business_10['FIPS_county'].astype(str)],\n",
    "                    default= df_business_10['FIPS_county'].astype(str))\n",
    "df_business_10['FIPS_state'] = np.where(df_business_10['FIPS_state']<10, \n",
    "                        '0'+df_business_10['FIPS_state'].astype(str), df_business_10['FIPS_state'].astype(str))\n",
    "df_business_10['FIPS'] = df_business_10['FIPS_state'] + df_business_10['FIPS_county']\n",
    "\n",
    "# 2011\n",
    "df_business_11['FIPS_county'] = np.select([df_business_11['FIPS_county']<10, df_business_11['FIPS_county']<100],\n",
    "                    ['00'+df_business_11['FIPS_county'].astype(str), '0'+df_business_11['FIPS_county'].astype(str)],\n",
    "                    default= df_business_11['FIPS_county'].astype(str))\n",
    "df_business_11['FIPS_state'] = np.where(df_business_11['FIPS_state']<10, \n",
    "                        '0'+df_business_11['FIPS_state'].astype(str), df_business_11['FIPS_state'].astype(str))\n",
    "df_business_11['FIPS'] = df_business_11['FIPS_state'] + df_business_11['FIPS_county']\n",
    "\n",
    "# 2012\n",
    "df_business_12['FIPS_county'] = np.select([df_business_12['FIPS_county']<10, df_business_12['FIPS_county']<100],\n",
    "                    ['00'+df_business_12['FIPS_county'].astype(str), '0'+df_business_12['FIPS_county'].astype(str)],\n",
    "                    default= df_business_12['FIPS_county'].astype(str))\n",
    "df_business_12['FIPS_state'] = np.where(df_business_12['FIPS_state']<10, \n",
    "                        '0'+df_business_12['FIPS_state'].astype(str), df_business_12['FIPS_state'].astype(str))\n",
    "df_business_12['FIPS'] = df_business_12['FIPS_state'] + df_business_12['FIPS_county']\n",
    "\n",
    "# 2013\n",
    "df_business_13['FIPS_county'] = np.select([df_business_13['FIPS_county']<10, df_business_13['FIPS_county']<100],\n",
    "                    ['00'+df_business_13['FIPS_county'].astype(str), '0'+df_business_13['FIPS_county'].astype(str)],\n",
    "                    default= df_business_13['FIPS_county'].astype(str))\n",
    "df_business_13['FIPS_state'] = np.where(df_business_13['FIPS_state']<10, \n",
    "                        '0'+df_business_13['FIPS_state'].astype(str), df_business_13['FIPS_state'].astype(str))\n",
    "df_business_13['FIPS'] = df_business_13['FIPS_state'] + df_business_13['FIPS_county']\n",
    "\n",
    "# 2014\n",
    "df_business_14['FIPS_county'] = np.select([df_business_14['FIPS_county']<10, df_business_14['FIPS_county']<100],\n",
    "                    ['00'+df_business_14['FIPS_county'].astype(str), '0'+df_business_14['FIPS_county'].astype(str)],\n",
    "                    default= df_business_14['FIPS_county'].astype(str))\n",
    "df_business_14['FIPS_state'] = np.where(df_business_14['FIPS_state']<10, \n",
    "                        '0'+df_business_14['FIPS_state'].astype(str), df_business_14['FIPS_state'].astype(str))\n",
    "df_business_14['FIPS'] = df_business_14['FIPS_state'] + df_business_14['FIPS_county']\n",
    "\n",
    "# 2015\n",
    "df_business_15['FIPS_county'] = np.select([df_business_15['FIPS_county']<10, df_business_15['FIPS_county']<100],\n",
    "                    ['00'+df_business_15['FIPS_county'].astype(str), '0'+df_business_15['FIPS_county'].astype(str)],\n",
    "                    default= df_business_15['FIPS_county'].astype(str))\n",
    "df_business_15['FIPS_state'] = np.where(df_business_15['FIPS_state']<10, \n",
    "                        '0'+df_business_15['FIPS_state'].astype(str), df_business_15['FIPS_state'].astype(str))\n",
    "df_business_15['FIPS'] = df_business_15['FIPS_state'] + df_business_15['FIPS_county']\n",
    "\n",
    "# 2016\n",
    "df_business_16['FIPS_county'] = np.select([df_business_16['FIPS_county']<10, df_business_16['FIPS_county']<100],\n",
    "                    ['00'+df_business_16['FIPS_county'].astype(str), '0'+df_business_16['FIPS_county'].astype(str)],\n",
    "                    default= df_business_16['FIPS_county'].astype(str))\n",
    "df_business_16['FIPS_state'] = np.where(df_business_16['FIPS_state']<10, \n",
    "                        '0'+df_business_16['FIPS_state'].astype(str), df_business_16['FIPS_state'].astype(str))\n",
    "df_business_16['FIPS'] = df_business_16['FIPS_state'] + df_business_16['FIPS_county']\n",
    "\n",
    "# 2017\n",
    "df_business_17['FIPS_county'] = np.select([df_business_17['FIPS_county']<10, df_business_17['FIPS_county']<100],\n",
    "                    ['00'+df_business_17['FIPS_county'].astype(str), '0'+df_business_17['FIPS_county'].astype(str)],\n",
    "                    default= df_business_17['FIPS_county'].astype(str))\n",
    "df_business_17['FIPS_state'] = np.where(df_business_17['FIPS_state']<10, \n",
    "                        '0'+df_business_17['FIPS_state'].astype(str), df_business_17['FIPS_state'].astype(str))\n",
    "df_business_17['FIPS'] = df_business_17['FIPS_state'] + df_business_17['FIPS_county']\n",
    "\n",
    "# 2018\n",
    "df_business_18['FIPS_county'] = np.select([df_business_18['FIPS_county']<10, df_business_18['FIPS_county']<100],\n",
    "                    ['00'+df_business_18['FIPS_county'].astype(str), '0'+df_business_18['FIPS_county'].astype(str)],\n",
    "                    default= df_business_18['FIPS_county'].astype(str))\n",
    "df_business_18['FIPS_state'] = np.where(df_business_18['FIPS_state']<10, \n",
    "                        '0'+df_business_18['FIPS_state'].astype(str), df_business_18['FIPS_state'].astype(str))\n",
    "df_business_18['FIPS'] = df_business_18['FIPS_state'] + df_business_18['FIPS_county']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate rows for each type of food establishment\n",
    "Use the NAICS data dictionary to map industry codes to each type of food establishment. Food retailers are broken into three categories: Restaraunts, Wholesalers, and Grocery stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_09[df_business_09['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_09[df_business_09['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_09[df_business_09['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2010\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_10[df_business_10['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_10[df_business_10['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_10[df_business_10['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2011\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_11[df_business_11['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_11[df_business_11['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_11[df_business_11['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2012\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_12[df_business_12['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_12[df_business_12['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_12[df_business_12['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2013\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_13[df_business_13['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_13[df_business_13['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_13[df_business_13['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2014\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_14[df_business_14['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_14[df_business_14['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_14[df_business_14['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2015\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_15[df_business_15['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_15[df_business_15['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_15[df_business_15['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2016\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_16[df_business_16['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_16[df_business_16['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_16[df_business_16['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2017\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_17[df_business_17['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_17[df_business_17['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_17[df_business_17['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2018\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_18[df_business_18['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_18[df_business_18['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_18[df_business_18['Industry'].isin(wholesale)].index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive # of businesses in each county\n",
    "Group dataframe by type of establishment, and sum # of businesses in each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "restaraunt_df = df_business_09.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_09.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_09.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_09 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2010\n",
    "restaraunt_df = df_business_10.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_10.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_10.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_10 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2011\n",
    "restaraunt_df = df_business_11.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_11.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_11.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_11 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2012\n",
    "restaraunt_df = df_business_12.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_12.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_12.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_12 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2013\n",
    "restaraunt_df = df_business_13.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_13.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_13.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_13 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2014\n",
    "restaraunt_df = df_business_14.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_14.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_14.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_14 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2015\n",
    "restaraunt_df = df_business_15.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_15.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_15.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_15 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2016\n",
    "restaraunt_df = df_business_16.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_16.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_16.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_16 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2017\n",
    "restaraunt_df = df_business_17.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_17.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_17.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_17 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2018\n",
    "restaraunt_df = df_business_18.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_18.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_18.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_18 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Year column to each df and impute nulls with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_09['Year'] = '2009'\n",
    "df_food_09.fillna(0, inplace=True)\n",
    "df_food_10['Year'] = '2010'\n",
    "df_food_10.fillna(0, inplace=True)\n",
    "df_food_11['Year'] = '2011'\n",
    "df_food_11.fillna(0, inplace=True)\n",
    "df_food_12['Year'] = '2012'\n",
    "df_food_12.fillna(0, inplace=True)\n",
    "df_food_13['Year'] = '2013'\n",
    "df_food_13.fillna(0, inplace=True)\n",
    "df_food_14['Year'] = '2014'\n",
    "df_food_14.fillna(0, inplace=True)\n",
    "df_food_15['Year'] = '2015'\n",
    "df_food_15.fillna(0, inplace=True)\n",
    "df_food_16['Year'] = '2016'\n",
    "df_food_16.fillna(0, inplace=True)\n",
    "df_food_17['Year'] = '2017'\n",
    "df_food_17.fillna(0, inplace=True)\n",
    "df_food_18['Year'] = '2018'\n",
    "df_food_18.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate all df's to create master dataframe of all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Num_wholesale</th>\n",
       "      <th>Num_restaraunts</th>\n",
       "      <th>Num_grocery</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>71.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01007</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01009</td>\n",
       "      <td>19.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01013</td>\n",
       "      <td>13.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>29211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>46121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>48155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>51045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>51091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17976 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS  Num_wholesale  Num_restaraunts  Num_grocery  Year\n",
       "0     01001           71.0             13.0        109.0  2009\n",
       "1     01005            5.0              7.0        109.0  2009\n",
       "2     01007            3.0             21.0         92.0  2009\n",
       "3     01009           19.0             32.0        186.0  2009\n",
       "4     01013           13.0            106.0         29.0  2009\n",
       "...     ...            ...              ...          ...   ...\n",
       "3105  29211            0.0              0.0         18.0  2018\n",
       "3106  46121            0.0              0.0         12.0  2018\n",
       "3107  48155            0.0              0.0          3.0  2018\n",
       "3108  51045            0.0              0.0         14.0  2018\n",
       "3109  51091            0.0              0.0          7.0  2018\n",
       "\n",
       "[17976 rows x 5 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_food = pd.concat([df_food_09,df_food_10,df_food_11,df_food_12,df_food_13,df_food_14,df_food_15,\n",
    "          df_food_16,df_food_17,df_food_18])\n",
    "df_food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge together all dataframes\n",
    "After each of the seven datasets (df_rent,df_houseless, df_cps, df_demographics, df_unemployment, df_FA, and df_food) has been cleaned and uniformly formatted, they are merged together to create a main dataframe with all of the features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge rent and houseless dataframes together, using FIPS and Year\n",
    "merge1 = df_rent.merge(df_houseless, on=['FIPS','Year'],how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge demographics dataframe with previous merge, using FIPS and Year\n",
    "merge2 = merge1.merge(df_cps, on=['FIPS','Year'],how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge3 = merge2.merge(df_demographics, on=['FIPS','Year'],how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge unemployment dataframe with previous merge, using FIPS and Year\n",
    "merge4 = merge3.merge(df_unemployment, on=['FIPS','Year','FIPS_state','FIPS_county'],how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge food insecurity dataframe with previous merge, using FIPS and Year\n",
    "merge5 = merge4.merge(df_FA, on=['FIPS','Year'],how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge food retail dataframe with previous merge, using FIPS and Year\n",
    "df_all = merge5.merge(df_food, on=['FIPS','Year'],how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Rent</th>\n",
       "      <th>Year</th>\n",
       "      <th>coc_number</th>\n",
       "      <th>Houseless_rate</th>\n",
       "      <th>Sheltered_rate</th>\n",
       "      <th>Unsheltered_rate</th>\n",
       "      <th>hh_med_income</th>\n",
       "      <th>pop_disabled</th>\n",
       "      <th>pop_hs_grad</th>\n",
       "      <th>pop_bachelors</th>\n",
       "      <th>pop_grad_degree</th>\n",
       "      <th>pop_priv_health</th>\n",
       "      <th>pop_public_health</th>\n",
       "      <th>pop_no_health</th>\n",
       "      <th>pop_total</th>\n",
       "      <th>percent_hh_poverty</th>\n",
       "      <th>hh_avg_size</th>\n",
       "      <th>pop_65+</th>\n",
       "      <th>hh_no_vehicle</th>\n",
       "      <th>num_hh</th>\n",
       "      <th>pop_non_citizen</th>\n",
       "      <th>hh_SNAP</th>\n",
       "      <th>FIPS_state</th>\n",
       "      <th>FIPS_county</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>TOT_POP</th>\n",
       "      <th>TOT_MALE</th>\n",
       "      <th>TOT_FEMALE</th>\n",
       "      <th>TOT_WHITE</th>\n",
       "      <th>TOT_BLACK</th>\n",
       "      <th>TOT_NATIVE</th>\n",
       "      <th>TOT_ASIAN</th>\n",
       "      <th>TOT_PACIFIC</th>\n",
       "      <th>TOT_LATINX</th>\n",
       "      <th>State/County</th>\n",
       "      <th>Total_workforce</th>\n",
       "      <th>Employed</th>\n",
       "      <th>Unemployed</th>\n",
       "      <th>Unemployment_rate</th>\n",
       "      <th>FI Rate</th>\n",
       "      <th>Low Threshold Type</th>\n",
       "      <th>High Threshold Type</th>\n",
       "      <th>Cost Per Meal</th>\n",
       "      <th>Num_wholesale</th>\n",
       "      <th>Num_restaraunts</th>\n",
       "      <th>Num_grocery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01073</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>2014</td>\n",
       "      <td>AL-500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9.13e-03</td>\n",
       "      <td>4.13e-03</td>\n",
       "      <td>45239.0</td>\n",
       "      <td>94584.0</td>\n",
       "      <td>117854.0</td>\n",
       "      <td>81626.0</td>\n",
       "      <td>52774.0</td>\n",
       "      <td>4.32e+05</td>\n",
       "      <td>2.12e+05</td>\n",
       "      <td>81336.0</td>\n",
       "      <td>6.59e+05</td>\n",
       "      <td>14.8</td>\n",
       "      <td>2.48</td>\n",
       "      <td>87036.0</td>\n",
       "      <td>93630.0</td>\n",
       "      <td>2.59e+05</td>\n",
       "      <td>17519.0</td>\n",
       "      <td>39967.0</td>\n",
       "      <td>01</td>\n",
       "      <td>073</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Jefferson County</td>\n",
       "      <td>6.60e+05</td>\n",
       "      <td>3.12e+05</td>\n",
       "      <td>3.47e+05</td>\n",
       "      <td>3.56e+05</td>\n",
       "      <td>284082.0</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>10378.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>2.41e+04</td>\n",
       "      <td>Jefferson County, AL</td>\n",
       "      <td>3.1e+05</td>\n",
       "      <td>2.9e+05</td>\n",
       "      <td>2e+04</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>2.93</td>\n",
       "      <td>483.0</td>\n",
       "      <td>2693.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01117</td>\n",
       "      <td>1229.76</td>\n",
       "      <td>2014</td>\n",
       "      <td>AL-500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9.13e-03</td>\n",
       "      <td>4.13e-03</td>\n",
       "      <td>69723.0</td>\n",
       "      <td>22792.0</td>\n",
       "      <td>28911.0</td>\n",
       "      <td>35773.0</td>\n",
       "      <td>18511.0</td>\n",
       "      <td>1.60e+05</td>\n",
       "      <td>4.24e+04</td>\n",
       "      <td>19175.0</td>\n",
       "      <td>2.01e+05</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.65</td>\n",
       "      <td>23404.0</td>\n",
       "      <td>19762.0</td>\n",
       "      <td>7.48e+04</td>\n",
       "      <td>7624.0</td>\n",
       "      <td>4706.0</td>\n",
       "      <td>01</td>\n",
       "      <td>117</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Shelby County</td>\n",
       "      <td>2.06e+05</td>\n",
       "      <td>1.00e+05</td>\n",
       "      <td>1.06e+05</td>\n",
       "      <td>1.74e+05</td>\n",
       "      <td>24247.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>4403.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.19e+04</td>\n",
       "      <td>Shelby County, AL</td>\n",
       "      <td>1.1e+05</td>\n",
       "      <td>1e+05</td>\n",
       "      <td>4.8e+03</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04003</td>\n",
       "      <td>1051.25</td>\n",
       "      <td>2014</td>\n",
       "      <td>AZ-500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.85e-03</td>\n",
       "      <td>6.10e-03</td>\n",
       "      <td>45974.0</td>\n",
       "      <td>20341.0</td>\n",
       "      <td>21109.0</td>\n",
       "      <td>12968.0</td>\n",
       "      <td>7566.0</td>\n",
       "      <td>7.61e+04</td>\n",
       "      <td>5.05e+04</td>\n",
       "      <td>14868.0</td>\n",
       "      <td>1.31e+05</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2.47</td>\n",
       "      <td>23593.0</td>\n",
       "      <td>16328.0</td>\n",
       "      <td>4.88e+04</td>\n",
       "      <td>7947.0</td>\n",
       "      <td>7812.0</td>\n",
       "      <td>04</td>\n",
       "      <td>003</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Cochise County</td>\n",
       "      <td>1.27e+05</td>\n",
       "      <td>6.47e+04</td>\n",
       "      <td>6.27e+04</td>\n",
       "      <td>1.12e+05</td>\n",
       "      <td>5737.0</td>\n",
       "      <td>2165.0</td>\n",
       "      <td>2757.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>4.44e+04</td>\n",
       "      <td>Cochise County, AZ</td>\n",
       "      <td>5.1e+04</td>\n",
       "      <td>4.7e+04</td>\n",
       "      <td>4.3e+03</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>SNAP, Other Nutrition Programs</td>\n",
       "      <td>SNAP, Other Nutrition Programs</td>\n",
       "      <td>2.81</td>\n",
       "      <td>800.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04013</td>\n",
       "      <td>1095.67</td>\n",
       "      <td>2014</td>\n",
       "      <td>AZ-502</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.03e-02</td>\n",
       "      <td>2.23e-03</td>\n",
       "      <td>53689.0</td>\n",
       "      <td>399455.0</td>\n",
       "      <td>593094.0</td>\n",
       "      <td>490927.0</td>\n",
       "      <td>273108.0</td>\n",
       "      <td>2.44e+06</td>\n",
       "      <td>1.20e+06</td>\n",
       "      <td>646167.0</td>\n",
       "      <td>3.95e+06</td>\n",
       "      <td>12.7</td>\n",
       "      <td>2.74</td>\n",
       "      <td>507428.0</td>\n",
       "      <td>546028.0</td>\n",
       "      <td>1.42e+06</td>\n",
       "      <td>373532.0</td>\n",
       "      <td>171581.0</td>\n",
       "      <td>04</td>\n",
       "      <td>013</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa County</td>\n",
       "      <td>4.09e+06</td>\n",
       "      <td>2.02e+06</td>\n",
       "      <td>2.07e+06</td>\n",
       "      <td>3.45e+06</td>\n",
       "      <td>235660.0</td>\n",
       "      <td>112383.0</td>\n",
       "      <td>172425.0</td>\n",
       "      <td>11190.0</td>\n",
       "      <td>1.24e+06</td>\n",
       "      <td>Maricopa County, AZ</td>\n",
       "      <td>2e+06</td>\n",
       "      <td>1.8e+06</td>\n",
       "      <td>1.1e+05</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.16</td>\n",
       "      <td>SNAP, Other Nutrition Programs</td>\n",
       "      <td>SNAP, Other Nutrition Programs</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2389.0</td>\n",
       "      <td>16857.0</td>\n",
       "      <td>6320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04019</td>\n",
       "      <td>928.55</td>\n",
       "      <td>2014</td>\n",
       "      <td>AZ-501</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.62e-02</td>\n",
       "      <td>4.42e-03</td>\n",
       "      <td>46233.0</td>\n",
       "      <td>133694.0</td>\n",
       "      <td>149147.0</td>\n",
       "      <td>115392.0</td>\n",
       "      <td>81406.0</td>\n",
       "      <td>5.92e+05</td>\n",
       "      <td>3.65e+05</td>\n",
       "      <td>141211.0</td>\n",
       "      <td>9.93e+05</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>162075.0</td>\n",
       "      <td>149710.0</td>\n",
       "      <td>3.86e+05</td>\n",
       "      <td>69636.0</td>\n",
       "      <td>57099.0</td>\n",
       "      <td>04</td>\n",
       "      <td>019</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Pima County</td>\n",
       "      <td>1.00e+06</td>\n",
       "      <td>4.95e+05</td>\n",
       "      <td>5.10e+05</td>\n",
       "      <td>8.58e+05</td>\n",
       "      <td>41043.0</td>\n",
       "      <td>42683.0</td>\n",
       "      <td>31905.0</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>3.63e+05</td>\n",
       "      <td>Pima County, AZ</td>\n",
       "      <td>4.6e+05</td>\n",
       "      <td>4.4e+05</td>\n",
       "      <td>2.8e+04</td>\n",
       "      <td>6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>SNAP, Other Nutrition Programs</td>\n",
       "      <td>SNAP, Other Nutrition Programs</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>1604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85989</th>\n",
       "      <td>49999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85990</th>\n",
       "      <td>51999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85991</th>\n",
       "      <td>53999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85992</th>\n",
       "      <td>54999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85993</th>\n",
       "      <td>55999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85994 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        FIPS     Rent  Year coc_number  Houseless_rate  Sheltered_rate  Unsheltered_rate  hh_med_income  pop_disabled  pop_hs_grad  pop_bachelors  pop_grad_degree  pop_priv_health  pop_public_health  pop_no_health  pop_total  percent_hh_poverty  hh_avg_size   pop_65+  hh_no_vehicle    num_hh  pop_non_citizen   hh_SNAP FIPS_state FIPS_county    State            County   TOT_POP  TOT_MALE  TOT_FEMALE  TOT_WHITE  TOT_BLACK  TOT_NATIVE  TOT_ASIAN  TOT_PACIFIC  TOT_LATINX          State/County Total_workforce Employed Unemployed Unemployment_rate  FI Rate              Low Threshold Type             High Threshold Type  Cost Per Meal  Num_wholesale  Num_restaraunts  Num_grocery\n",
       "0      01073  1020.00  2014     AL-500            0.01        9.13e-03          4.13e-03        45239.0       94584.0     117854.0        81626.0          52774.0         4.32e+05           2.12e+05        81336.0   6.59e+05                14.8         2.48   87036.0        93630.0  2.59e+05          17519.0   39967.0         01         073  Alabama  Jefferson County  6.60e+05  3.12e+05    3.47e+05   3.56e+05   284082.0      2029.0    10378.0        347.0    2.41e+04  Jefferson County, AL         3.1e+05  2.9e+05      2e+04               6.3     0.20                            SNAP         Other Nutrition Program           2.93          483.0           2693.0        400.0\n",
       "1      01117  1229.76  2014     AL-500            0.01        9.13e-03          4.13e-03        69723.0       22792.0      28911.0        35773.0          18511.0         1.60e+05           4.24e+04        19175.0   2.01e+05                 6.2         2.65   23404.0        19762.0  7.48e+04           7624.0    4706.0         01         117  Alabama     Shelby County  2.06e+05  1.00e+05    1.06e+05   1.74e+05    24247.0       805.0     4403.0        101.0    1.19e+04     Shelby County, AL         1.1e+05    1e+05    4.8e+03               4.5     0.10                            SNAP         Other Nutrition Program           3.37            1.0            743.0       2706.0\n",
       "2      04003  1051.25  2014     AZ-500            0.01        7.85e-03          6.10e-03        45974.0       20341.0      21109.0        12968.0           7566.0         7.61e+04           5.05e+04        14868.0   1.31e+05                13.1         2.47   23593.0        16328.0  4.88e+04           7947.0    7812.0         04         003  Arizona    Cochise County  1.27e+05  6.47e+04    6.27e+04   1.12e+05     5737.0      2165.0     2757.0        510.0    4.44e+04    Cochise County, AZ         5.1e+04  4.7e+04    4.3e+03               8.4     0.16  SNAP, Other Nutrition Programs  SNAP, Other Nutrition Programs           2.81          800.0             72.0        340.0\n",
       "3      04013  1095.67  2014     AZ-502            0.01        1.03e-02          2.23e-03        53689.0      399455.0     593094.0       490927.0         273108.0         2.44e+06           1.20e+06       646167.0   3.95e+06                12.7         2.74  507428.0       546028.0  1.42e+06         373532.0  171581.0         04         013  Arizona   Maricopa County  4.09e+06  2.02e+06    2.07e+06   3.45e+06   235660.0    112383.0   172425.0      11190.0    1.24e+06   Maricopa County, AZ           2e+06  1.8e+06    1.1e+05               5.8     0.16  SNAP, Other Nutrition Programs  SNAP, Other Nutrition Programs           2.90         2389.0          16857.0       6320.0\n",
       "4      04019   928.55  2014     AZ-501            0.02        1.62e-02          4.42e-03        46233.0      133694.0     149147.0       115392.0          81406.0         5.92e+05           3.65e+05       141211.0   9.93e+05                13.2         2.50  162075.0       149710.0  3.86e+05          69636.0   57099.0         04         019  Arizona       Pima County  1.00e+06  4.95e+05    5.10e+05   8.58e+05    41043.0     42683.0    31905.0       2266.0    3.63e+05       Pima County, AZ         4.6e+05  4.4e+05    2.8e+04                 6     0.15  SNAP, Other Nutrition Programs  SNAP, Other Nutrition Programs           2.85         3591.0            838.0       1604.0\n",
       "...      ...      ...   ...        ...             ...             ...               ...            ...           ...          ...            ...              ...              ...                ...            ...        ...                 ...          ...       ...            ...       ...              ...       ...        ...         ...      ...               ...       ...       ...         ...        ...        ...         ...        ...          ...         ...                   ...             ...      ...        ...               ...      ...                             ...                             ...            ...            ...              ...          ...\n",
       "85989  49999      NaN  2018        NaN             NaN             NaN               NaN            NaN           NaN          NaN            NaN              NaN              NaN                NaN            NaN        NaN                 NaN          NaN       NaN            NaN       NaN              NaN       NaN        NaN         NaN      NaN               NaN       NaN       NaN         NaN        NaN        NaN         NaN        NaN          NaN         NaN                   NaN             NaN      NaN        NaN               NaN      NaN                             NaN                             NaN            NaN            5.0              0.0          0.0\n",
       "85990  51999      NaN  2018        NaN             NaN             NaN               NaN            NaN           NaN          NaN            NaN              NaN              NaN                NaN            NaN        NaN                 NaN          NaN       NaN            NaN       NaN              NaN       NaN        NaN         NaN      NaN               NaN       NaN       NaN         NaN        NaN        NaN         NaN        NaN          NaN         NaN                   NaN             NaN      NaN        NaN               NaN      NaN                             NaN                             NaN            NaN           16.0              0.0          0.0\n",
       "85991  53999      NaN  2018        NaN             NaN             NaN               NaN            NaN           NaN          NaN            NaN              NaN              NaN                NaN            NaN        NaN                 NaN          NaN       NaN            NaN       NaN              NaN       NaN        NaN         NaN      NaN               NaN       NaN       NaN         NaN        NaN        NaN         NaN        NaN          NaN         NaN                   NaN             NaN      NaN        NaN               NaN      NaN                             NaN                             NaN            NaN           16.0              0.0          0.0\n",
       "85992  54999      NaN  2018        NaN             NaN             NaN               NaN            NaN           NaN          NaN            NaN              NaN              NaN                NaN            NaN        NaN                 NaN          NaN       NaN            NaN       NaN              NaN       NaN        NaN         NaN      NaN               NaN       NaN       NaN         NaN        NaN        NaN         NaN        NaN          NaN         NaN                   NaN             NaN      NaN        NaN               NaN      NaN                             NaN                             NaN            NaN            4.0              0.0          0.0\n",
       "85993  55999      NaN  2018        NaN             NaN             NaN               NaN            NaN           NaN          NaN            NaN              NaN              NaN                NaN            NaN        NaN                 NaN          NaN       NaN            NaN       NaN              NaN       NaN        NaN         NaN      NaN               NaN       NaN       NaN         NaN        NaN        NaN         NaN        NaN          NaN         NaN                   NaN             NaN      NaN        NaN               NaN      NaN                             NaN                             NaN            NaN           13.0              0.0          0.0\n",
       "\n",
       "[85994 rows x 48 columns]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the cleaned dataset using Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../pickled/partially_cleaned_data.pickle', \"wb\") as output_file:\n",
    "    pickle.dump(df_all, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
