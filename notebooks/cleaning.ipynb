{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Cleaning\n",
    "## Projecting US Food Insecurity in 2020\n",
    "### By Khyatee Desai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "pd.set_option('display.max_rows', 10)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feeding America Datasets\n",
    "### Import all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../datasets/feeding_america/\"\n",
    "\n",
    "df_FA_09 = pd.read_excel(directory+'FA_2011_2009.xlsx')\n",
    "df_FA_10 = pd.read_excel(directory+'FA_2012_2010.xlsx')\n",
    "df_FA_11 = pd.read_excel(directory+'FA_2013_2011.xlsx')\n",
    "df_FA_12 = pd.read_excel(directory+'FA_2014_2012.xlsx')\n",
    "df_FA_13 = pd.read_excel(directory+'FA_2015_2013.xlsx')\n",
    "df_FA_14 = pd.read_excel(directory+'FA_2016_2014.xlsx')\n",
    "df_FA_15 = pd.read_excel(directory+'FA_2017_2015.xlsx')\n",
    "df_FA_16 = pd.read_excel(directory+'FA_2018_2016.xlsx')\n",
    "df_FA_17 = pd.read_excel(directory+'FA_2019_2017.xlsx')\n",
    "df_FA_18 = pd.read_excel(directory+'FA_2020_2018.xlsx',header=1)\n",
    "df_FAprojection_20 = pd.read_excel(directory+'projection_10.2020.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_FA_09 = df_FA_09.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "            '% FI Btwn Thresholds','% FI > High Threshold', '% of children in FI HH with HH incomes at or below 185% FPL',\n",
    "              'Number Food Insecure Children','% of children in FI HH with HH incomes above 185% FPL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_FA_10 = df_FA_10.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "              '% FI Btwn Thresholds', 'Number of Food Insecure Children in 2010 ',\n",
    "              '% FI > High Threshold', '% food insecure children in HH w/ HH incomes below 185 FPL',\n",
    "               '% of food insecure children in HH w/ HH incomes above 185 FPL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_11 = df_FA_11.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                          '% FI Btwn Thresholds', 'Number of Food Insecure Children in 2011',\n",
    "              '% FI > High Threshold', '% food insecure children in HH w/ HH incomes below 185 FPL',\n",
    "               '% of food insecure children in HH w/ HH incomes above 185 FPL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_12 = df_FA_12.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds','% FI > High Threshold', '# of Food Insecure Children in 2012',\n",
    "               '% food insecure Children in HH w/HH Incomes Below 185 FPL in 2012',\n",
    "               '% food insecure Children in HH w/HH Incomes Above 185 FPL in 2012'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_13 = df_FA_13.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds','% FI > High Threshold', '# of Food Insecure Children in 2013',\n",
    "               '% food insecure Children in HH w/HH Incomes Below 185 FPL in 2013',\n",
    "               '% food insecure Children in HH w/HH Incomes Above 185 FPL in 2013'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_14 = df_FA_14.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds', '% FI > High Threshold', '# of Food Insecure Children in 2014',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2014',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2014'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_15 = df_FA_15.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds','% FI > High Threshold', '# of Food Insecure Children in 2015',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2015',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2015'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_16 = df_FA_16.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds','% FI > High Threshold', '# of Food Insecure Children in 2016',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2016',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2016'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_17 = df_FA_17.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds', '% FI > High Threshold', '# of Food Insecure Children in 2017',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2017',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2017'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_FA_18 = df_FA_18.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds', '% FI > High Threshold', '# of Food Insecure Children in 2018',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2018',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2018'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat FIPS Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "# drop null rows at the end\n",
    "df_FA_09.drop(df_FA_09[df_FA_09['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "\n",
    "# change FIPS to string and add leading zeros if needed\n",
    "df_FA_09['FIPS'] = np.where(df_FA_09['FIPS']<10000, \n",
    "                        '0'+df_FA_09['FIPS'].astype(int).astype(str), df_FA_09['FIPS'].astype(int).astype(str))\n",
    "# 2011\n",
    "df_FA_11.drop(df_FA_11[df_FA_11['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_11['FIPS'] = np.where(df_FA_11['FIPS']<10000, \n",
    "                        '0'+df_FA_11['FIPS'].astype(int).astype(str), df_FA_11['FIPS'].astype(int).astype(str))\n",
    "# 2012\n",
    "df_FA_12.drop(df_FA_12[df_FA_12['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_12['FIPS'] = np.where(df_FA_12['FIPS']<10000, \n",
    "                        '0'+df_FA_12['FIPS'].astype(int).astype(str), df_FA_12['FIPS'].astype(int).astype(str))\n",
    "# 2013\n",
    "df_FA_13.drop(df_FA_13[df_FA_13['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_13['FIPS'] = np.where(df_FA_13['FIPS']<10000, \n",
    "                        '0'+df_FA_13['FIPS'].astype(int).astype(str), df_FA_13['FIPS'].astype(int).astype(str))\n",
    "# 2014\n",
    "df_FA_14.drop(df_FA_14[df_FA_14['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_14['FIPS'] = np.where(df_FA_14['FIPS']<10000, \n",
    "                        '0'+df_FA_14['FIPS'].astype(int).astype(str), df_FA_14['FIPS'].astype(int).astype(str))\n",
    "# 2015\n",
    "df_FA_15.drop(df_FA_15[df_FA_15['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_15['FIPS'] = np.where(df_FA_15['FIPS']<10000, \n",
    "                        '0'+df_FA_15['FIPS'].astype(int).astype(str), df_FA_15['FIPS'].astype(int).astype(str))\n",
    "# 2016\n",
    "df_FA_16.drop(df_FA_16[df_FA_16['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_16['FIPS'] = np.where(df_FA_16['FIPS']<10000, \n",
    "                        '0'+df_FA_16['FIPS'].astype(int).astype(str), df_FA_16['FIPS'].astype(int).astype(str))\n",
    "# 2017\n",
    "df_FA_17.drop(df_FA_17[df_FA_17['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_17['FIPS'] = np.where(df_FA_17['FIPS']<10000, \n",
    "                        '0'+df_FA_17['FIPS'].astype(int).astype(str), df_FA_17['FIPS'].astype(int).astype(str))\n",
    "# 2018\n",
    "df_FA_18.drop(df_FA_18[df_FA_18['FIPS'].isnull()].index, axis=0, inplace=True)\n",
    "df_FA_18['FIPS'] = np.where(df_FA_18['FIPS']<10000, \n",
    "                        '0'+df_FA_18['FIPS'].astype(int).astype(str), df_FA_18['FIPS'].astype(int).astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Year column to each df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_09['Year'] = '2009'\n",
    "df_FA_10['Year'] = '2010'\n",
    "df_FA_11['Year'] = '2011'\n",
    "df_FA_12['Year'] = '2012'\n",
    "df_FA_13['Year'] = '2013'\n",
    "df_FA_14['Year'] = '2014'\n",
    "df_FA_15['Year'] = '2015'\n",
    "df_FA_16['Year'] = '2016'\n",
    "df_FA_17['Year'] = '2017'\n",
    "df_FA_18['Year'] = '2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State</th>\n",
       "      <th>County, State</th>\n",
       "      <th>2017 Food Insecurity Rate</th>\n",
       "      <th># of Food Insecure Persons in 2017</th>\n",
       "      <th>Low Threshold Type</th>\n",
       "      <th>High Threshold Type</th>\n",
       "      <th>2017 Child food insecurity rate</th>\n",
       "      <th>2017 Cost Per Meal</th>\n",
       "      <th>2017 Weighted Annual Food Budget Shortfall</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>0.132</td>\n",
       "      <td>7270</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.198</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3957000</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01003</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin County, Alabama</td>\n",
       "      <td>0.116</td>\n",
       "      <td>23560</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.189</td>\n",
       "      <td>3.57</td>\n",
       "      <td>14361000</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01005</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour County, Alabama</td>\n",
       "      <td>0.220</td>\n",
       "      <td>5760</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.276</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3035000</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01007</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bibb County, Alabama</td>\n",
       "      <td>0.143</td>\n",
       "      <td>3240</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.221</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1684000</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01009</td>\n",
       "      <td>AL</td>\n",
       "      <td>Blount County, Alabama</td>\n",
       "      <td>0.107</td>\n",
       "      <td>6140</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.212</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3249000</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>56037</td>\n",
       "      <td>WY</td>\n",
       "      <td>Sweetwater County, Wyoming</td>\n",
       "      <td>0.107</td>\n",
       "      <td>4750</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.170</td>\n",
       "      <td>3.14</td>\n",
       "      <td>2542000</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>56039</td>\n",
       "      <td>WY</td>\n",
       "      <td>Teton County, Wyoming</td>\n",
       "      <td>0.097</td>\n",
       "      <td>2220</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.117</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1592000</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>56041</td>\n",
       "      <td>WY</td>\n",
       "      <td>Uinta County, Wyoming</td>\n",
       "      <td>0.128</td>\n",
       "      <td>2660</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.189</td>\n",
       "      <td>2.95</td>\n",
       "      <td>1340000</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>56043</td>\n",
       "      <td>WY</td>\n",
       "      <td>Washakie County, Wyoming</td>\n",
       "      <td>0.112</td>\n",
       "      <td>920</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.174</td>\n",
       "      <td>3.16</td>\n",
       "      <td>497000</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>56045</td>\n",
       "      <td>WY</td>\n",
       "      <td>Weston County, Wyoming</td>\n",
       "      <td>0.131</td>\n",
       "      <td>940</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.202</td>\n",
       "      <td>3.15</td>\n",
       "      <td>505000</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3142 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS State               County, State  2017 Food Insecurity Rate  \\\n",
       "0     01001    AL     Autauga County, Alabama                      0.132   \n",
       "1     01003    AL     Baldwin County, Alabama                      0.116   \n",
       "2     01005    AL     Barbour County, Alabama                      0.220   \n",
       "3     01007    AL        Bibb County, Alabama                      0.143   \n",
       "4     01009    AL      Blount County, Alabama                      0.107   \n",
       "...     ...   ...                         ...                        ...   \n",
       "3137  56037    WY  Sweetwater County, Wyoming                      0.107   \n",
       "3138  56039    WY       Teton County, Wyoming                      0.097   \n",
       "3139  56041    WY       Uinta County, Wyoming                      0.128   \n",
       "3140  56043    WY    Washakie County, Wyoming                      0.112   \n",
       "3141  56045    WY      Weston County, Wyoming                      0.131   \n",
       "\n",
       "      # of Food Insecure Persons in 2017 Low Threshold Type  \\\n",
       "0                                   7270               SNAP   \n",
       "1                                  23560               SNAP   \n",
       "2                                   5760               SNAP   \n",
       "3                                   3240               SNAP   \n",
       "4                                   6140               SNAP   \n",
       "...                                  ...                ...   \n",
       "3137                                4750               SNAP   \n",
       "3138                                2220               SNAP   \n",
       "3139                                2660               SNAP   \n",
       "3140                                 920               SNAP   \n",
       "3141                                 940               SNAP   \n",
       "\n",
       "          High Threshold Type  2017 Child food insecurity rate  \\\n",
       "0     Other Nutrition Program                            0.198   \n",
       "1     Other Nutrition Program                            0.189   \n",
       "2     Other Nutrition Program                            0.276   \n",
       "3     Other Nutrition Program                            0.221   \n",
       "4     Other Nutrition Program                            0.212   \n",
       "...                       ...                              ...   \n",
       "3137  Other Nutrition Program                            0.170   \n",
       "3138  Other Nutrition Program                            0.117   \n",
       "3139  Other Nutrition Program                            0.189   \n",
       "3140  Other Nutrition Program                            0.174   \n",
       "3141  Other Nutrition Program                            0.202   \n",
       "\n",
       "      2017 Cost Per Meal  2017 Weighted Annual Food Budget Shortfall  Year  \n",
       "0                   3.19                                     3957000  2017  \n",
       "1                   3.57                                    14361000  2017  \n",
       "2                   3.09                                     3035000  2017  \n",
       "3                   3.05                                     1684000  2017  \n",
       "4                   3.10                                     3249000  2017  \n",
       "...                  ...                                         ...   ...  \n",
       "3137                3.14                                     2542000  2017  \n",
       "3138                4.20                                     1592000  2017  \n",
       "3139                2.95                                     1340000  2017  \n",
       "3140                3.16                                      497000  2017  \n",
       "3141                3.15                                      505000  2017  \n",
       "\n",
       "[3142 rows x 11 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FA_17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Unemployment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../datasets/unemployment/\"\n",
    "\n",
    "df_unemp_09 = pd.read_excel(directory + 'laucnty09.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_10 = pd.read_excel(directory + 'laucnty10.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_11 = pd.read_excel(directory + 'laucnty11.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_12 = pd.read_excel(directory + 'laucnty12.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_13 = pd.read_excel(directory + 'laucnty13.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_14 = pd.read_excel(directory + 'laucnty14.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_15 = pd.read_excel(directory + 'laucnty15.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_16 = pd.read_excel(directory + 'laucnty16.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_17 = pd.read_excel(directory + 'laucnty17.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_18 = pd.read_excel(directory + 'laucnty18.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_19 = pd.read_excel(directory + 'laucnty19.xlsx', header=4).drop(0,axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns using data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_09.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_10.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_11.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_12.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_13.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_14.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_15.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_16.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_17.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_18.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_19.rename(columns = {'LAUS Code':'CN', 'Code':'FIPS_state', 'Code.1':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', \n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop null rows, drop some columns, and reformat year column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "# drop last three rows which were null\n",
    "df_unemp_09.drop(df_unemp_09[df_unemp_09['FIPS_state'].isnull()].index, inplace=True)\n",
    "# change year column to string\n",
    "df_unemp_09['Year'] = df_unemp_09['Year'].astype(int).astype(str)\n",
    "# drop unneeded columns\n",
    "df_unemp_09.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2010\n",
    "df_unemp_10.drop(df_unemp_10[df_unemp_10['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_10['Year'] = df_unemp_10['Year'].astype(int).astype(str)\n",
    "df_unemp_10.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2011\n",
    "df_unemp_11.drop(df_unemp_11[df_unemp_11['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_11['Year'] = df_unemp_11['Year'].astype(int).astype(str)\n",
    "df_unemp_11.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2012\n",
    "df_unemp_12.drop(df_unemp_12[df_unemp_12['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_12['Year'] = df_unemp_12['Year'].astype(int).astype(str)\n",
    "df_unemp_12.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2013\n",
    "df_unemp_13.drop(df_unemp_13[df_unemp_13['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_13['Year'] = df_unemp_13['Year'].astype(int).astype(str)\n",
    "df_unemp_13.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2014\n",
    "df_unemp_14.drop(df_unemp_14[df_unemp_14['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_14['Year'] = df_unemp_14['Year'].astype(int).astype(str)\n",
    "df_unemp_14.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2015\n",
    "df_unemp_15.drop(df_unemp_15[df_unemp_15['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_15['Year'] = df_unemp_15['Year'].astype(int).astype(str)\n",
    "df_unemp_15.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2016\n",
    "df_unemp_16.drop(df_unemp_16[df_unemp_16['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_16['Year'] = df_unemp_16['Year'].astype(int).astype(str)\n",
    "df_unemp_16.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2017\n",
    "df_unemp_17.drop(df_unemp_17[df_unemp_17['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_17['Year'] = df_unemp_17['Year'].astype(int).astype(str)\n",
    "df_unemp_17.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2018\n",
    "df_unemp_18.drop(df_unemp_18[df_unemp_18['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_18['Year'] = df_unemp_18['Year'].astype(int).astype(str)\n",
    "df_unemp_18.drop(['CN', 'idk'], axis=1, inplace=True)\n",
    "\n",
    "# 2019\n",
    "# drop last three rows which were null\n",
    "df_unemp_19.drop(df_unemp_19[df_unemp_19['FIPS_state'].isnull()].index, inplace=True)\n",
    "df_unemp_19.drop(['CN'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat FIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2009\n",
    "# add leading zeros to FIPS codes and convert to string\n",
    "df_unemp_09['FIPS_county'] = np.select([df_unemp_09['FIPS_county']<10, df_unemp_09['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_09['FIPS_county'].astype(int).astype(str), '0'+df_unemp_09['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_09['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_09['FIPS_state'] = np.where(df_unemp_09['FIPS_state']<10, \n",
    "                        '0'+df_unemp_09['FIPS_state'].astype(int).astype(str), df_unemp_09['FIPS_state'].astype(int).astype(str))\n",
    "# Create main fips code\n",
    "df_unemp_09['FIPS'] = df_unemp_09['FIPS_state'] + df_unemp_09['FIPS_county']\n",
    "\n",
    "# 2010\n",
    "df_unemp_10['FIPS_county'] = np.select([df_unemp_10['FIPS_county']<10, df_unemp_10['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_10['FIPS_county'].astype(int).astype(str), '0'+df_unemp_10['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_10['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_10['FIPS_state'] = np.where(df_unemp_10['FIPS_state']<10, \n",
    "                        '0'+df_unemp_10['FIPS_state'].astype(int).astype(str), df_unemp_10['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_10['FIPS'] = df_unemp_10['FIPS_state'] + df_unemp_10['FIPS_county']\n",
    "\n",
    "# 2011\n",
    "df_unemp_11['FIPS_county'] = np.select([df_unemp_11['FIPS_county']<10, df_unemp_11['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_11['FIPS_county'].astype(int).astype(str), '0'+df_unemp_11['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_11['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_11['FIPS_state'] = np.where(df_unemp_11['FIPS_state']<10, \n",
    "                        '0'+df_unemp_11['FIPS_state'].astype(int).astype(str), df_unemp_11['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_11['FIPS'] = df_unemp_11['FIPS_state'] + df_unemp_11['FIPS_county']\n",
    "\n",
    "# 2012\n",
    "df_unemp_12['FIPS_county'] = np.select([df_unemp_12['FIPS_county']<10, df_unemp_12['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_12['FIPS_county'].astype(int).astype(str), '0'+df_unemp_12['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_12['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_12['FIPS_state'] = np.where(df_unemp_12['FIPS_state']<10, \n",
    "                        '0'+df_unemp_12['FIPS_state'].astype(int).astype(str), df_unemp_12['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_12['FIPS'] = df_unemp_12['FIPS_state'] + df_unemp_12['FIPS_county']\n",
    "\n",
    "# 2013\n",
    "df_unemp_13['FIPS_county'] = np.select([df_unemp_13['FIPS_county']<10, df_unemp_13['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_13['FIPS_county'].astype(int).astype(str), '0'+df_unemp_13['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_13['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_13['FIPS_state'] = np.where(df_unemp_13['FIPS_state']<10, \n",
    "                        '0'+df_unemp_13['FIPS_state'].astype(int).astype(str), df_unemp_13['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_13['FIPS'] = df_unemp_13['FIPS_state'] + df_unemp_13['FIPS_county']\n",
    "\n",
    "# 2014\n",
    "df_unemp_14['FIPS_county'] = np.select([df_unemp_14['FIPS_county']<10, df_unemp_14['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_14['FIPS_county'].astype(int).astype(str), '0'+df_unemp_14['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_14['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_14['FIPS_state'] = np.where(df_unemp_14['FIPS_state']<10, \n",
    "                        '0'+df_unemp_14['FIPS_state'].astype(int).astype(str), df_unemp_14['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_14['FIPS'] = df_unemp_14['FIPS_state'] + df_unemp_14['FIPS_county']\n",
    "\n",
    "# 2015\n",
    "df_unemp_15['FIPS_county'] = np.select([df_unemp_15['FIPS_county']<10, df_unemp_15['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_15['FIPS_county'].astype(int).astype(str), '0'+df_unemp_15['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_15['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_15['FIPS_state'] = np.where(df_unemp_15['FIPS_state']<10, \n",
    "                        '0'+df_unemp_15['FIPS_state'].astype(int).astype(str), df_unemp_15['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_15['FIPS'] = df_unemp_15['FIPS_state'] + df_unemp_15['FIPS_county']\n",
    "\n",
    "# 2016\n",
    "df_unemp_16['FIPS_county'] = np.select([df_unemp_16['FIPS_county']<10, df_unemp_16['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_16['FIPS_county'].astype(int).astype(str), '0'+df_unemp_16['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_16['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_16['FIPS_state'] = np.where(df_unemp_16['FIPS_state']<10, \n",
    "                        '0'+df_unemp_16['FIPS_state'].astype(int).astype(str), df_unemp_16['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_16['FIPS'] = df_unemp_16['FIPS_state'] + df_unemp_16['FIPS_county']\n",
    "\n",
    "# 2017\n",
    "df_unemp_17['FIPS_county'] = np.select([df_unemp_17['FIPS_county']<10, df_unemp_17['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_17['FIPS_county'].astype(int).astype(str), '0'+df_unemp_17['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_17['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_17['FIPS_state'] = np.where(df_unemp_17['FIPS_state']<10, \n",
    "                        '0'+df_unemp_17['FIPS_state'].astype(int).astype(str), df_unemp_17['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_17['FIPS'] = df_unemp_17['FIPS_state'] + df_unemp_17['FIPS_county']\n",
    "\n",
    "# 2018\n",
    "df_unemp_18['FIPS_county'] = np.select([df_unemp_18['FIPS_county']<10, df_unemp_18['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_18['FIPS_county'].astype(int).astype(str), '0'+df_unemp_18['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_18['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_18['FIPS_state'] = np.where(df_unemp_18['FIPS_state']<10, \n",
    "                        '0'+df_unemp_18['FIPS_state'].astype(int).astype(str), df_unemp_18['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_18['FIPS'] = df_unemp_18['FIPS_state'] + df_unemp_18['FIPS_county']\n",
    "\n",
    "# 2019\n",
    "df_unemp_19['FIPS_county'] = np.select([df_unemp_19['FIPS_county']<10, df_unemp_19['FIPS_county']<100],\n",
    "                    ['00'+df_unemp_19['FIPS_county'].astype(int).astype(str), '0'+df_unemp_19['FIPS_county'].astype(int).astype(str)],\n",
    "                    default= df_unemp_19['FIPS_county'].astype(int).astype(str))\n",
    "df_unemp_19['FIPS_state'] = np.where(df_unemp_19['FIPS_state']<10, \n",
    "                        '0'+df_unemp_19['FIPS_state'].astype(int).astype(str), df_unemp_19['FIPS_state'].astype(int).astype(str))\n",
    "df_unemp_19['FIPS'] = df_unemp_19['FIPS_state'] + df_unemp_19['FIPS_county']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break down 2019 dataset into 2019 and 2020 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add year column for each, derived from Period column, and then drop period column\n",
    "df_unemp_20 = df_unemp_19[df_unemp_19['Period'].str.contains('20')]\n",
    "df_unemp_20['Year'] = '2020'\n",
    "df_unemp_20.drop('Period', axis=1, inplace=True)\n",
    "\n",
    "df_unemp_19 = df_unemp_19[df_unemp_19['Period'].str.contains('19')]\n",
    "df_unemp_19['Year'] = '2019'\n",
    "df_unemp_19.drop('Period', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_state</th>\n",
       "      <th>FIPS_county</th>\n",
       "      <th>State/County</th>\n",
       "      <th>Total_workforce</th>\n",
       "      <th>Employed</th>\n",
       "      <th>Unemployed</th>\n",
       "      <th>Unemployment_rate</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12877</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Autauga County, AL</td>\n",
       "      <td>25912</td>\n",
       "      <td>25125</td>\n",
       "      <td>787</td>\n",
       "      <td>3</td>\n",
       "      <td>01001</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12878</th>\n",
       "      <td>01</td>\n",
       "      <td>003</td>\n",
       "      <td>Baldwin County, AL</td>\n",
       "      <td>95316</td>\n",
       "      <td>92389</td>\n",
       "      <td>2927</td>\n",
       "      <td>3.1</td>\n",
       "      <td>01003</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12879</th>\n",
       "      <td>01</td>\n",
       "      <td>005</td>\n",
       "      <td>Barbour County, AL</td>\n",
       "      <td>8509</td>\n",
       "      <td>8186</td>\n",
       "      <td>323</td>\n",
       "      <td>3.8</td>\n",
       "      <td>01005</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12880</th>\n",
       "      <td>01</td>\n",
       "      <td>007</td>\n",
       "      <td>Bibb County, AL</td>\n",
       "      <td>8629</td>\n",
       "      <td>8342</td>\n",
       "      <td>287</td>\n",
       "      <td>3.3</td>\n",
       "      <td>01007</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12881</th>\n",
       "      <td>01</td>\n",
       "      <td>009</td>\n",
       "      <td>Blount County, AL</td>\n",
       "      <td>25098</td>\n",
       "      <td>24352</td>\n",
       "      <td>746</td>\n",
       "      <td>3</td>\n",
       "      <td>01009</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45062</th>\n",
       "      <td>72</td>\n",
       "      <td>145</td>\n",
       "      <td>Vega Baja Municipio, PR</td>\n",
       "      <td>12543</td>\n",
       "      <td>11146</td>\n",
       "      <td>1397</td>\n",
       "      <td>11.1</td>\n",
       "      <td>72145</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45063</th>\n",
       "      <td>72</td>\n",
       "      <td>147</td>\n",
       "      <td>Vieques Municipio, PR</td>\n",
       "      <td>2386</td>\n",
       "      <td>2133</td>\n",
       "      <td>253</td>\n",
       "      <td>10.6</td>\n",
       "      <td>72147</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45064</th>\n",
       "      <td>72</td>\n",
       "      <td>149</td>\n",
       "      <td>Villalba Municipio, PR</td>\n",
       "      <td>6603</td>\n",
       "      <td>5969</td>\n",
       "      <td>634</td>\n",
       "      <td>9.6</td>\n",
       "      <td>72149</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45065</th>\n",
       "      <td>72</td>\n",
       "      <td>151</td>\n",
       "      <td>Yabucoa Municipio, PR</td>\n",
       "      <td>7961</td>\n",
       "      <td>7168</td>\n",
       "      <td>793</td>\n",
       "      <td>10</td>\n",
       "      <td>72151</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45066</th>\n",
       "      <td>72</td>\n",
       "      <td>153</td>\n",
       "      <td>Yauco Municipio, PR</td>\n",
       "      <td>9250</td>\n",
       "      <td>8321</td>\n",
       "      <td>929</td>\n",
       "      <td>10</td>\n",
       "      <td>72153</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32190 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS_state FIPS_county             State/County Total_workforce  \\\n",
       "12877         01         001       Autauga County, AL           25912   \n",
       "12878         01         003       Baldwin County, AL           95316   \n",
       "12879         01         005       Barbour County, AL            8509   \n",
       "12880         01         007          Bibb County, AL            8629   \n",
       "12881         01         009        Blount County, AL           25098   \n",
       "...          ...         ...                      ...             ...   \n",
       "45062         72         145  Vega Baja Municipio, PR           12543   \n",
       "45063         72         147    Vieques Municipio, PR            2386   \n",
       "45064         72         149   Villalba Municipio, PR            6603   \n",
       "45065         72         151    Yabucoa Municipio, PR            7961   \n",
       "45066         72         153      Yauco Municipio, PR            9250   \n",
       "\n",
       "      Employed Unemployed Unemployment_rate   FIPS  Year  \n",
       "12877    25125        787                 3  01001  2020  \n",
       "12878    92389       2927               3.1  01003  2020  \n",
       "12879     8186        323               3.8  01005  2020  \n",
       "12880     8342        287               3.3  01007  2020  \n",
       "12881    24352        746                 3  01009  2020  \n",
       "...        ...        ...               ...    ...   ...  \n",
       "45062    11146       1397              11.1  72145  2020  \n",
       "45063     2133        253              10.6  72147  2020  \n",
       "45064     5969        634               9.6  72149  2020  \n",
       "45065     7168        793                10  72151  2020  \n",
       "45066     8321        929                10  72153  2020  \n",
       "\n",
       "[32190 rows x 9 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unemp_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CPS Data (2019 &2020)\n",
    "data dict 2019: https://www2.census.gov/programs-surveys/cps/techdocs/cpsmar19.pdf<br>\n",
    "data dict 2020: https://www2.census.gov/programs-surveys/cps/datasets/2020/march/ASEC2020ddl_pub_full.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household_19 = pd.read_csv('../datasets/household/hhpub19.csv')\n",
    "df_household_20 = pd.read_csv('../datasets/household/hhpub20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map column values to data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np.select to map values on 2019 data\n",
    "conditions=[df_household_19['GTMETSTA'] ==1,df_household_19['GTMETSTA'] ==2, df_household_19['GTMETSTA'] ==3]\n",
    "choices = ['HH_Metrop', 'HH_Non-Metrop','N/A']\n",
    "df_household_19['GTMETSTA'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_19['H_TENURE'] ==0,df_household_19['H_TENURE'] ==1,df_household_19['H_TENURE'] ==2, df_household_19['H_TENURE'] ==3]\n",
    "choices = ['N/A', 'HH_owned', 'HH_rented','HH_rented_noCash']\n",
    "df_household_19['H_TENURE'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_19['HDIS_YN'] ==0,df_household_19['HDIS_YN'] ==1,df_household_19['HDIS_YN'] ==2]\n",
    "choices = ['N/A',  'HH_disabled','HH_not_disabled' ]\n",
    "df_household_19['HDIS_YN'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_19['HCSP_YN'] ==0,df_household_19['HCSP_YN'] ==1,df_household_19['HCSP_YN'] ==2]\n",
    "choices = ['N/A','HH_Child_support', 'HH_no_child_support' ]\n",
    "df_household_19['HCSP_YN'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_19['HINC_UC'] ==0,df_household_19['HINC_UC'] ==1,df_household_19['HINC_UC'] ==2]\n",
    "choices = ['N/A','HH_unemployment_pay', 'HH_no_unemployment_pay' ]\n",
    "df_household_19['HINC_UC'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_19['NOW_HCOV'] ==1,df_household_19['NOW_HCOV'] ==2,df_household_19['NOW_HCOV'] ==3]\n",
    "choices = [ 'HH_health_insured','HH_some_health_insured','HH_no_health_insured' ]\n",
    "df_household_19['NOW_HCOV'] = np.select(conditions, choices,default='N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np.select to map values on 2020 data\n",
    "conditions=[df_household_20['GTMETSTA'] ==1,df_household_20['GTMETSTA'] ==2, df_household_20['GTMETSTA'] ==3]\n",
    "choices = ['HH_Metrop', 'HH_Non-Metrop','N/A']\n",
    "df_household_20['GTMETSTA'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['H_TENURE'] ==0,df_household_20['H_TENURE'] ==1,df_household_20['H_TENURE'] ==2, df_household_20['H_TENURE'] ==3]\n",
    "choices = ['N/A', 'HH_owned', 'HH_rented','HH_rented_noCash']\n",
    "df_household_20['H_TENURE'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['HDIS_YN'] ==0,df_household_20['HDIS_YN'] ==1,df_household_20['HDIS_YN'] ==2]\n",
    "choices = ['N/A',  'HH_disabled','HH_not_disabled' ]\n",
    "df_household_20['HDIS_YN'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['HCSP_YN'] ==0,df_household_20['HCSP_YN'] ==1,df_household_20['HCSP_YN'] ==2]\n",
    "choices = ['N/A','HH_Child_support', 'HH_no_child_support' ]\n",
    "df_household_20['HCSP_YN'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['HINC_UC'] ==0,df_household_20['HINC_UC'] ==1,df_household_20['HINC_UC'] ==2]\n",
    "choices = ['N/A','HH_unemployment_pay', 'HH_no_unemployment_pay' ]\n",
    "df_household_20['HINC_UC'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['NOW_HCOV'] ==1,df_household_20['NOW_HCOV'] ==2,df_household_20['NOW_HCOV'] ==3]\n",
    "choices = [ 'HH_health_insured','HH_some_health_insured','HH_no_health_insured' ]\n",
    "df_household_20['NOW_HCOV'] = np.select(conditions, choices,default='N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 2019 data\n",
    "df_household_19 = df_household_19.loc[:,['GESTFIPS', 'GTCO', 'GTMETSTA', 'HTOTVAL','H_NUMPER', 'HUNDER18',\n",
    "                 'H_TENURE','HDIS_YN', 'HCSP_YN', 'HINC_UC','NOW_HCOV']]\n",
    "df_household_19 = df_household_19.rename(columns={'GESTFIPS':'FIPS_state', 'GTCO':'FIPS_county', 'GTMETSTA':'Metro_status',\n",
    "                               'HEFAMINC':'HH_income', \n",
    "                                'H_NUMPER':'HH_size', 'HUNDER18':'Num_minors','H_TENURE':'Rent_vs_Owned',\n",
    "                               'HDIS_YN':'Disability', 'HCSP_YN':'Child_support', 'HINC_UC':'Unemployment_payments',\n",
    "                               'NOW_HCOV':'Health_insurance'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename 2020 data\n",
    "df_household_20 = df_household_20.loc[:,['GESTFIPS', 'GTCO', 'GTMETSTA', 'HTOTVAL','H_NUMPER', 'HUNDER18',\n",
    "                 'H_TENURE','HDIS_YN', 'HCSP_YN', 'HINC_UC','NOW_HCOV']]\n",
    "df_household_20 = df_household_20.rename(columns={'GESTFIPS':'FIPS_state', 'GTCO':'FIPS_county', 'GTMETSTA':'Metro_status',\n",
    "                               'HEFAMINC':'HH_income', \n",
    "                                'H_NUMPER':'HH_size', 'HUNDER18':'Num_minors','H_TENURE':'Rent_vs_Owned',\n",
    "                               'HDIS_YN':'Disability', 'HCSP_YN':'Child_support', 'HINC_UC':'Unemployment_payments',\n",
    "                               'NOW_HCOV':'Health_insurance'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_state</th>\n",
       "      <th>FIPS_county</th>\n",
       "      <th>Metro_status</th>\n",
       "      <th>HTOTVAL</th>\n",
       "      <th>HH_size</th>\n",
       "      <th>Num_minors</th>\n",
       "      <th>Rent_vs_Owned</th>\n",
       "      <th>Disability</th>\n",
       "      <th>Child_support</th>\n",
       "      <th>Unemployment_payments</th>\n",
       "      <th>Health_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>127449</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>64680</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>40002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>8424</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_rented</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>59114</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91495</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>HH_Metrop</td>\n",
       "      <td>40700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91496</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>HH_Metrop</td>\n",
       "      <td>20421</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_rented_noCash</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91497</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>HH_Metrop</td>\n",
       "      <td>72455</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_some_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91498</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>HH_Metrop</td>\n",
       "      <td>13626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_rented</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91499</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>HH_Metrop</td>\n",
       "      <td>121101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91500 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS_state  FIPS_county   Metro_status  HTOTVAL  HH_size  Num_minors  \\\n",
       "0              23            0  HH_Non-Metrop   127449        2           0   \n",
       "1              23            0  HH_Non-Metrop    64680        2           0   \n",
       "2              23            0  HH_Non-Metrop    40002        1           0   \n",
       "3              23            0  HH_Non-Metrop     8424        2           0   \n",
       "4              23            0  HH_Non-Metrop    59114        4           0   \n",
       "...           ...          ...            ...      ...      ...         ...   \n",
       "91495          15            3      HH_Metrop    40700        1           0   \n",
       "91496          15            3      HH_Metrop    20421        1           0   \n",
       "91497          15            3      HH_Metrop    72455        2           0   \n",
       "91498          15            3      HH_Metrop    13626        1           0   \n",
       "91499          15            3      HH_Metrop   121101        2           1   \n",
       "\n",
       "          Rent_vs_Owned       Disability        Child_support  \\\n",
       "0              HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "1              HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "2              HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "3             HH_rented  HH_not_disabled  HH_no_child_support   \n",
       "4              HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "...                 ...              ...                  ...   \n",
       "91495          HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "91496  HH_rented_noCash  HH_not_disabled  HH_no_child_support   \n",
       "91497          HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "91498         HH_rented  HH_not_disabled  HH_no_child_support   \n",
       "91499          HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "\n",
       "        Unemployment_payments        Health_insurance  \n",
       "0      HH_no_unemployment_pay       HH_health_insured  \n",
       "1      HH_no_unemployment_pay       HH_health_insured  \n",
       "2      HH_no_unemployment_pay       HH_health_insured  \n",
       "3      HH_no_unemployment_pay       HH_health_insured  \n",
       "4      HH_no_unemployment_pay       HH_health_insured  \n",
       "...                       ...                     ...  \n",
       "91495  HH_no_unemployment_pay       HH_health_insured  \n",
       "91496  HH_no_unemployment_pay       HH_health_insured  \n",
       "91497  HH_no_unemployment_pay  HH_some_health_insured  \n",
       "91498  HH_no_unemployment_pay       HH_health_insured  \n",
       "91499  HH_no_unemployment_pay       HH_health_insured  \n",
       "\n",
       "[91500 rows x 11 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_household_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Demographic Data\n",
    "Data Dict: https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2010-2019/cc-est2019-alldata.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_demographics = pd.read_csv('../datasets/demographics/demographics.csv',encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map categorical variables to values from data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics = df_demographics.loc[:,['STATE', 'COUNTY', 'STNAME', 'CTYNAME', 'YEAR', 'AGEGRP', 'TOT_POP','TOT_MALE', 'TOT_FEMALE',\n",
    "    'WA_MALE','WA_FEMALE','BA_MALE','BA_FEMALE','IA_MALE','IA_FEMALE','AA_MALE','AA_FEMALE','NA_MALE','NA_FEMALE']]\n",
    "\n",
    "conditions=[((df_demographics['YEAR'] ==1) | (df_demographics['YEAR'] ==2) | (df_demographics['YEAR'] ==3)),\n",
    "            df_demographics['YEAR'] ==4, df_demographics['YEAR'] ==5, df_demographics['YEAR'] ==6, \n",
    "            df_demographics['YEAR'] ==7, df_demographics['YEAR'] ==8, df_demographics['YEAR'] ==9,\n",
    "            df_demographics['YEAR'] ==10, df_demographics['YEAR'] ==11, df_demographics['YEAR'] ==12]\n",
    "choices = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "df_demographics['YEAR'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_demographics['AGEGRP'] ==0, df_demographics['AGEGRP'] ==1, df_demographics['AGEGRP'] ==2, df_demographics['AGEGRP'] ==3,\n",
    "            df_demographics['AGEGRP'] ==4, df_demographics['AGEGRP'] ==5, df_demographics['AGEGRP'] ==6, \n",
    "            df_demographics['AGEGRP'] ==7, df_demographics['AGEGRP'] ==8, df_demographics['AGEGRP'] ==9,\n",
    "            df_demographics['AGEGRP'] ==10, df_demographics['AGEGRP'] ==11, df_demographics['AGEGRP'] ==12,\n",
    "           df_demographics['AGEGRP'] ==13, df_demographics['AGEGRP'] ==14, df_demographics['AGEGRP'] ==15,\n",
    "           df_demographics['AGEGRP'] ==16, df_demographics['AGEGRP'] ==17, df_demographics['AGEGRP'] ==18]\n",
    "choices = ['All Ages', 'Age 0 to 4 years', 'Age 5 to 9 years', 'Age 10 to 14 years', 'Age 15 to 19 years', \n",
    "           'Age 20 to 24 years', 'Age 25 to 29 years', 'Age 30 to 34 years', 'Age 35 to 39 years', \n",
    "           'Age 40 to 44 years', 'Age 45 to 49 years', 'Age 50 to 54 years', 'Age 55 to 59 years',\n",
    "           'Age 60 to 64 years', 'Age 65 to 69 years', 'Age 70 to 74 years', 'Age 75 to 79 years',\n",
    "            'Age 80 to 84 years', 'Age 85+']\n",
    "df_demographics['AGEGRP'] = np.select(conditions, choices,default='N/A')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new columns for totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics['TOT_WHITE'] = df_demographics['WA_MALE'] + df_demographics['WA_FEMALE']\n",
    "df_demographics['TOT_BLACK'] = df_demographics['BA_MALE'] + df_demographics['BA_FEMALE']\n",
    "df_demographics['TOT_NATIVE'] = df_demographics['IA_MALE'] + df_demographics['IA_FEMALE']\n",
    "df_demographics['TOT_ASIAN'] = df_demographics['AA_MALE'] + df_demographics['AA_FEMALE']\n",
    "df_demographics['TOT_PACIFIC'] = df_demographics['NA_MALE'] + df_demographics['NA_FEMALE']\n",
    "\n",
    "# drop unnecessary cols\n",
    "df_demographics.drop(['WA_MALE','WA_FEMALE','BA_MALE','BA_FEMALE','IA_MALE','IA_FEMALE',\n",
    "                      'AA_MALE','AA_FEMALE','NA_MALE','NA_FEMALE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics.rename(columns={'STATE':'FIPS_state', 'COUNTY':'FIPS_county', 'STNAME': 'State', 'CTYNAME':'County'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix format of FIPS columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_state</th>\n",
       "      <th>FIPS_county</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>AGEGRP</th>\n",
       "      <th>TOT_POP</th>\n",
       "      <th>TOT_MALE</th>\n",
       "      <th>TOT_FEMALE</th>\n",
       "      <th>TOT_WHITE</th>\n",
       "      <th>TOT_BLACK</th>\n",
       "      <th>TOT_NATIVE</th>\n",
       "      <th>TOT_ASIAN</th>\n",
       "      <th>TOT_PACIFIC</th>\n",
       "      <th>FIPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>54571</td>\n",
       "      <td>26569</td>\n",
       "      <td>28002</td>\n",
       "      <td>43297</td>\n",
       "      <td>9689</td>\n",
       "      <td>258</td>\n",
       "      <td>484</td>\n",
       "      <td>47</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>Age 0 to 4 years</td>\n",
       "      <td>3579</td>\n",
       "      <td>1866</td>\n",
       "      <td>1713</td>\n",
       "      <td>2727</td>\n",
       "      <td>679</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>Age 5 to 9 years</td>\n",
       "      <td>3991</td>\n",
       "      <td>2001</td>\n",
       "      <td>1990</td>\n",
       "      <td>3047</td>\n",
       "      <td>773</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>Age 10 to 14 years</td>\n",
       "      <td>4290</td>\n",
       "      <td>2171</td>\n",
       "      <td>2119</td>\n",
       "      <td>3278</td>\n",
       "      <td>837</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>Age 15 to 19 years</td>\n",
       "      <td>4290</td>\n",
       "      <td>2213</td>\n",
       "      <td>2077</td>\n",
       "      <td>3213</td>\n",
       "      <td>926</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716371</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2019</td>\n",
       "      <td>Age 65 to 69 years</td>\n",
       "      <td>499</td>\n",
       "      <td>280</td>\n",
       "      <td>219</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716372</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2019</td>\n",
       "      <td>Age 70 to 74 years</td>\n",
       "      <td>352</td>\n",
       "      <td>180</td>\n",
       "      <td>172</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716373</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2019</td>\n",
       "      <td>Age 75 to 79 years</td>\n",
       "      <td>229</td>\n",
       "      <td>107</td>\n",
       "      <td>122</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716374</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2019</td>\n",
       "      <td>Age 80 to 84 years</td>\n",
       "      <td>198</td>\n",
       "      <td>82</td>\n",
       "      <td>116</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716375</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2019</td>\n",
       "      <td>Age 85+</td>\n",
       "      <td>200</td>\n",
       "      <td>72</td>\n",
       "      <td>128</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716376 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS_state FIPS_county    State          County  YEAR  \\\n",
       "0              01         001  Alabama  Autauga County  2010   \n",
       "1              01         001  Alabama  Autauga County  2010   \n",
       "2              01         001  Alabama  Autauga County  2010   \n",
       "3              01         001  Alabama  Autauga County  2010   \n",
       "4              01         001  Alabama  Autauga County  2010   \n",
       "...           ...         ...      ...             ...   ...   \n",
       "716371         56         045  Wyoming   Weston County  2019   \n",
       "716372         56         045  Wyoming   Weston County  2019   \n",
       "716373         56         045  Wyoming   Weston County  2019   \n",
       "716374         56         045  Wyoming   Weston County  2019   \n",
       "716375         56         045  Wyoming   Weston County  2019   \n",
       "\n",
       "                    AGEGRP  TOT_POP  TOT_MALE  TOT_FEMALE  TOT_WHITE  \\\n",
       "0                 All Ages    54571     26569       28002      43297   \n",
       "1         Age 0 to 4 years     3579      1866        1713       2727   \n",
       "2         Age 5 to 9 years     3991      2001        1990       3047   \n",
       "3       Age 10 to 14 years     4290      2171        2119       3278   \n",
       "4       Age 15 to 19 years     4290      2213        2077       3213   \n",
       "...                    ...      ...       ...         ...        ...   \n",
       "716371  Age 65 to 69 years      499       280         219        459   \n",
       "716372  Age 70 to 74 years      352       180         172        342   \n",
       "716373  Age 75 to 79 years      229       107         122        225   \n",
       "716374  Age 80 to 84 years      198        82         116        195   \n",
       "716375             Age 85+      200        72         128        195   \n",
       "\n",
       "        TOT_BLACK  TOT_NATIVE  TOT_ASIAN  TOT_PACIFIC   FIPS  \n",
       "0            9689         258        484           47  01001  \n",
       "1             679           8         28            1  01001  \n",
       "2             773          22         38            4  01001  \n",
       "3             837          27         41            5  01001  \n",
       "4             926          19         39            6  01001  \n",
       "...           ...         ...        ...          ...    ...  \n",
       "716371          1           2         31            0  56045  \n",
       "716372          0           2          4            0  56045  \n",
       "716373          0           2          0            0  56045  \n",
       "716374          0           2          0            0  56045  \n",
       "716375          0           2          1            0  56045  \n",
       "\n",
       "[716376 rows x 15 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics['FIPS_county'] = np.select([df_demographics['FIPS_county']<10, df_demographics['FIPS_county']<100],\n",
    "                    ['00'+df_demographics['FIPS_county'].astype(str), '0'+df_demographics['FIPS_county'].astype(str)],\n",
    "                    default= df_demographics['FIPS_county'].astype(str))\n",
    "df_demographics['FIPS_state'] = np.where(df_demographics['FIPS_state']<10, \n",
    "                        '0'+df_demographics['FIPS_state'].astype(str), df_demographics['FIPS_state'].astype(str))\n",
    "\n",
    "# Create main fips code\n",
    "df_demographics['FIPS'] = df_demographics['FIPS_state'] + df_demographics['FIPS_county']\n",
    "df_demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Houselessness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_houseless_19 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2019')\n",
    "df_houseless_18 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2018')\n",
    "df_houseless_17 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2017')\n",
    "df_houseless_16 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2016')\n",
    "df_houseless_15 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2015')\n",
    "df_houseless_14 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2014')\n",
    "df_houseless_13 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2013')\n",
    "df_houseless_12 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2012')\n",
    "df_houseless_11 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2011')\n",
    "df_houseless_10 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2010')\n",
    "df_houseless_09 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2009')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim down unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houseless_19 = df_houseless_19.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2019', 'Sheltered Total Homeless, 2019', 'Unsheltered Homeless, 2019']]\n",
    "df_houseless_18 = df_houseless_18.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2018', 'Sheltered Total Homeless, 2018', 'Unsheltered Homeless, 2018']]\n",
    "df_houseless_17 = df_houseless_17.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2017', 'Sheltered Total Homeless, 2017', 'Unsheltered Homeless, 2017']]\n",
    "df_houseless_16 = df_houseless_16.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2016', 'Sheltered Total Homeless, 2016', 'Unsheltered Homeless, 2016']]\n",
    "df_houseless_15 = df_houseless_15.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2015', 'Sheltered Total Homeless, 2015', 'Unsheltered Homeless, 2015']]\n",
    "df_houseless_14 = df_houseless_14.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2014', 'Sheltered Total Homeless, 2014', 'Unsheltered Homeless, 2014']]\n",
    "df_houseless_13 = df_houseless_13.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2013', 'Sheltered Total Homeless, 2013', 'Unsheltered Homeless, 2013']]\n",
    "df_houseless_12 = df_houseless_12.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2012', 'Sheltered Total Homeless, 2012', 'Unsheltered Homeless, 2012']]\n",
    "df_houseless_11 = df_houseless_11.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2011', 'Sheltered Total Homeless, 2011', 'Unsheltered Homeless, 2011']]\n",
    "df_houseless_10 = df_houseless_10.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2010', 'Sheltered Total Homeless, 2010', 'Unsheltered Homeless, 2010']]\n",
    "df_houseless_09 = df_houseless_09.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2009', 'Sheltered Total Homeless, 2009', 'Unsheltered Homeless, 2009']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houseless_19.rename(columns={'Overall Homeless, 2019':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2019': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2019': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_18.rename(columns={'Overall Homeless, 2018':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2018': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2018': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_17.rename(columns={'Overall Homeless, 2017':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2017': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2017': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_16.rename(columns={'Overall Homeless, 2016':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2016': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2016': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_15.rename(columns={'Overall Homeless, 2015':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2015': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2015': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_14.rename(columns={'Overall Homeless, 2014':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2014': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2014': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_13.rename(columns={'Overall Homeless, 2013':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2013': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2013': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_12.rename(columns={'Overall Homeless, 2012':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2012': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2012': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_11.rename(columns={'Overall Homeless, 2011':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2011': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2011': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_10.rename(columns={'Overall Homeless, 2010':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2010': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2010': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_09.rename(columns={'Overall Homeless, 2009':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2009': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2009': 'Unsheltered_houseless'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Subtask: Map CoC's to Counties\n",
    "Method: merge CoC column to demographics df to get population perCoC.<br>\n",
    "Join that with houseless df to derive houseless rate per CoC.<br>\n",
    "Join that to CoC_county to get houseless rate per county.<br>\n",
    "(optional) Join rates back with demographic df to get number of houseless, per county<br>\n",
    "Source: https://github.com/tomhbyrne/HUD-CoC-Geography-Crosswalk/blob/master/output/county_coc_match.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import csv that maps counties to a CoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoC_county = pd.read_csv('../datasets/houseless/county_coc_match.csv', encoding='ISO-8859-1')\n",
    "CoC_county = CoC_county.loc[:,['county_fips','coc_number']]\n",
    "\n",
    "# rename columns\n",
    "CoC_county.rename(columns={'county_fips':'FIPS'}, inplace=True)\n",
    "\n",
    "# drop 2 rows with no FIPS\n",
    "CoC_county.drop(CoC_county[CoC_county['FIPS'].isnull()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix format of FIPS column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change FIPS to string and add leading zeros if needed\n",
    "CoC_county['FIPS'] = np.where(CoC_county['FIPS']<10000, \n",
    "                        '0'+CoC_county['FIPS'].astype(int).astype(str), CoC_county['FIPS'].astype(int).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge CoC mapping with demographics df to get population count per CoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get total population by county\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2010') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "# merge with CoC_county to get pop count per CoC\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_10 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# repeat for each year\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2011') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_11 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2012\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2012') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_12 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2013\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2013') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_13 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2014\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2014') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_14 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2015\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2015') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_15 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2016\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2016') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_16 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2017\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2017') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_17 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2018\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2018') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_18 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2019\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2019') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_19 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge population count per CoC with houselessness df to derive houselessness rate per CoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get houseless rate per CoC \n",
    "# 2010\n",
    "merged = pop_per_coc_10.merge(df_houseless_10, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_10 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2011\n",
    "merged = pop_per_coc_11.merge(df_houseless_11, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_11 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2012\n",
    "merged = pop_per_coc_12.merge(df_houseless_12, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_12 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2013\n",
    "merged = pop_per_coc_13.merge(df_houseless_13, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_13 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2014\n",
    "merged = pop_per_coc_14.merge(df_houseless_14, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_14 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2015\n",
    "merged = pop_per_coc_15.merge(df_houseless_15, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_15 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2016\n",
    "merged = pop_per_coc_16.merge(df_houseless_16, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_16 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2017\n",
    "merged = pop_per_coc_17.merge(df_houseless_17, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_17 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2018\n",
    "merged = pop_per_coc_18.merge(df_houseless_18, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_18 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2019\n",
    "merged = pop_per_coc_19.merge(df_houseless_19, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_19 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge CoC rates with CoC_county mapping to get houseless rates per county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get houseless rate per county, for each year\n",
    "df_houseless_10 = rates_10.merge(CoC_county, on='coc_number')\n",
    "df_houseless_11 = rates_11.merge(CoC_county, on='coc_number')\n",
    "df_houseless_12 = rates_12.merge(CoC_county, on='coc_number')\n",
    "df_houseless_13 = rates_13.merge(CoC_county, on='coc_number')\n",
    "df_houseless_14 = rates_14.merge(CoC_county, on='coc_number')\n",
    "df_houseless_15 = rates_15.merge(CoC_county, on='coc_number')\n",
    "df_houseless_16 = rates_16.merge(CoC_county, on='coc_number')\n",
    "df_houseless_17 = rates_17.merge(CoC_county, on='coc_number')\n",
    "df_houseless_18 = rates_18.merge(CoC_county, on='coc_number')\n",
    "df_houseless_19 = rates_19.merge(CoC_county, on='coc_number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Year column to each df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coc_number</th>\n",
       "      <th>Houseless_rate</th>\n",
       "      <th>Sheltered_rate</th>\n",
       "      <th>Unsheltered_rate</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK-500</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>02020</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>02013</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>02016</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>02050</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>02060</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>56037</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>56039</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>56041</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>56043</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>56045</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3158 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coc_number  Houseless_rate  Sheltered_rate  Unsheltered_rate   FIPS  Year\n",
       "0        AK-500        0.003411        0.003234          0.000177  02020  2014\n",
       "1        AK-501        0.001744        0.001533          0.000211  02013  2014\n",
       "2        AK-501        0.001744        0.001533          0.000211  02016  2014\n",
       "3        AK-501        0.001744        0.001533          0.000211  02050  2014\n",
       "4        AK-501        0.001744        0.001533          0.000211  02060  2014\n",
       "...         ...             ...             ...               ...    ...   ...\n",
       "3153     WY-500        0.001300        0.000966          0.000333  56037  2014\n",
       "3154     WY-500        0.001300        0.000966          0.000333  56039  2014\n",
       "3155     WY-500        0.001300        0.000966          0.000333  56041  2014\n",
       "3156     WY-500        0.001300        0.000966          0.000333  56043  2014\n",
       "3157     WY-500        0.001300        0.000966          0.000333  56045  2014\n",
       "\n",
       "[3158 rows x 6 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_houseless_10['Year'] = '2010'\n",
    "df_houseless_11['Year'] = '2011'\n",
    "df_houseless_12['Year'] = '2012'\n",
    "df_houseless_13['Year'] = '2013'\n",
    "df_houseless_14['Year'] = '2014'\n",
    "df_houseless_15['Year'] = '2015'\n",
    "df_houseless_16['Year'] = '2016'\n",
    "df_houseless_17['Year'] = '2017'\n",
    "df_houseless_18['Year'] = '2018'\n",
    "df_houseless_19['Year'] = '2019'\n",
    "df_houseless_14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Rent Prices\n",
    "Zillow Observed Rent Index (ZORI): A smoothed measure of the typical observed market rate rent across a given region. ZORI is a repeat-rent index that is weighted to the rental housing stock to ensure representativeness across the entire market, not just those homes currently listed for-rent. The index is dollar-denominated by computing the mean of listed rents that fall into the 40th to 60th percentile range for all homes and apartments in a given region, which is once again weighted to reflect the rental housing stock. Details available in ZORI methodology.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take averages of months in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Zillow dataset\n",
    "df_rent = pd.read_csv('../datasets/rent_prices/rent_prices.csv')\n",
    "\n",
    "# isolate columns corresponding to each year, and make new column\n",
    "drop_14 = df_rent.columns[df_rent.columns.str.contains('2014')]\n",
    "df_rent['2014'] = df_rent.loc[:,drop_14].mean(axis=1)\n",
    "\n",
    "drop_15 = df_rent.columns[df_rent.columns.str.contains('2015')]\n",
    "df_rent['2015'] = df_rent.loc[:,drop_15].mean(axis=1)\n",
    "\n",
    "drop_16 = df_rent.columns[df_rent.columns.str.contains('2016')]\n",
    "df_rent['2016'] = df_rent.loc[:,drop_16].mean(axis=1)\n",
    "\n",
    "drop_17 = df_rent.columns[df_rent.columns.str.contains('2017')]\n",
    "df_rent['2017'] = df_rent.loc[:,drop_17].mean(axis=1)\n",
    "\n",
    "drop_18 = df_rent.columns[df_rent.columns.str.contains('2018')]\n",
    "df_rent['2018'] = df_rent.loc[:,drop_18].mean(axis=1)\n",
    "\n",
    "drop_19 = df_rent.columns[df_rent.columns.str.contains('2019')]\n",
    "df_rent['2019'] = df_rent.loc[:,drop_19].mean(axis=1)\n",
    "\n",
    "drop_20 = df_rent.columns[df_rent.columns.str.contains('2020')]\n",
    "df_rent['2020'] = df_rent.loc[:,drop_20].mean(axis=1)\n",
    "\n",
    "# drop all monthly data \n",
    "to_drop = drop_14.append(drop_15).append(drop_16).append(drop_17).append(drop_18).append(drop_19).append(drop_20)\n",
    "df_rent.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rent.rename(columns={'RegionName':'Zipcode', 'MsaName':'City/State'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask: Map Zipcodes to Counties\n",
    "Method: join county data to each zipcode, then groupby county and take mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zips = pd.read_csv('../datasets/rent_prices/uszips.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Zipcode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns and rename some\n",
    "zips =zips.loc[:,['zip', 'lat', 'lng','county_fips']]\n",
    "zips.rename(columns={'zip': 'Zipcode', 'county_fips': 'FIPS'},inplace=True)\n",
    "\n",
    "# add leading zero to FIPS values where needed\n",
    "zips['FIPS'] = np.where(zips['FIPS']<10000, \n",
    "                        '0'+zips['FIPS'].astype(str), zips['FIPS'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = df_rent.merge(zips, on='Zipcode', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01073</td>\n",
       "      <td>1019.995960</td>\n",
       "      <td>1049.230909</td>\n",
       "      <td>1070.125758</td>\n",
       "      <td>1090.527273</td>\n",
       "      <td>1127.700000</td>\n",
       "      <td>1165.383333</td>\n",
       "      <td>1199.082222</td>\n",
       "      <td>33.508132</td>\n",
       "      <td>-86.754922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01117</td>\n",
       "      <td>1229.755051</td>\n",
       "      <td>1265.133333</td>\n",
       "      <td>1282.000000</td>\n",
       "      <td>1296.611111</td>\n",
       "      <td>1333.997475</td>\n",
       "      <td>1380.585859</td>\n",
       "      <td>1416.266667</td>\n",
       "      <td>33.280850</td>\n",
       "      <td>-86.721547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04003</td>\n",
       "      <td>1051.250000</td>\n",
       "      <td>1047.458333</td>\n",
       "      <td>1035.083333</td>\n",
       "      <td>1033.000000</td>\n",
       "      <td>1084.791667</td>\n",
       "      <td>1151.583333</td>\n",
       "      <td>1217.494444</td>\n",
       "      <td>31.535215</td>\n",
       "      <td>-110.189590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04013</td>\n",
       "      <td>1095.670228</td>\n",
       "      <td>1164.839760</td>\n",
       "      <td>1224.381957</td>\n",
       "      <td>1274.524778</td>\n",
       "      <td>1349.587550</td>\n",
       "      <td>1443.687661</td>\n",
       "      <td>1537.921840</td>\n",
       "      <td>33.499874</td>\n",
       "      <td>-112.038614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04019</td>\n",
       "      <td>928.546429</td>\n",
       "      <td>947.020635</td>\n",
       "      <td>974.154497</td>\n",
       "      <td>1015.562169</td>\n",
       "      <td>1070.978307</td>\n",
       "      <td>1135.423696</td>\n",
       "      <td>1206.153817</td>\n",
       "      <td>32.212688</td>\n",
       "      <td>-110.936371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>53061</td>\n",
       "      <td>1390.782323</td>\n",
       "      <td>1490.695286</td>\n",
       "      <td>1610.368754</td>\n",
       "      <td>1717.006818</td>\n",
       "      <td>1793.825455</td>\n",
       "      <td>1868.800000</td>\n",
       "      <td>1924.686667</td>\n",
       "      <td>47.930571</td>\n",
       "      <td>-122.181536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>53063</td>\n",
       "      <td>808.358297</td>\n",
       "      <td>844.682540</td>\n",
       "      <td>900.673160</td>\n",
       "      <td>959.858225</td>\n",
       "      <td>1031.226190</td>\n",
       "      <td>1086.455318</td>\n",
       "      <td>1146.716667</td>\n",
       "      <td>47.680049</td>\n",
       "      <td>-117.399160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>55025</td>\n",
       "      <td>1280.044444</td>\n",
       "      <td>1348.669913</td>\n",
       "      <td>1388.861111</td>\n",
       "      <td>1418.138889</td>\n",
       "      <td>1437.537879</td>\n",
       "      <td>1468.611111</td>\n",
       "      <td>1506.958333</td>\n",
       "      <td>43.055933</td>\n",
       "      <td>-89.425323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>55059</td>\n",
       "      <td>689.000000</td>\n",
       "      <td>695.400000</td>\n",
       "      <td>741.272727</td>\n",
       "      <td>782.416667</td>\n",
       "      <td>818.416667</td>\n",
       "      <td>872.100000</td>\n",
       "      <td>921.800000</td>\n",
       "      <td>42.622560</td>\n",
       "      <td>-87.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>55079</td>\n",
       "      <td>968.360000</td>\n",
       "      <td>986.251818</td>\n",
       "      <td>997.403333</td>\n",
       "      <td>1009.583333</td>\n",
       "      <td>1024.450000</td>\n",
       "      <td>1049.133333</td>\n",
       "      <td>1072.595556</td>\n",
       "      <td>43.053424</td>\n",
       "      <td>-87.916406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS         2014         2015         2016         2017         2018  \\\n",
       "0    01073  1019.995960  1049.230909  1070.125758  1090.527273  1127.700000   \n",
       "1    01117  1229.755051  1265.133333  1282.000000  1296.611111  1333.997475   \n",
       "2    04003  1051.250000  1047.458333  1035.083333  1033.000000  1084.791667   \n",
       "3    04013  1095.670228  1164.839760  1224.381957  1274.524778  1349.587550   \n",
       "4    04019   928.546429   947.020635   974.154497  1015.562169  1070.978307   \n",
       "..     ...          ...          ...          ...          ...          ...   \n",
       "307  53061  1390.782323  1490.695286  1610.368754  1717.006818  1793.825455   \n",
       "308  53063   808.358297   844.682540   900.673160   959.858225  1031.226190   \n",
       "309  55025  1280.044444  1348.669913  1388.861111  1418.138889  1437.537879   \n",
       "310  55059   689.000000   695.400000   741.272727   782.416667   818.416667   \n",
       "311  55079   968.360000   986.251818   997.403333  1009.583333  1024.450000   \n",
       "\n",
       "            2019         2020        lat         lng  \n",
       "0    1165.383333  1199.082222  33.508132  -86.754922  \n",
       "1    1380.585859  1416.266667  33.280850  -86.721547  \n",
       "2    1151.583333  1217.494444  31.535215 -110.189590  \n",
       "3    1443.687661  1537.921840  33.499874 -112.038614  \n",
       "4    1135.423696  1206.153817  32.212688 -110.936371  \n",
       "..           ...          ...        ...         ...  \n",
       "307  1868.800000  1924.686667  47.930571 -122.181536  \n",
       "308  1086.455318  1146.716667  47.680049 -117.399160  \n",
       "309  1468.611111  1506.958333  43.055933  -89.425323  \n",
       "310   872.100000   921.800000  42.622560  -87.830000  \n",
       "311  1049.133333  1072.595556  43.053424  -87.916406  \n",
       "\n",
       "[312 rows x 10 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rent = merged.groupby('FIPS').mean().drop(['RegionID', 'Zipcode', 'SizeRank'],axis=1).reset_index()\n",
    "df_rent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break down into separate df's by year, and add year column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014\n",
    "# isolate relevant columns, rename, and creat year column\n",
    "df_rent_14 = df_rent[['FIPS', '2014', 'lat','lng']]\n",
    "df_rent_14.rename(columns={'2014':'Rent'}, inplace=True)\n",
    "df_rent_14['Year'] = '2014'\n",
    "\n",
    "# 2015\n",
    "df_rent_15 = df_rent[['FIPS', '2015', 'lat','lng']]\n",
    "df_rent_15.rename(columns={'2015':'Rent'}, inplace=True)\n",
    "df_rent_15['Year'] = '2015'\n",
    "\n",
    "# 2016\n",
    "df_rent_16 = df_rent[['FIPS', '2016', 'lat','lng']]\n",
    "df_rent_16.rename(columns={'2016':'Rent'}, inplace=True)\n",
    "df_rent_16['Year'] = '2016'\n",
    "\n",
    "# 2016\n",
    "df_rent_16 = df_rent[['FIPS', '2016', 'lat','lng']]\n",
    "df_rent_16.rename(columns={'2016':'Rent'}, inplace=True)\n",
    "df_rent_16['Year'] = '2016'\n",
    "\n",
    "# 2017\n",
    "df_rent_17 = df_rent[['FIPS', '2017', 'lat','lng']]\n",
    "df_rent_17.rename(columns={'2017':'Rent'}, inplace=True)\n",
    "df_rent_17['Year'] = '2017'\n",
    "\n",
    "# 2018\n",
    "df_rent_18 = df_rent[['FIPS', '2018', 'lat','lng']]\n",
    "df_rent_18.rename(columns={'2018':'Rent'}, inplace=True)\n",
    "df_rent_18['Year'] = '2018'\n",
    "\n",
    "# 2019\n",
    "df_rent_19 = df_rent[['FIPS', '2019', 'lat','lng']]\n",
    "df_rent_19.rename(columns={'2019':'Rent'}, inplace=True)\n",
    "df_rent_19['Year'] = '2019'\n",
    "\n",
    "# 2020\n",
    "df_rent_20 = df_rent[['FIPS', '2020', 'lat','lng']]\n",
    "df_rent_20.rename(columns={'2020':'Rent'}, inplace=True)\n",
    "df_rent_20['Year'] = '2020'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Rent</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01073</td>\n",
       "      <td>1199.082222</td>\n",
       "      <td>33.508132</td>\n",
       "      <td>-86.754922</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01117</td>\n",
       "      <td>1416.266667</td>\n",
       "      <td>33.280850</td>\n",
       "      <td>-86.721547</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04003</td>\n",
       "      <td>1217.494444</td>\n",
       "      <td>31.535215</td>\n",
       "      <td>-110.189590</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04013</td>\n",
       "      <td>1537.921840</td>\n",
       "      <td>33.499874</td>\n",
       "      <td>-112.038614</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04019</td>\n",
       "      <td>1206.153817</td>\n",
       "      <td>32.212688</td>\n",
       "      <td>-110.936371</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>53061</td>\n",
       "      <td>1924.686667</td>\n",
       "      <td>47.930571</td>\n",
       "      <td>-122.181536</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>53063</td>\n",
       "      <td>1146.716667</td>\n",
       "      <td>47.680049</td>\n",
       "      <td>-117.399160</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>55025</td>\n",
       "      <td>1506.958333</td>\n",
       "      <td>43.055933</td>\n",
       "      <td>-89.425323</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>55059</td>\n",
       "      <td>921.800000</td>\n",
       "      <td>42.622560</td>\n",
       "      <td>-87.830000</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>55079</td>\n",
       "      <td>1072.595556</td>\n",
       "      <td>43.053424</td>\n",
       "      <td>-87.916406</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS         Rent        lat         lng  Year\n",
       "0    01073  1199.082222  33.508132  -86.754922  2020\n",
       "1    01117  1416.266667  33.280850  -86.721547  2020\n",
       "2    04003  1217.494444  31.535215 -110.189590  2020\n",
       "3    04013  1537.921840  33.499874 -112.038614  2020\n",
       "4    04019  1206.153817  32.212688 -110.936371  2020\n",
       "..     ...          ...        ...         ...   ...\n",
       "307  53061  1924.686667  47.930571 -122.181536  2020\n",
       "308  53063  1146.716667  47.680049 -117.399160  2020\n",
       "309  55025  1506.958333  43.055933  -89.425323  2020\n",
       "310  55059   921.800000  42.622560  -87.830000  2020\n",
       "311  55079  1072.595556  43.053424  -87.916406  2020\n",
       "\n",
       "[312 rows x 5 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rent_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Businesses Data\n",
    "Data Dict: https://www2.census.gov/programs-surveys/cbp/technical-documentation/records-layouts/2018_record_layouts/county-layout-2018.txt\n",
    "<br>\n",
    "naics dict: https://www2.census.gov/programs-surveys/cbp/technical-documentation/reference/naics-descriptions/naics2017.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business_09 = pd.read_csv('../datasets/businesses/bus_09.txt')\n",
    "df_business_10 = pd.read_csv('../datasets/businesses/bus_10.txt')\n",
    "df_business_11 = pd.read_csv('../datasets/businesses/bus_11.txt')\n",
    "df_business_12 = pd.read_csv('../datasets/businesses/bus_12.txt')\n",
    "df_business_13 = pd.read_csv('../datasets/businesses/bus_13.txt')\n",
    "df_business_14 = pd.read_csv('../datasets/businesses/bus_14.txt')\n",
    "df_business_15 = pd.read_csv('../datasets/businesses/bus_15.txt')\n",
    "df_business_16 = pd.read_csv('../datasets/businesses/bus_16.txt')\n",
    "df_business_17 = pd.read_csv('../datasets/businesses/bus_17.txt')\n",
    "df_business_18 = pd.read_csv('../datasets/businesses/bus_18.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns and rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "df_business_09 = df_business_09.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_09 = df_business_09.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2010\n",
    "df_business_10 = df_business_10.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_10 = df_business_10.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2011\n",
    "df_business_11 = df_business_11.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_11 = df_business_11.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2012\n",
    "df_business_12 = df_business_12.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_12 = df_business_12.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2013\n",
    "df_business_13 = df_business_13.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_13 = df_business_13.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2014\n",
    "df_business_14 = df_business_14.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_14 = df_business_14.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2015\n",
    "df_business_15 = df_business_15.loc[:,['FIPSTATE', 'FIPSCTY', 'NAICS', 'EST']]\n",
    "df_business_15 = df_business_15.rename(columns={'FIPSTATE': 'FIPS_state', 'FIPSCTY':'FIPS_county', \n",
    "                                'NAICS':'Industry','EST':'Num_establishments'})\n",
    "# 2016\n",
    "df_business_16 = df_business_16.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_16 = df_business_16.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2017\n",
    "df_business_17 = df_business_17.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_17 = df_business_17.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2018\n",
    "df_business_18 = df_business_18.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_18 = df_business_18.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat FIPS codes and join together state+county codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add leading zeros to FIPS codes, and concat state and county FIPS codes\n",
    "# 2009\n",
    "df_business_09['FIPS_county'] = np.select([df_business_09['FIPS_county']<10, df_business_09['FIPS_county']<100],\n",
    "                    ['00'+df_business_09['FIPS_county'].astype(str), '0'+df_business_09['FIPS_county'].astype(str)],\n",
    "                    default= df_business_09['FIPS_county'].astype(str))\n",
    "df_business_09['FIPS_state'] = np.where(df_business_09['FIPS_state']<10, \n",
    "                        '0'+df_business_09['FIPS_state'].astype(str), df_business_09['FIPS_state'].astype(str))\n",
    "df_business_09['FIPS'] = df_business_09['FIPS_state'] + df_business_09['FIPS_county']\n",
    "\n",
    "# 2010\n",
    "df_business_10['FIPS_county'] = np.select([df_business_10['FIPS_county']<10, df_business_10['FIPS_county']<100],\n",
    "                    ['00'+df_business_10['FIPS_county'].astype(str), '0'+df_business_10['FIPS_county'].astype(str)],\n",
    "                    default= df_business_10['FIPS_county'].astype(str))\n",
    "df_business_10['FIPS_state'] = np.where(df_business_10['FIPS_state']<10, \n",
    "                        '0'+df_business_10['FIPS_state'].astype(str), df_business_10['FIPS_state'].astype(str))\n",
    "df_business_10['FIPS'] = df_business_10['FIPS_state'] + df_business_10['FIPS_county']\n",
    "\n",
    "# 2011\n",
    "df_business_11['FIPS_county'] = np.select([df_business_11['FIPS_county']<10, df_business_11['FIPS_county']<100],\n",
    "                    ['00'+df_business_11['FIPS_county'].astype(str), '0'+df_business_11['FIPS_county'].astype(str)],\n",
    "                    default= df_business_11['FIPS_county'].astype(str))\n",
    "df_business_11['FIPS_state'] = np.where(df_business_11['FIPS_state']<10, \n",
    "                        '0'+df_business_11['FIPS_state'].astype(str), df_business_11['FIPS_state'].astype(str))\n",
    "df_business_11['FIPS'] = df_business_11['FIPS_state'] + df_business_11['FIPS_county']\n",
    "\n",
    "# 2012\n",
    "df_business_12['FIPS_county'] = np.select([df_business_12['FIPS_county']<10, df_business_12['FIPS_county']<100],\n",
    "                    ['00'+df_business_12['FIPS_county'].astype(str), '0'+df_business_12['FIPS_county'].astype(str)],\n",
    "                    default= df_business_12['FIPS_county'].astype(str))\n",
    "df_business_12['FIPS_state'] = np.where(df_business_12['FIPS_state']<10, \n",
    "                        '0'+df_business_12['FIPS_state'].astype(str), df_business_12['FIPS_state'].astype(str))\n",
    "df_business_12['FIPS'] = df_business_12['FIPS_state'] + df_business_12['FIPS_county']\n",
    "\n",
    "# 2013\n",
    "df_business_13['FIPS_county'] = np.select([df_business_13['FIPS_county']<10, df_business_13['FIPS_county']<100],\n",
    "                    ['00'+df_business_13['FIPS_county'].astype(str), '0'+df_business_13['FIPS_county'].astype(str)],\n",
    "                    default= df_business_13['FIPS_county'].astype(str))\n",
    "df_business_13['FIPS_state'] = np.where(df_business_13['FIPS_state']<10, \n",
    "                        '0'+df_business_13['FIPS_state'].astype(str), df_business_13['FIPS_state'].astype(str))\n",
    "df_business_13['FIPS'] = df_business_13['FIPS_state'] + df_business_13['FIPS_county']\n",
    "\n",
    "# 2014\n",
    "df_business_14['FIPS_county'] = np.select([df_business_14['FIPS_county']<10, df_business_14['FIPS_county']<100],\n",
    "                    ['00'+df_business_14['FIPS_county'].astype(str), '0'+df_business_14['FIPS_county'].astype(str)],\n",
    "                    default= df_business_14['FIPS_county'].astype(str))\n",
    "df_business_14['FIPS_state'] = np.where(df_business_14['FIPS_state']<10, \n",
    "                        '0'+df_business_14['FIPS_state'].astype(str), df_business_14['FIPS_state'].astype(str))\n",
    "df_business_14['FIPS'] = df_business_14['FIPS_state'] + df_business_14['FIPS_county']\n",
    "\n",
    "# 2015\n",
    "df_business_15['FIPS_county'] = np.select([df_business_15['FIPS_county']<10, df_business_15['FIPS_county']<100],\n",
    "                    ['00'+df_business_15['FIPS_county'].astype(str), '0'+df_business_15['FIPS_county'].astype(str)],\n",
    "                    default= df_business_15['FIPS_county'].astype(str))\n",
    "df_business_15['FIPS_state'] = np.where(df_business_15['FIPS_state']<10, \n",
    "                        '0'+df_business_15['FIPS_state'].astype(str), df_business_15['FIPS_state'].astype(str))\n",
    "df_business_15['FIPS'] = df_business_15['FIPS_state'] + df_business_15['FIPS_county']\n",
    "\n",
    "# 2016\n",
    "df_business_16['FIPS_county'] = np.select([df_business_16['FIPS_county']<10, df_business_16['FIPS_county']<100],\n",
    "                    ['00'+df_business_16['FIPS_county'].astype(str), '0'+df_business_16['FIPS_county'].astype(str)],\n",
    "                    default= df_business_16['FIPS_county'].astype(str))\n",
    "df_business_16['FIPS_state'] = np.where(df_business_16['FIPS_state']<10, \n",
    "                        '0'+df_business_16['FIPS_state'].astype(str), df_business_16['FIPS_state'].astype(str))\n",
    "df_business_16['FIPS'] = df_business_16['FIPS_state'] + df_business_16['FIPS_county']\n",
    "\n",
    "# 2017\n",
    "df_business_17['FIPS_county'] = np.select([df_business_17['FIPS_county']<10, df_business_17['FIPS_county']<100],\n",
    "                    ['00'+df_business_17['FIPS_county'].astype(str), '0'+df_business_17['FIPS_county'].astype(str)],\n",
    "                    default= df_business_17['FIPS_county'].astype(str))\n",
    "df_business_17['FIPS_state'] = np.where(df_business_17['FIPS_state']<10, \n",
    "                        '0'+df_business_17['FIPS_state'].astype(str), df_business_17['FIPS_state'].astype(str))\n",
    "df_business_17['FIPS'] = df_business_17['FIPS_state'] + df_business_17['FIPS_county']\n",
    "\n",
    "# 2018\n",
    "df_business_18['FIPS_county'] = np.select([df_business_18['FIPS_county']<10, df_business_18['FIPS_county']<100],\n",
    "                    ['00'+df_business_18['FIPS_county'].astype(str), '0'+df_business_18['FIPS_county'].astype(str)],\n",
    "                    default= df_business_18['FIPS_county'].astype(str))\n",
    "df_business_18['FIPS_state'] = np.where(df_business_18['FIPS_state']<10, \n",
    "                        '0'+df_business_18['FIPS_state'].astype(str), df_business_18['FIPS_state'].astype(str))\n",
    "df_business_18['FIPS'] = df_business_18['FIPS_state'] + df_business_18['FIPS_county']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate rows for each type of food establishment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_09[df_business_09['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_09[df_business_09['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_09[df_business_09['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2010\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_10[df_business_10['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_10[df_business_10['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_10[df_business_10['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2011\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_11[df_business_11['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_11[df_business_11['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_11[df_business_11['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2012\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_12[df_business_12['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_12[df_business_12['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_12[df_business_12['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2013\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_13[df_business_13['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_13[df_business_13['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_13[df_business_13['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2014\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_14[df_business_14['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_14[df_business_14['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_14[df_business_14['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2015\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_15[df_business_15['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_15[df_business_15['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_15[df_business_15['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2016\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_16[df_business_16['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_16[df_business_16['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_16[df_business_16['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2017\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_17[df_business_17['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_17[df_business_17['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_17[df_business_17['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2018\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_18[df_business_18['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_18[df_business_18['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_18[df_business_18['Industry'].isin(wholesale)].index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group dataframe by type of establishment, and sum # of businesses in each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "restaraunt_df = df_business_09.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_09.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_09.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_09 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2010\n",
    "restaraunt_df = df_business_10.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_10.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_10.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_10 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2011\n",
    "restaraunt_df = df_business_11.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_11.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_11.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_11 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2012\n",
    "restaraunt_df = df_business_12.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_12.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_12.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_12 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2013\n",
    "restaraunt_df = df_business_13.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_13.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_13.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_13 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2014\n",
    "restaraunt_df = df_business_14.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_14.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_14.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_14 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2015\n",
    "restaraunt_df = df_business_15.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_15.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_15.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_15 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2016\n",
    "restaraunt_df = df_business_16.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_16.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_16.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_16 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2017\n",
    "restaraunt_df = df_business_17.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_17.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_17.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_17 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2018\n",
    "restaraunt_df = df_business_18.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_18.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_18.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_18 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Year column to each df and impute nulls with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Num_wholesale</th>\n",
       "      <th>Num_restaraunts</th>\n",
       "      <th>Num_grocery</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01003</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01015</td>\n",
       "      <td>18.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01021</td>\n",
       "      <td>3.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01031</td>\n",
       "      <td>4.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01033</td>\n",
       "      <td>18.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>29211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>46121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>48155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>51045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>51091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3110 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS  Num_wholesale  Num_restaraunts  Num_grocery  Year\n",
       "0     01003           58.0           1955.0        551.0  2018\n",
       "1     01015           18.0            711.0        259.0  2018\n",
       "2     01021            3.0            194.0         96.0  2018\n",
       "3     01031            4.0            352.0         83.0  2018\n",
       "4     01033           18.0            363.0        192.0  2018\n",
       "...     ...            ...              ...          ...   ...\n",
       "3105  29211            0.0              0.0         18.0  2018\n",
       "3106  46121            0.0              0.0         12.0  2018\n",
       "3107  48155            0.0              0.0          3.0  2018\n",
       "3108  51045            0.0              0.0         14.0  2018\n",
       "3109  51091            0.0              0.0          7.0  2018\n",
       "\n",
       "[3110 rows x 5 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_food_09['Year'] = '2009'\n",
    "df_food_09.fillna(0, inplace=True)\n",
    "df_food_10['Year'] = '2010'\n",
    "df_food_10.fillna(0, inplace=True)\n",
    "df_food_11['Year'] = '2011'\n",
    "df_food_11.fillna(0, inplace=True)\n",
    "df_food_12['Year'] = '2012'\n",
    "df_food_12.fillna(0, inplace=True)\n",
    "df_food_13['Year'] = '2013'\n",
    "df_food_13.fillna(0, inplace=True)\n",
    "df_food_14['Year'] = '2014'\n",
    "df_food_14.fillna(0, inplace=True)\n",
    "df_food_15['Year'] = '2015'\n",
    "df_food_15.fillna(0, inplace=True)\n",
    "df_food_16['Year'] = '2016'\n",
    "df_food_16.fillna(0, inplace=True)\n",
    "df_food_17['Year'] = '2017'\n",
    "df_food_17.fillna(0, inplace=True)\n",
    "df_food_18['Year'] = '2018'\n",
    "df_food_18.fillna(0, inplace=True)\n",
    "df_food_18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
