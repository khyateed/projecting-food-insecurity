{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Cleaning\n",
    "## Projecting US Food Insecurity in 2020\n",
    "### By Khyatee Desai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "pd.set_option('display.max_rows', 10)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feeding America Datasets\n",
    "### Import all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../datasets/feeding_america/\"\n",
    "\n",
    "df_FA_09 = pd.read_excel(directory+'FA_2011_2009.xlsx')\n",
    "df_FA_10 = pd.read_excel(directory+'FA_2012_2010.xlsx')\n",
    "df_FA_11 = pd.read_excel(directory+'FA_2013_2011.xlsx')\n",
    "df_FA_12 = pd.read_excel(directory+'FA_2014_2012.xlsx')\n",
    "df_FA_13 = pd.read_excel(directory+'FA_2015_2013.xlsx')\n",
    "df_FA_14 = pd.read_excel(directory+'FA_2016_2014.xlsx')\n",
    "df_FA_15 = pd.read_excel(directory+'FA_2017_2015.xlsx')\n",
    "df_FA_16 = pd.read_excel(directory+'FA_2018_2016.xlsx')\n",
    "df_FA_17 = pd.read_excel(directory+'FA_2019_2017.xlsx')\n",
    "df_FA_18 = pd.read_excel(directory+'FA_2020_2018.xlsx',header=1)\n",
    "df_FAprojection_20 = pd.read_excel(directory+'projection_10.2020.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_FA_09 = df_FA_09.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "            '% FI Btwn Thresholds','% FI > High Threshold', '% of children in FI HH with HH incomes at or below 185% FPL',\n",
    "              'Number Food Insecure Children','% of children in FI HH with HH incomes above 185% FPL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_FA_10 = df_FA_10.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "              '% FI Btwn Thresholds', 'Number of Food Insecure Children in 2010 ',\n",
    "              '% FI > High Threshold', '% food insecure children in HH w/ HH incomes below 185 FPL',\n",
    "               '% of food insecure children in HH w/ HH incomes above 185 FPL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_11 = df_FA_11.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                          '% FI Btwn Thresholds', 'Number of Food Insecure Children in 2011',\n",
    "              '% FI > High Threshold', '% food insecure children in HH w/ HH incomes below 185 FPL',\n",
    "               '% of food insecure children in HH w/ HH incomes above 185 FPL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_12 = df_FA_12.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds','% FI > High Threshold', '# of Food Insecure Children in 2012',\n",
    "               '% food insecure Children in HH w/HH Incomes Below 185 FPL in 2012',\n",
    "               '% food insecure Children in HH w/HH Incomes Above 185 FPL in 2012'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_13 = df_FA_13.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds','% FI > High Threshold', '# of Food Insecure Children in 2013',\n",
    "               '% food insecure Children in HH w/HH Incomes Below 185 FPL in 2013',\n",
    "               '% food insecure Children in HH w/HH Incomes Above 185 FPL in 2013'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_14 = df_FA_14.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds', '% FI > High Threshold', '# of Food Insecure Children in 2014',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2014',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2014'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_15 = df_FA_15.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds','% FI > High Threshold', '# of Food Insecure Children in 2015',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2015',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2015'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_16 = df_FA_16.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds','% FI > High Threshold', '# of Food Insecure Children in 2016',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2016',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2016'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FA_17 = df_FA_17.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds', '% FI > High Threshold', '# of Food Insecure Children in 2017',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2017',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2017'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_FA_18 = df_FA_18.drop(['Low Threshold in state', 'High Threshold in state', '% FI ≤ Low Threshold',\n",
    "                '% FI Btwn Thresholds', '% FI > High Threshold', '# of Food Insecure Children in 2018',\n",
    "               '% food insecure children in HH w/ HH incomes below 185 FPL in 2018',\n",
    "               '% food insecure children in HH w/ HH incomes above 185 FPL in 2018'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State</th>\n",
       "      <th>County, State</th>\n",
       "      <th>2018 Food Insecurity Rate</th>\n",
       "      <th># of Food Insecure Persons in 2018</th>\n",
       "      <th>Low Threshold Type</th>\n",
       "      <th>High Threshold Type</th>\n",
       "      <th>2018 Child food insecurity rate</th>\n",
       "      <th>2018 Cost Per Meal</th>\n",
       "      <th>2018 Weighted Annual Food Budget Shortfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>0.156</td>\n",
       "      <td>8620</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.214</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4857000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin County, Alabama</td>\n",
       "      <td>0.129</td>\n",
       "      <td>26860</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.169</td>\n",
       "      <td>3.58</td>\n",
       "      <td>16274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour County, Alabama</td>\n",
       "      <td>0.219</td>\n",
       "      <td>5650</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.320</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bibb County, Alabama</td>\n",
       "      <td>0.151</td>\n",
       "      <td>3400</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.209</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>AL</td>\n",
       "      <td>Blount County, Alabama</td>\n",
       "      <td>0.136</td>\n",
       "      <td>7810</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.191</td>\n",
       "      <td>3.14</td>\n",
       "      <td>4149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>56037</td>\n",
       "      <td>WY</td>\n",
       "      <td>Sweetwater County, Wyoming</td>\n",
       "      <td>0.117</td>\n",
       "      <td>5140</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.154</td>\n",
       "      <td>3.29</td>\n",
       "      <td>2865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>56039</td>\n",
       "      <td>WY</td>\n",
       "      <td>Teton County, Wyoming</td>\n",
       "      <td>0.095</td>\n",
       "      <td>2200</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.084</td>\n",
       "      <td>4.52</td>\n",
       "      <td>1683000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>56041</td>\n",
       "      <td>WY</td>\n",
       "      <td>Uinta County, Wyoming</td>\n",
       "      <td>0.135</td>\n",
       "      <td>2780</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.187</td>\n",
       "      <td>3.07</td>\n",
       "      <td>1444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>56043</td>\n",
       "      <td>WY</td>\n",
       "      <td>Washakie County, Wyoming</td>\n",
       "      <td>0.126</td>\n",
       "      <td>1020</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.184</td>\n",
       "      <td>3.26</td>\n",
       "      <td>562000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>56045</td>\n",
       "      <td>WY</td>\n",
       "      <td>Weston County, Wyoming</td>\n",
       "      <td>0.140</td>\n",
       "      <td>990</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>0.223</td>\n",
       "      <td>3.16</td>\n",
       "      <td>529000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3142 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS State               County, State  2018 Food Insecurity Rate  \\\n",
       "0      1001    AL     Autauga County, Alabama                      0.156   \n",
       "1      1003    AL     Baldwin County, Alabama                      0.129   \n",
       "2      1005    AL     Barbour County, Alabama                      0.219   \n",
       "3      1007    AL        Bibb County, Alabama                      0.151   \n",
       "4      1009    AL      Blount County, Alabama                      0.136   \n",
       "...     ...   ...                         ...                        ...   \n",
       "3137  56037    WY  Sweetwater County, Wyoming                      0.117   \n",
       "3138  56039    WY       Teton County, Wyoming                      0.095   \n",
       "3139  56041    WY       Uinta County, Wyoming                      0.135   \n",
       "3140  56043    WY    Washakie County, Wyoming                      0.126   \n",
       "3141  56045    WY      Weston County, Wyoming                      0.140   \n",
       "\n",
       "      # of Food Insecure Persons in 2018 Low Threshold Type  \\\n",
       "0                                   8620               SNAP   \n",
       "1                                  26860               SNAP   \n",
       "2                                   5650               SNAP   \n",
       "3                                   3400               SNAP   \n",
       "4                                   7810               SNAP   \n",
       "...                                  ...                ...   \n",
       "3137                                5140               SNAP   \n",
       "3138                                2200               SNAP   \n",
       "3139                                2780               SNAP   \n",
       "3140                                1020               SNAP   \n",
       "3141                                 990               SNAP   \n",
       "\n",
       "          High Threshold Type  2018 Child food insecurity rate  \\\n",
       "0     Other Nutrition Program                            0.214   \n",
       "1     Other Nutrition Program                            0.169   \n",
       "2     Other Nutrition Program                            0.320   \n",
       "3     Other Nutrition Program                            0.209   \n",
       "4     Other Nutrition Program                            0.191   \n",
       "...                       ...                              ...   \n",
       "3137  Other Nutrition Program                            0.154   \n",
       "3138  Other Nutrition Program                            0.084   \n",
       "3139  Other Nutrition Program                            0.187   \n",
       "3140  Other Nutrition Program                            0.184   \n",
       "3141  Other Nutrition Program                            0.223   \n",
       "\n",
       "      2018 Cost Per Meal  2018 Weighted Annual Food Budget Shortfall  \n",
       "0                   3.33                                     4857000  \n",
       "1                   3.58                                    16274000  \n",
       "2                   3.12                                     2988000  \n",
       "3                   2.94                                     1690000  \n",
       "4                   3.14                                     4149000  \n",
       "...                  ...                                         ...  \n",
       "3137                3.29                                     2865000  \n",
       "3138                4.52                                     1683000  \n",
       "3139                3.07                                     1444000  \n",
       "3140                3.26                                      562000  \n",
       "3141                3.16                                      529000  \n",
       "\n",
       "[3142 rows x 10 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FA_18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Unemployment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../datasets/unemployment/\"\n",
    "\n",
    "df_unemp_09 = pd.read_excel(directory + 'laucnty09.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_10 = pd.read_excel(directory + 'laucnty10.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_11 = pd.read_excel(directory + 'laucnty11.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_12 = pd.read_excel(directory + 'laucnty12.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_13 = pd.read_excel(directory + 'laucnty13.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_14 = pd.read_excel(directory + 'laucnty14.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_15 = pd.read_excel(directory + 'laucnty15.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_16 = pd.read_excel(directory + 'laucnty16.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_17 = pd.read_excel(directory + 'laucnty17.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_18 = pd.read_excel(directory + 'laucnty18.xlsx', header=4).drop(0,axis=0)\n",
    "df_unemp_19 = pd.read_excel(directory + 'laucnty19.xlsx', header=4).drop(0,axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns using data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_09.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_10.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_11.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_12.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_13.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_14.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_15.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_16.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_17.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_18.rename(columns = {'Code':'CN', 'Code.1':'FIPS_state', 'Code.2':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', 'Unnamed: 5': 'idk',\n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemp_19.rename(columns = {'LAUS Code':'LAUS', 'Code':'FIPS_state', 'Code.1':'FIPS_county', \n",
    "                             'County Name/State Abbreviation': 'State/County', \n",
    "                              'Force':'Total_workforce','(%)':'Unemployment_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAUS</th>\n",
       "      <th>FIPS_state</th>\n",
       "      <th>FIPS_county</th>\n",
       "      <th>State/County</th>\n",
       "      <th>Period</th>\n",
       "      <th>Total_workforce</th>\n",
       "      <th>Employed</th>\n",
       "      <th>Unemployed</th>\n",
       "      <th>Unemployment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN0100100000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Autauga County, AL</td>\n",
       "      <td>Sep-19</td>\n",
       "      <td>26010</td>\n",
       "      <td>25391</td>\n",
       "      <td>619</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN0100300000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Baldwin County, AL</td>\n",
       "      <td>Sep-19</td>\n",
       "      <td>96754</td>\n",
       "      <td>94510</td>\n",
       "      <td>2244</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN0100500000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Barbour County, AL</td>\n",
       "      <td>Sep-19</td>\n",
       "      <td>8656</td>\n",
       "      <td>8376</td>\n",
       "      <td>280</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CN0100700000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Bibb County, AL</td>\n",
       "      <td>Sep-19</td>\n",
       "      <td>8655</td>\n",
       "      <td>8430</td>\n",
       "      <td>225</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CN0100900000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Blount County, AL</td>\n",
       "      <td>Sep-19</td>\n",
       "      <td>25351</td>\n",
       "      <td>24763</td>\n",
       "      <td>588</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45065</th>\n",
       "      <td>CN7215100000000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>Yabucoa Municipio, PR</td>\n",
       "      <td>Oct-20 p</td>\n",
       "      <td>7961</td>\n",
       "      <td>7168</td>\n",
       "      <td>793</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45066</th>\n",
       "      <td>CN7215300000000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>Yauco Municipio, PR</td>\n",
       "      <td>Oct-20 p</td>\n",
       "      <td>9250</td>\n",
       "      <td>8321</td>\n",
       "      <td>929</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45067</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45068</th>\n",
       "      <td>p = preliminary.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOURCE:  BLS, LAUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45069</th>\n",
       "      <td>Dash indicates that data are not available.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>December 3, 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45069 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              LAUS  FIPS_state  FIPS_county  \\\n",
       "1                                  CN0100100000000         1.0          1.0   \n",
       "2                                  CN0100300000000         1.0          3.0   \n",
       "3                                  CN0100500000000         1.0          5.0   \n",
       "4                                  CN0100700000000         1.0          7.0   \n",
       "5                                  CN0100900000000         1.0          9.0   \n",
       "...                                            ...         ...          ...   \n",
       "45065                              CN7215100000000        72.0        151.0   \n",
       "45066                              CN7215300000000        72.0        153.0   \n",
       "45067                                          NaN         NaN          NaN   \n",
       "45068                             p = preliminary.         NaN          NaN   \n",
       "45069  Dash indicates that data are not available.         NaN          NaN   \n",
       "\n",
       "                State/County    Period Total_workforce Employed Unemployed  \\\n",
       "1         Autauga County, AL    Sep-19           26010    25391        619   \n",
       "2         Baldwin County, AL    Sep-19           96754    94510       2244   \n",
       "3         Barbour County, AL    Sep-19            8656     8376        280   \n",
       "4            Bibb County, AL    Sep-19            8655     8430        225   \n",
       "5          Blount County, AL    Sep-19           25351    24763        588   \n",
       "...                      ...       ...             ...      ...        ...   \n",
       "45065  Yabucoa Municipio, PR  Oct-20 p            7961     7168        793   \n",
       "45066    Yauco Municipio, PR  Oct-20 p            9250     8321        929   \n",
       "45067                    NaN       NaN             NaN      NaN        NaN   \n",
       "45068                    NaN       NaN             NaN      NaN        NaN   \n",
       "45069                    NaN       NaN             NaN      NaN        NaN   \n",
       "\n",
       "        Unemployment_rate  \n",
       "1                     2.4  \n",
       "2                     2.3  \n",
       "3                     3.2  \n",
       "4                     2.6  \n",
       "5                     2.3  \n",
       "...                   ...  \n",
       "45065                  10  \n",
       "45066                  10  \n",
       "45067                 NaN  \n",
       "45068  SOURCE:  BLS, LAUS  \n",
       "45069    December 3, 2020  \n",
       "\n",
       "[45069 rows x 9 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unemp_19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Household Income Data (2019 &2020)\n",
    "data dict 2019: https://www2.census.gov/programs-surveys/cps/techdocs/cpsmar19.pdf<br>\n",
    "data dict 2020: https://www2.census.gov/programs-surveys/cps/datasets/2020/march/ASEC2020ddl_pub_full.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household_19 = pd.read_csv('../datasets/household/hhpub19.csv')\n",
    "df_household_20 = pd.read_csv('../datasets/household/hhpub20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map column values to data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np.select to map values on 2019 data\n",
    "conditions=[df_household_19['GTMETSTA'] ==1,df_household_19['GTMETSTA'] ==2, df_household_19['GTMETSTA'] ==3]\n",
    "choices = ['HH_Metrop', 'HH_Non-Metrop','N/A']\n",
    "df_household_19['GTMETSTA'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_19['H_TENURE'] ==0,df_household_19['H_TENURE'] ==1,df_household_19['H_TENURE'] ==2, df_household_19['H_TENURE'] ==3]\n",
    "choices = ['N/A', 'HH_owned', 'HH_rented','HH_rented_noCash']\n",
    "df_household_19['H_TENURE'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_19['HDIS_YN'] ==0,df_household_19['HDIS_YN'] ==1,df_household_19['HDIS_YN'] ==2]\n",
    "choices = ['N/A',  'HH_disabled','HH_not_disabled' ]\n",
    "df_household_19['HDIS_YN'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_19['HCSP_YN'] ==0,df_household_19['HCSP_YN'] ==1,df_household_19['HCSP_YN'] ==2]\n",
    "choices = ['N/A','HH_Child_support', 'HH_no_child_support' ]\n",
    "df_household_19['HCSP_YN'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_19['HINC_UC'] ==0,df_household_19['HINC_UC'] ==1,df_household_19['HINC_UC'] ==2]\n",
    "choices = ['N/A','HH_unemployment_pay', 'HH_no_unemployment_pay' ]\n",
    "df_household_19['HINC_UC'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_19['NOW_HCOV'] ==1,df_household_19['NOW_HCOV'] ==2,df_household_19['NOW_HCOV'] ==3]\n",
    "choices = [ 'HH_health_insured','HH_some_health_insured','HH_no_health_insured' ]\n",
    "df_household_19['NOW_HCOV'] = np.select(conditions, choices,default='N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np.select to map values on 2020 data\n",
    "conditions=[df_household_20['GTMETSTA'] ==1,df_household_20['GTMETSTA'] ==2, df_household_20['GTMETSTA'] ==3]\n",
    "choices = ['HH_Metrop', 'HH_Non-Metrop','N/A']\n",
    "df_household_20['GTMETSTA'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['H_TENURE'] ==0,df_household_20['H_TENURE'] ==1,df_household_20['H_TENURE'] ==2, df_household_20['H_TENURE'] ==3]\n",
    "choices = ['N/A', 'HH_owned', 'HH_rented','HH_rented_noCash']\n",
    "df_household_20['H_TENURE'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['HDIS_YN'] ==0,df_household_20['HDIS_YN'] ==1,df_household_20['HDIS_YN'] ==2]\n",
    "choices = ['N/A',  'HH_disabled','HH_not_disabled' ]\n",
    "df_household_20['HDIS_YN'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['HCSP_YN'] ==0,df_household_20['HCSP_YN'] ==1,df_household_20['HCSP_YN'] ==2]\n",
    "choices = ['N/A','HH_Child_support', 'HH_no_child_support' ]\n",
    "df_household_20['HCSP_YN'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['HINC_UC'] ==0,df_household_20['HINC_UC'] ==1,df_household_20['HINC_UC'] ==2]\n",
    "choices = ['N/A','HH_unemployment_pay', 'HH_no_unemployment_pay' ]\n",
    "df_household_20['HINC_UC'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_household_20['NOW_HCOV'] ==1,df_household_20['NOW_HCOV'] ==2,df_household_20['NOW_HCOV'] ==3]\n",
    "choices = [ 'HH_health_insured','HH_some_health_insured','HH_no_health_insured' ]\n",
    "df_household_20['NOW_HCOV'] = np.select(conditions, choices,default='N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 2019 data\n",
    "df_household_19 = df_household_19.loc[:,['GESTFIPS', 'GTCO', 'GTMETSTA', 'HTOTVAL','H_NUMPER', 'HUNDER18',\n",
    "                 'H_TENURE','HDIS_YN', 'HCSP_YN', 'HINC_UC','NOW_HCOV']]\n",
    "df_household_19 = df_household_19.rename(columns={'GESTFIPS':'FIPS_state', 'GTCO':'FIPS_county', 'GTMETSTA':'Metro_status',\n",
    "                               'HEFAMINC':'HH_income', \n",
    "                                'H_NUMPER':'HH_size', 'HUNDER18':'Num_minors','H_TENURE':'Rent_vs_Owned',\n",
    "                               'HDIS_YN':'Disability', 'HCSP_YN':'Child_support', 'HINC_UC':'Unemployment_payments',\n",
    "                               'NOW_HCOV':'Health_insurance'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename 2020 data\n",
    "df_household_20 = df_household_20.loc[:,['GESTFIPS', 'GTCO', 'GTMETSTA', 'HTOTVAL','H_NUMPER', 'HUNDER18',\n",
    "                 'H_TENURE','HDIS_YN', 'HCSP_YN', 'HINC_UC','NOW_HCOV']]\n",
    "df_household_20 = df_household_20.rename(columns={'GESTFIPS':'FIPS_state', 'GTCO':'FIPS_county', 'GTMETSTA':'Metro_status',\n",
    "                               'HEFAMINC':'HH_income', \n",
    "                                'H_NUMPER':'HH_size', 'HUNDER18':'Num_minors','H_TENURE':'Rent_vs_Owned',\n",
    "                               'HDIS_YN':'Disability', 'HCSP_YN':'Child_support', 'HINC_UC':'Unemployment_payments',\n",
    "                               'NOW_HCOV':'Health_insurance'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_state</th>\n",
       "      <th>FIPS_county</th>\n",
       "      <th>Metro_status</th>\n",
       "      <th>HTOTVAL</th>\n",
       "      <th>HH_size</th>\n",
       "      <th>Num_minors</th>\n",
       "      <th>Rent_vs_Owned</th>\n",
       "      <th>Disability</th>\n",
       "      <th>Child_support</th>\n",
       "      <th>Unemployment_payments</th>\n",
       "      <th>Health_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>127449</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>64680</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>40002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>8424</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_rented</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_Non-Metrop</td>\n",
       "      <td>59114</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91495</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>HH_Metrop</td>\n",
       "      <td>40700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91496</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>HH_Metrop</td>\n",
       "      <td>20421</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_rented_noCash</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91497</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>HH_Metrop</td>\n",
       "      <td>72455</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_some_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91498</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>HH_Metrop</td>\n",
       "      <td>13626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HH_rented</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91499</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>HH_Metrop</td>\n",
       "      <td>121101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>HH_owned</td>\n",
       "      <td>HH_not_disabled</td>\n",
       "      <td>HH_no_child_support</td>\n",
       "      <td>HH_no_unemployment_pay</td>\n",
       "      <td>HH_health_insured</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91500 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS_state  FIPS_county   Metro_status  HTOTVAL  HH_size  Num_minors  \\\n",
       "0              23            0  HH_Non-Metrop   127449        2           0   \n",
       "1              23            0  HH_Non-Metrop    64680        2           0   \n",
       "2              23            0  HH_Non-Metrop    40002        1           0   \n",
       "3              23            0  HH_Non-Metrop     8424        2           0   \n",
       "4              23            0  HH_Non-Metrop    59114        4           0   \n",
       "...           ...          ...            ...      ...      ...         ...   \n",
       "91495          15            3      HH_Metrop    40700        1           0   \n",
       "91496          15            3      HH_Metrop    20421        1           0   \n",
       "91497          15            3      HH_Metrop    72455        2           0   \n",
       "91498          15            3      HH_Metrop    13626        1           0   \n",
       "91499          15            3      HH_Metrop   121101        2           1   \n",
       "\n",
       "          Rent_vs_Owned       Disability        Child_support  \\\n",
       "0              HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "1              HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "2              HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "3             HH_rented  HH_not_disabled  HH_no_child_support   \n",
       "4              HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "...                 ...              ...                  ...   \n",
       "91495          HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "91496  HH_rented_noCash  HH_not_disabled  HH_no_child_support   \n",
       "91497          HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "91498         HH_rented  HH_not_disabled  HH_no_child_support   \n",
       "91499          HH_owned  HH_not_disabled  HH_no_child_support   \n",
       "\n",
       "        Unemployment_payments        Health_insurance  \n",
       "0      HH_no_unemployment_pay       HH_health_insured  \n",
       "1      HH_no_unemployment_pay       HH_health_insured  \n",
       "2      HH_no_unemployment_pay       HH_health_insured  \n",
       "3      HH_no_unemployment_pay       HH_health_insured  \n",
       "4      HH_no_unemployment_pay       HH_health_insured  \n",
       "...                       ...                     ...  \n",
       "91495  HH_no_unemployment_pay       HH_health_insured  \n",
       "91496  HH_no_unemployment_pay       HH_health_insured  \n",
       "91497  HH_no_unemployment_pay  HH_some_health_insured  \n",
       "91498  HH_no_unemployment_pay       HH_health_insured  \n",
       "91499  HH_no_unemployment_pay       HH_health_insured  \n",
       "\n",
       "[91500 rows x 11 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_household_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Demographic Data\n",
    "Data Dict: https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2010-2019/cc-est2019-alldata.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>AGEGRP</th>\n",
       "      <th>TOT_POP</th>\n",
       "      <th>TOT_MALE</th>\n",
       "      <th>TOT_FEMALE</th>\n",
       "      <th>WA_MALE</th>\n",
       "      <th>WA_FEMALE</th>\n",
       "      <th>BA_MALE</th>\n",
       "      <th>BA_FEMALE</th>\n",
       "      <th>IA_MALE</th>\n",
       "      <th>IA_FEMALE</th>\n",
       "      <th>AA_MALE</th>\n",
       "      <th>AA_FEMALE</th>\n",
       "      <th>NA_MALE</th>\n",
       "      <th>NA_FEMALE</th>\n",
       "      <th>TOM_MALE</th>\n",
       "      <th>TOM_FEMALE</th>\n",
       "      <th>WAC_MALE</th>\n",
       "      <th>WAC_FEMALE</th>\n",
       "      <th>BAC_MALE</th>\n",
       "      <th>BAC_FEMALE</th>\n",
       "      <th>IAC_MALE</th>\n",
       "      <th>IAC_FEMALE</th>\n",
       "      <th>AAC_MALE</th>\n",
       "      <th>AAC_FEMALE</th>\n",
       "      <th>NAC_MALE</th>\n",
       "      <th>NAC_FEMALE</th>\n",
       "      <th>NH_MALE</th>\n",
       "      <th>NH_FEMALE</th>\n",
       "      <th>NHWA_MALE</th>\n",
       "      <th>NHWA_FEMALE</th>\n",
       "      <th>NHBA_MALE</th>\n",
       "      <th>NHBA_FEMALE</th>\n",
       "      <th>NHIA_MALE</th>\n",
       "      <th>NHIA_FEMALE</th>\n",
       "      <th>NHAA_MALE</th>\n",
       "      <th>NHAA_FEMALE</th>\n",
       "      <th>NHNA_MALE</th>\n",
       "      <th>NHNA_FEMALE</th>\n",
       "      <th>NHTOM_MALE</th>\n",
       "      <th>NHTOM_FEMALE</th>\n",
       "      <th>NHWAC_MALE</th>\n",
       "      <th>NHWAC_FEMALE</th>\n",
       "      <th>NHBAC_MALE</th>\n",
       "      <th>NHBAC_FEMALE</th>\n",
       "      <th>NHIAC_MALE</th>\n",
       "      <th>NHIAC_FEMALE</th>\n",
       "      <th>NHAAC_MALE</th>\n",
       "      <th>NHAAC_FEMALE</th>\n",
       "      <th>NHNAC_MALE</th>\n",
       "      <th>NHNAC_FEMALE</th>\n",
       "      <th>H_MALE</th>\n",
       "      <th>H_FEMALE</th>\n",
       "      <th>HWA_MALE</th>\n",
       "      <th>HWA_FEMALE</th>\n",
       "      <th>HBA_MALE</th>\n",
       "      <th>HBA_FEMALE</th>\n",
       "      <th>HIA_MALE</th>\n",
       "      <th>HIA_FEMALE</th>\n",
       "      <th>HAA_MALE</th>\n",
       "      <th>HAA_FEMALE</th>\n",
       "      <th>HNA_MALE</th>\n",
       "      <th>HNA_FEMALE</th>\n",
       "      <th>HTOM_MALE</th>\n",
       "      <th>HTOM_FEMALE</th>\n",
       "      <th>HWAC_MALE</th>\n",
       "      <th>HWAC_FEMALE</th>\n",
       "      <th>HBAC_MALE</th>\n",
       "      <th>HBAC_FEMALE</th>\n",
       "      <th>HIAC_MALE</th>\n",
       "      <th>HIAC_FEMALE</th>\n",
       "      <th>HAAC_MALE</th>\n",
       "      <th>HAAC_FEMALE</th>\n",
       "      <th>HNAC_MALE</th>\n",
       "      <th>HNAC_FEMALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54571</td>\n",
       "      <td>26569</td>\n",
       "      <td>28002</td>\n",
       "      <td>21295</td>\n",
       "      <td>22002</td>\n",
       "      <td>4559</td>\n",
       "      <td>5130</td>\n",
       "      <td>119</td>\n",
       "      <td>139</td>\n",
       "      <td>200</td>\n",
       "      <td>284</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>367</td>\n",
       "      <td>429</td>\n",
       "      <td>21633</td>\n",
       "      <td>22391</td>\n",
       "      <td>4704</td>\n",
       "      <td>5306</td>\n",
       "      <td>277</td>\n",
       "      <td>314</td>\n",
       "      <td>300</td>\n",
       "      <td>409</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>25875</td>\n",
       "      <td>27386</td>\n",
       "      <td>20709</td>\n",
       "      <td>21485</td>\n",
       "      <td>4512</td>\n",
       "      <td>5091</td>\n",
       "      <td>103</td>\n",
       "      <td>115</td>\n",
       "      <td>194</td>\n",
       "      <td>280</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>344</td>\n",
       "      <td>406</td>\n",
       "      <td>21026</td>\n",
       "      <td>21853</td>\n",
       "      <td>4647</td>\n",
       "      <td>5258</td>\n",
       "      <td>251</td>\n",
       "      <td>282</td>\n",
       "      <td>291</td>\n",
       "      <td>398</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>694</td>\n",
       "      <td>616</td>\n",
       "      <td>586</td>\n",
       "      <td>517</td>\n",
       "      <td>47</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>607</td>\n",
       "      <td>538</td>\n",
       "      <td>57</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3579</td>\n",
       "      <td>1866</td>\n",
       "      <td>1713</td>\n",
       "      <td>1411</td>\n",
       "      <td>1316</td>\n",
       "      <td>362</td>\n",
       "      <td>317</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>1479</td>\n",
       "      <td>1368</td>\n",
       "      <td>405</td>\n",
       "      <td>362</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1778</td>\n",
       "      <td>1651</td>\n",
       "      <td>1337</td>\n",
       "      <td>1260</td>\n",
       "      <td>356</td>\n",
       "      <td>313</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>61</td>\n",
       "      <td>1402</td>\n",
       "      <td>1312</td>\n",
       "      <td>396</td>\n",
       "      <td>357</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3991</td>\n",
       "      <td>2001</td>\n",
       "      <td>1990</td>\n",
       "      <td>1521</td>\n",
       "      <td>1526</td>\n",
       "      <td>399</td>\n",
       "      <td>374</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>1570</td>\n",
       "      <td>1583</td>\n",
       "      <td>425</td>\n",
       "      <td>403</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1933</td>\n",
       "      <td>1916</td>\n",
       "      <td>1460</td>\n",
       "      <td>1465</td>\n",
       "      <td>398</td>\n",
       "      <td>372</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>1506</td>\n",
       "      <td>1517</td>\n",
       "      <td>423</td>\n",
       "      <td>400</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>74</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4290</td>\n",
       "      <td>2171</td>\n",
       "      <td>2119</td>\n",
       "      <td>1658</td>\n",
       "      <td>1620</td>\n",
       "      <td>431</td>\n",
       "      <td>406</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>62</td>\n",
       "      <td>1694</td>\n",
       "      <td>1681</td>\n",
       "      <td>453</td>\n",
       "      <td>436</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2105</td>\n",
       "      <td>2055</td>\n",
       "      <td>1613</td>\n",
       "      <td>1570</td>\n",
       "      <td>421</td>\n",
       "      <td>403</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>1643</td>\n",
       "      <td>1624</td>\n",
       "      <td>440</td>\n",
       "      <td>429</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4290</td>\n",
       "      <td>2213</td>\n",
       "      <td>2077</td>\n",
       "      <td>1628</td>\n",
       "      <td>1585</td>\n",
       "      <td>502</td>\n",
       "      <td>424</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>1664</td>\n",
       "      <td>1624</td>\n",
       "      <td>525</td>\n",
       "      <td>444</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2153</td>\n",
       "      <td>2026</td>\n",
       "      <td>1580</td>\n",
       "      <td>1543</td>\n",
       "      <td>495</td>\n",
       "      <td>420</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>1616</td>\n",
       "      <td>1580</td>\n",
       "      <td>518</td>\n",
       "      <td>439</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUMLEV  STATE  COUNTY   STNAME         CTYNAME  YEAR  AGEGRP  TOT_POP  \\\n",
       "0      50      1       1  Alabama  Autauga County     1       0    54571   \n",
       "1      50      1       1  Alabama  Autauga County     1       1     3579   \n",
       "2      50      1       1  Alabama  Autauga County     1       2     3991   \n",
       "3      50      1       1  Alabama  Autauga County     1       3     4290   \n",
       "4      50      1       1  Alabama  Autauga County     1       4     4290   \n",
       "\n",
       "   TOT_MALE  TOT_FEMALE  WA_MALE  WA_FEMALE  BA_MALE  BA_FEMALE  IA_MALE  \\\n",
       "0     26569       28002    21295      22002     4559       5130      119   \n",
       "1      1866        1713     1411       1316      362        317        5   \n",
       "2      2001        1990     1521       1526      399        374       14   \n",
       "3      2171        2119     1658       1620      431        406       15   \n",
       "4      2213        2077     1628       1585      502        424       12   \n",
       "\n",
       "   IA_FEMALE  AA_MALE  AA_FEMALE  NA_MALE  NA_FEMALE  TOM_MALE  TOM_FEMALE  \\\n",
       "0        139      200        284       29         18       367         429   \n",
       "1          3       13         15        1          0        74          62   \n",
       "2          8       17         21        1          3        49          58   \n",
       "3         12       23         18        4          1        40          62   \n",
       "4          7       25         14        4          2        42          45   \n",
       "\n",
       "   WAC_MALE  WAC_FEMALE  BAC_MALE  BAC_FEMALE  IAC_MALE  IAC_FEMALE  AAC_MALE  \\\n",
       "0     21633       22391      4704        5306       277         314       300   \n",
       "1      1479        1368       405         362        23          18        34   \n",
       "2      1570        1583       425         403        27          19        32   \n",
       "3      1694        1681       453         436        29          27        32   \n",
       "4      1664        1624       525         444        23          20        39   \n",
       "\n",
       "   AAC_FEMALE  NAC_MALE  NAC_FEMALE  NH_MALE  NH_FEMALE  NHWA_MALE  \\\n",
       "0         409        42          37    25875      27386      20709   \n",
       "1          28         3           1     1778       1651       1337   \n",
       "2          42         3           4     1933       1916       1460   \n",
       "3          37         4           5     2105       2055       1613   \n",
       "4          31         6           5     2153       2026       1580   \n",
       "\n",
       "   NHWA_FEMALE  NHBA_MALE  NHBA_FEMALE  NHIA_MALE  NHIA_FEMALE  NHAA_MALE  \\\n",
       "0        21485       4512         5091        103          115        194   \n",
       "1         1260        356          313          2            2         13   \n",
       "2         1465        398          372         12            2         17   \n",
       "3         1570        421          403         12            9         22   \n",
       "4         1543        495          420         12            5         23   \n",
       "\n",
       "   NHAA_FEMALE  NHNA_MALE  NHNA_FEMALE  NHTOM_MALE  NHTOM_FEMALE  NHWAC_MALE  \\\n",
       "0          280         13            9         344           406       21026   \n",
       "1           15          0            0          70            61        1402   \n",
       "2           21          0            3          46            53        1506   \n",
       "3           18          3            0          34            55        1643   \n",
       "4           14          1            1          42            43        1616   \n",
       "\n",
       "   NHWAC_FEMALE  NHBAC_MALE  NHBAC_FEMALE  NHIAC_MALE  NHIAC_FEMALE  \\\n",
       "0         21853        4647          5258         251           282   \n",
       "1          1312         396           357          19            17   \n",
       "2          1517         423           400          25            12   \n",
       "3          1624         440           429          24            22   \n",
       "4          1580         518           439          23            18   \n",
       "\n",
       "   NHAAC_MALE  NHAAC_FEMALE  NHNAC_MALE  NHNAC_FEMALE  H_MALE  H_FEMALE  \\\n",
       "0         291           398          23            27     694       616   \n",
       "1          34            28           1             0      88        62   \n",
       "2          30            39           1             4      68        74   \n",
       "3          30            36           3             4      66        64   \n",
       "4          37            30           3             4      60        51   \n",
       "\n",
       "   HWA_MALE  HWA_FEMALE  HBA_MALE  HBA_FEMALE  HIA_MALE  HIA_FEMALE  HAA_MALE  \\\n",
       "0       586         517        47          39        16          24         6   \n",
       "1        74          56         6           4         3           1         0   \n",
       "2        61          61         1           2         2           6         0   \n",
       "3        45          50        10           3         3           3         1   \n",
       "4        48          42         7           4         0           2         2   \n",
       "\n",
       "   HAA_FEMALE  HNA_MALE  HNA_FEMALE  HTOM_MALE  HTOM_FEMALE  HWAC_MALE  \\\n",
       "0           4        16           9         23           23        607   \n",
       "1           0         1           0          4            1         77   \n",
       "2           0         1           0          3            5         64   \n",
       "3           0         1           1          6            7         51   \n",
       "4           0         3           1          0            2         48   \n",
       "\n",
       "   HWAC_FEMALE  HBAC_MALE  HBAC_FEMALE  HIAC_MALE  HIAC_FEMALE  HAAC_MALE  \\\n",
       "0          538         57           48         26           32          9   \n",
       "1           56          9            5          4            1          0   \n",
       "2           66          2            3          2            7          2   \n",
       "3           57         13            7          5            5          2   \n",
       "4           44          7            5          0            2          2   \n",
       "\n",
       "   HAAC_FEMALE  HNAC_MALE  HNAC_FEMALE  \n",
       "0           11         19           10  \n",
       "1            0          2            1  \n",
       "2            3          2            0  \n",
       "3            1          1            1  \n",
       "4            1          3            1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics = pd.read_csv('../datasets/demographics/demographics.csv',encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map categorical variables to values from data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics = df_demographics.loc[:,['STATE', 'COUNTY', 'STNAME', 'CTYNAME', 'YEAR', 'AGEGRP', 'TOT_POP','TOT_MALE', 'TOT_FEMALE',\n",
    "    'WA_MALE','WA_FEMALE','BA_MALE','BA_FEMALE','IA_MALE','IA_FEMALE','AA_MALE','AA_FEMALE','NA_MALE','NA_FEMALE']]\n",
    "\n",
    "conditions=[((df_demographics['YEAR'] ==1) | (df_demographics['YEAR'] ==2) | (df_demographics['YEAR'] ==3)),\n",
    "            df_demographics['YEAR'] ==4, df_demographics['YEAR'] ==5, df_demographics['YEAR'] ==6, \n",
    "            df_demographics['YEAR'] ==7, df_demographics['YEAR'] ==8, df_demographics['YEAR'] ==9,\n",
    "            df_demographics['YEAR'] ==10, df_demographics['YEAR'] ==11, df_demographics['YEAR'] ==12]\n",
    "choices = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "df_demographics['YEAR'] = np.select(conditions, choices,default='N/A')\n",
    "\n",
    "conditions=[df_demographics['AGEGRP'] ==0, df_demographics['AGEGRP'] ==1, df_demographics['AGEGRP'] ==2, df_demographics['AGEGRP'] ==3,\n",
    "            df_demographics['AGEGRP'] ==4, df_demographics['AGEGRP'] ==5, df_demographics['AGEGRP'] ==6, \n",
    "            df_demographics['AGEGRP'] ==7, df_demographics['AGEGRP'] ==8, df_demographics['AGEGRP'] ==9,\n",
    "            df_demographics['AGEGRP'] ==10, df_demographics['AGEGRP'] ==11, df_demographics['AGEGRP'] ==12,\n",
    "           df_demographics['AGEGRP'] ==13, df_demographics['AGEGRP'] ==14, df_demographics['AGEGRP'] ==15,\n",
    "           df_demographics['AGEGRP'] ==16, df_demographics['AGEGRP'] ==17, df_demographics['AGEGRP'] ==18]\n",
    "choices = ['All Ages', 'Age 0 to 4 years', 'Age 5 to 9 years', 'Age 10 to 14 years', 'Age 15 to 19 years', \n",
    "           'Age 20 to 24 years', 'Age 25 to 29 years', 'Age 30 to 34 years', 'Age 35 to 39 years', \n",
    "           'Age 40 to 44 years', 'Age 45 to 49 years', 'Age 50 to 54 years', 'Age 55 to 59 years',\n",
    "           'Age 60 to 64 years', 'Age 65 to 69 years', 'Age 70 to 74 years', 'Age 75 to 79 years',\n",
    "            'Age 80 to 84 years', 'Age 85+']\n",
    "df_demographics['AGEGRP'] = np.select(conditions, choices,default='N/A')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new columns for totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics['TOT_WHITE'] = df_demographics['WA_MALE'] + df_demographics['WA_FEMALE']\n",
    "df_demographics['TOT_BLACK'] = df_demographics['BA_MALE'] + df_demographics['BA_FEMALE']\n",
    "df_demographics['TOT_NATIVE'] = df_demographics['IA_MALE'] + df_demographics['IA_FEMALE']\n",
    "df_demographics['TOT_ASIAN'] = df_demographics['AA_MALE'] + df_demographics['AA_FEMALE']\n",
    "df_demographics['TOT_PACIFIC'] = df_demographics['NA_MALE'] + df_demographics['NA_FEMALE']\n",
    "\n",
    "# drop unnecessary cols\n",
    "df_demographics.drop(['WA_MALE','WA_FEMALE','BA_MALE','BA_FEMALE','IA_MALE','IA_FEMALE',\n",
    "                      'AA_MALE','AA_FEMALE','NA_MALE','NA_FEMALE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics.rename(columns={'STATE':'FIPS_state', 'COUNTY':'FIPS_county', 'STNAME': 'State', 'CTYNAME':'County'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix format of FIPS columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_state</th>\n",
       "      <th>FIPS_county</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>AGEGRP</th>\n",
       "      <th>TOT_POP</th>\n",
       "      <th>TOT_MALE</th>\n",
       "      <th>TOT_FEMALE</th>\n",
       "      <th>TOT_WHITE</th>\n",
       "      <th>TOT_BLACK</th>\n",
       "      <th>TOT_NATIVE</th>\n",
       "      <th>TOT_ASIAN</th>\n",
       "      <th>TOT_PACIFIC</th>\n",
       "      <th>FIPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>54571</td>\n",
       "      <td>26569</td>\n",
       "      <td>28002</td>\n",
       "      <td>43297</td>\n",
       "      <td>9689</td>\n",
       "      <td>258</td>\n",
       "      <td>484</td>\n",
       "      <td>47</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>Age 0 to 4 years</td>\n",
       "      <td>3579</td>\n",
       "      <td>1866</td>\n",
       "      <td>1713</td>\n",
       "      <td>2727</td>\n",
       "      <td>679</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>Age 5 to 9 years</td>\n",
       "      <td>3991</td>\n",
       "      <td>2001</td>\n",
       "      <td>1990</td>\n",
       "      <td>3047</td>\n",
       "      <td>773</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>Age 10 to 14 years</td>\n",
       "      <td>4290</td>\n",
       "      <td>2171</td>\n",
       "      <td>2119</td>\n",
       "      <td>3278</td>\n",
       "      <td>837</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2010</td>\n",
       "      <td>Age 15 to 19 years</td>\n",
       "      <td>4290</td>\n",
       "      <td>2213</td>\n",
       "      <td>2077</td>\n",
       "      <td>3213</td>\n",
       "      <td>926</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716371</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2019</td>\n",
       "      <td>Age 65 to 69 years</td>\n",
       "      <td>499</td>\n",
       "      <td>280</td>\n",
       "      <td>219</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716372</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2019</td>\n",
       "      <td>Age 70 to 74 years</td>\n",
       "      <td>352</td>\n",
       "      <td>180</td>\n",
       "      <td>172</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716373</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2019</td>\n",
       "      <td>Age 75 to 79 years</td>\n",
       "      <td>229</td>\n",
       "      <td>107</td>\n",
       "      <td>122</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716374</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2019</td>\n",
       "      <td>Age 80 to 84 years</td>\n",
       "      <td>198</td>\n",
       "      <td>82</td>\n",
       "      <td>116</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716375</th>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>2019</td>\n",
       "      <td>Age 85+</td>\n",
       "      <td>200</td>\n",
       "      <td>72</td>\n",
       "      <td>128</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716376 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS_state FIPS_county    State          County  YEAR  \\\n",
       "0              01         001  Alabama  Autauga County  2010   \n",
       "1              01         001  Alabama  Autauga County  2010   \n",
       "2              01         001  Alabama  Autauga County  2010   \n",
       "3              01         001  Alabama  Autauga County  2010   \n",
       "4              01         001  Alabama  Autauga County  2010   \n",
       "...           ...         ...      ...             ...   ...   \n",
       "716371         56         045  Wyoming   Weston County  2019   \n",
       "716372         56         045  Wyoming   Weston County  2019   \n",
       "716373         56         045  Wyoming   Weston County  2019   \n",
       "716374         56         045  Wyoming   Weston County  2019   \n",
       "716375         56         045  Wyoming   Weston County  2019   \n",
       "\n",
       "                    AGEGRP  TOT_POP  TOT_MALE  TOT_FEMALE  TOT_WHITE  \\\n",
       "0                 All Ages    54571     26569       28002      43297   \n",
       "1         Age 0 to 4 years     3579      1866        1713       2727   \n",
       "2         Age 5 to 9 years     3991      2001        1990       3047   \n",
       "3       Age 10 to 14 years     4290      2171        2119       3278   \n",
       "4       Age 15 to 19 years     4290      2213        2077       3213   \n",
       "...                    ...      ...       ...         ...        ...   \n",
       "716371  Age 65 to 69 years      499       280         219        459   \n",
       "716372  Age 70 to 74 years      352       180         172        342   \n",
       "716373  Age 75 to 79 years      229       107         122        225   \n",
       "716374  Age 80 to 84 years      198        82         116        195   \n",
       "716375             Age 85+      200        72         128        195   \n",
       "\n",
       "        TOT_BLACK  TOT_NATIVE  TOT_ASIAN  TOT_PACIFIC   FIPS  \n",
       "0            9689         258        484           47  01001  \n",
       "1             679           8         28            1  01001  \n",
       "2             773          22         38            4  01001  \n",
       "3             837          27         41            5  01001  \n",
       "4             926          19         39            6  01001  \n",
       "...           ...         ...        ...          ...    ...  \n",
       "716371          1           2         31            0  56045  \n",
       "716372          0           2          4            0  56045  \n",
       "716373          0           2          0            0  56045  \n",
       "716374          0           2          0            0  56045  \n",
       "716375          0           2          1            0  56045  \n",
       "\n",
       "[716376 rows x 15 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics['FIPS_county'] = np.select([df_demographics['FIPS_county']<10, df_demographics['FIPS_county']<100],\n",
    "                    ['00'+df_demographics['FIPS_county'].astype(str), '0'+df_demographics['FIPS_county'].astype(str)],\n",
    "                    default= df_demographics['FIPS_county'].astype(str))\n",
    "df_demographics['FIPS_state'] = np.where(df_demographics['FIPS_state']<10, \n",
    "                        '0'+df_demographics['FIPS_state'].astype(str), df_demographics['FIPS_state'].astype(str))\n",
    "\n",
    "# Create main fips code\n",
    "df_demographics['FIPS'] = df_demographics['FIPS_state'] + df_demographics['FIPS_county']\n",
    "df_demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Houselessness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_houseless_19 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2019')\n",
    "df_houseless_18 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2018')\n",
    "df_houseless_17 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2017')\n",
    "df_houseless_16 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2016')\n",
    "df_houseless_15 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2015')\n",
    "df_houseless_14 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2014')\n",
    "df_houseless_13 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2013')\n",
    "df_houseless_12 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2012')\n",
    "df_houseless_11 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2011')\n",
    "df_houseless_10 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2010')\n",
    "df_houseless_09 = pd.read_excel('../datasets/houseless/houseless_coc.xlsx', sheet_name='2009')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim down unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houseless_19 = df_houseless_19.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2019', 'Sheltered Total Homeless, 2019', 'Unsheltered Homeless, 2019']]\n",
    "df_houseless_18 = df_houseless_18.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2018', 'Sheltered Total Homeless, 2018', 'Unsheltered Homeless, 2018']]\n",
    "df_houseless_17 = df_houseless_17.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2017', 'Sheltered Total Homeless, 2017', 'Unsheltered Homeless, 2017']]\n",
    "df_houseless_16 = df_houseless_16.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2016', 'Sheltered Total Homeless, 2016', 'Unsheltered Homeless, 2016']]\n",
    "df_houseless_15 = df_houseless_15.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2015', 'Sheltered Total Homeless, 2015', 'Unsheltered Homeless, 2015']]\n",
    "df_houseless_14 = df_houseless_14.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2014', 'Sheltered Total Homeless, 2014', 'Unsheltered Homeless, 2014']]\n",
    "df_houseless_13 = df_houseless_13.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2013', 'Sheltered Total Homeless, 2013', 'Unsheltered Homeless, 2013']]\n",
    "df_houseless_12 = df_houseless_12.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2012', 'Sheltered Total Homeless, 2012', 'Unsheltered Homeless, 2012']]\n",
    "df_houseless_11 = df_houseless_11.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2011', 'Sheltered Total Homeless, 2011', 'Unsheltered Homeless, 2011']]\n",
    "df_houseless_10 = df_houseless_10.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2010', 'Sheltered Total Homeless, 2010', 'Unsheltered Homeless, 2010']]\n",
    "df_houseless_09 = df_houseless_09.loc[:,['CoC Number', 'CoC Name','Overall Homeless, 2009', 'Sheltered Total Homeless, 2009', 'Unsheltered Homeless, 2009']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houseless_19.rename(columns={'Overall Homeless, 2019':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2019': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2019': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_18.rename(columns={'Overall Homeless, 2018':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2018': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2018': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_17.rename(columns={'Overall Homeless, 2017':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2017': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2017': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_16.rename(columns={'Overall Homeless, 2016':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2016': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2016': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_15.rename(columns={'Overall Homeless, 2015':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2015': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2015': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_14.rename(columns={'Overall Homeless, 2014':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2014': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2014': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_13.rename(columns={'Overall Homeless, 2013':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2013': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2013': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_12.rename(columns={'Overall Homeless, 2012':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2012': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2012': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_11.rename(columns={'Overall Homeless, 2011':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2011': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2011': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_10.rename(columns={'Overall Homeless, 2010':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2010': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2010': 'Unsheltered_houseless'}, inplace=True)\n",
    "df_houseless_09.rename(columns={'Overall Homeless, 2009':'Tot_houseless', \n",
    "                       'Sheltered Total Homeless, 2009': 'Sheltered_houseless',\n",
    "                       'Unsheltered Homeless, 2009': 'Unsheltered_houseless'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Subtask: Map CoC's to Counties\n",
    "Method: merge CoC column to demographics df to get population perCoC.<br>\n",
    "Join that with houseless df to derive houseless rate per CoC.<br>\n",
    "Join that to CoC_county to get houseless rate per county.<br>\n",
    "(optional) Join rates back with demographic df to get number of houseless, per county<br>\n",
    "Source: https://github.com/tomhbyrne/HUD-CoC-Geography-Crosswalk/blob/master/output/county_coc_match.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import csv that maps counties to a CoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoC_county = pd.read_csv('../datasets/houseless/county_coc_match.csv', encoding='ISO-8859-1')\n",
    "CoC_county = coc_county.loc[:,['county_fips','coc_number']]\n",
    "\n",
    "# rename columns\n",
    "CoC_county.rename(columns={'county_fips':'FIPS'}, inplace=True)\n",
    "\n",
    "# drop 2 rows with no FIPS\n",
    "CoC_county.drop(CoC_county[CoC_county['FIPS'].isnull()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix format of FIPS column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change FIPS to string and add leading zeros if needed\n",
    "CoC_county['FIPS'] = np.where(CoC_county['FIPS']<10000, \n",
    "                        '0'+CoC_county['FIPS'].astype(int).astype(str), CoC_county['FIPS'].astype(int).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge CoC mapping with demographics df to get population count per CoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get total population by county\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2010') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "# merge with CoC_county to get pop count per CoC\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_10 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# repeat for each year\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2011') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_11 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2012\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2012') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_12 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2013\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2013') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_13 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2014\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2014') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_14 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2015\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2015') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_15 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2016\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2016') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_16 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2017\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2017') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_17 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2018\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2018') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_18 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n",
    "\n",
    "# 2019\n",
    "avg = df_demographics[(df_demographics['YEAR']=='2019') & (df_demographics['AGEGRP']=='All Ages')].groupby('FIPS').mean()\n",
    "merged = avg.merge(CoC_county, on='FIPS', how='left')\n",
    "pop_per_coc_19 = merged.groupby('coc_number').sum()['TOT_POP'].reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge population count per CoC with houselessness df to derive houselessness rate per CoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get houseless rate per CoC \n",
    "# 2010\n",
    "merged = pop_per_coc_10.merge(df_houseless_10, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_10 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2011\n",
    "merged = pop_per_coc_11.merge(df_houseless_11, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_11 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2012\n",
    "merged = pop_per_coc_12.merge(df_houseless_12, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_12 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2013\n",
    "merged = pop_per_coc_13.merge(df_houseless_13, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_13 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2014\n",
    "merged = pop_per_coc_14.merge(df_houseless_14, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_14 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2015\n",
    "merged = pop_per_coc_15.merge(df_houseless_15, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_15 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2016\n",
    "merged = pop_per_coc_16.merge(df_houseless_16, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_16 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2017\n",
    "merged = pop_per_coc_17.merge(df_houseless_17, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_17 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2018\n",
    "merged = pop_per_coc_18.merge(df_houseless_18, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_18 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]\n",
    "\n",
    "# 2019\n",
    "merged = pop_per_coc_19.merge(df_houseless_19, left_on='coc_number', right_on='CoC Number')\n",
    "merged['Houseless_rate'] = merged['Tot_houseless']/merged['TOT_POP'] \n",
    "merged['Sheltered_rate'] = merged['Sheltered_houseless']/merged['TOT_POP'] \n",
    "merged['Unsheltered_rate'] = merged['Unsheltered_houseless']/merged['TOT_POP'] \n",
    "rates_19 = merged.loc[:,['coc_number', 'Houseless_rate','Sheltered_rate','Unsheltered_rate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge CoC rates with CoC_county mapping to get houseless rates per county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coc_number</th>\n",
       "      <th>Houseless_rate</th>\n",
       "      <th>Sheltered_rate</th>\n",
       "      <th>Unsheltered_rate</th>\n",
       "      <th>FIPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK-500</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>02020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>02013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>02016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>02050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>02060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>56037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>56039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>56041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>56043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>WY-500</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3163 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coc_number  Houseless_rate  Sheltered_rate  Unsheltered_rate   FIPS\n",
       "0        AK-500        0.003858        0.003521          0.000337  02020\n",
       "1        AK-501        0.001795        0.001398          0.000397  02013\n",
       "2        AK-501        0.001795        0.001398          0.000397  02016\n",
       "3        AK-501        0.001795        0.001398          0.000397  02050\n",
       "4        AK-501        0.001795        0.001398          0.000397  02060\n",
       "...         ...             ...             ...               ...    ...\n",
       "3158     WY-500        0.000947        0.000731          0.000216  56037\n",
       "3159     WY-500        0.000947        0.000731          0.000216  56039\n",
       "3160     WY-500        0.000947        0.000731          0.000216  56041\n",
       "3161     WY-500        0.000947        0.000731          0.000216  56043\n",
       "3162     WY-500        0.000947        0.000731          0.000216  56045\n",
       "\n",
       "[3163 rows x 5 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get houseless rate per county, for each year\n",
    "df_houseless_10 = rates_10.merge(CoC_county, on='coc_number')\n",
    "df_houseless_11 = rates_11.merge(CoC_county, on='coc_number')\n",
    "df_houseless_12 = rates_12.merge(CoC_county, on='coc_number')\n",
    "df_houseless_13 = rates_13.merge(CoC_county, on='coc_number')\n",
    "df_houseless_14 = rates_14.merge(CoC_county, on='coc_number')\n",
    "df_houseless_15 = rates_15.merge(CoC_county, on='coc_number')\n",
    "df_houseless_16 = rates_16.merge(CoC_county, on='coc_number')\n",
    "df_houseless_17 = rates_17.merge(CoC_county, on='coc_number')\n",
    "df_houseless_18 = rates_18.merge(CoC_county, on='coc_number')\n",
    "df_houseless_19 = rates_19.merge(CoC_county, on='coc_number')\n",
    "df_houseless_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Rent Prices\n",
    "Zillow Observed Rent Index (ZORI): A smoothed measure of the typical observed market rate rent across a given region. ZORI is a repeat-rent index that is weighted to the rental housing stock to ensure representativeness across the entire market, not just those homes currently listed for-rent. The index is dollar-denominated by computing the mean of listed rents that fall into the 40th to 60th percentile range for all homes and apartments in a given region, which is once again weighted to reflect the rental housing stock. Details available in ZORI methodology.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take averages of months in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Zillow dataset\n",
    "df_rent = pd.read_csv('../datasets/rent_prices/rent_prices.csv')\n",
    "\n",
    "# isolate columns corresponding to each year, and make new column\n",
    "drop_14 = df_rent.columns[df_rent.columns.str.contains('2014')]\n",
    "df_rent['2014'] = df_rent.loc[:,drop_14].mean(axis=1)\n",
    "\n",
    "drop_15 = df_rent.columns[df_rent.columns.str.contains('2015')]\n",
    "df_rent['2015'] = df_rent.loc[:,drop_15].mean(axis=1)\n",
    "\n",
    "drop_16 = df_rent.columns[df_rent.columns.str.contains('2016')]\n",
    "df_rent['2016'] = df_rent.loc[:,drop_16].mean(axis=1)\n",
    "\n",
    "drop_17 = df_rent.columns[df_rent.columns.str.contains('2017')]\n",
    "df_rent['2017'] = df_rent.loc[:,drop_17].mean(axis=1)\n",
    "\n",
    "drop_18 = df_rent.columns[df_rent.columns.str.contains('2018')]\n",
    "df_rent['2018'] = df_rent.loc[:,drop_18].mean(axis=1)\n",
    "\n",
    "drop_19 = df_rent.columns[df_rent.columns.str.contains('2019')]\n",
    "df_rent['2019'] = df_rent.loc[:,drop_19].mean(axis=1)\n",
    "\n",
    "drop_20 = df_rent.columns[df_rent.columns.str.contains('2020')]\n",
    "df_rent['2020'] = df_rent.loc[:,drop_20].mean(axis=1)\n",
    "\n",
    "# drop all monthly data\n",
    "to_drop = drop_14.append(drop_15).append(drop_16).append(drop_17).append(drop_18).append(drop_19).append(drop_20)\n",
    "df_rent.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rent.rename(columns={'RegionName':'Zipcode', 'MsaName':'City/State'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Zipcodes to counties\n",
    "Method: join county data to each zipcode, then groupby county and take mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>City/State</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61639</td>\n",
       "      <td>10025</td>\n",
       "      <td>1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>3075.083333</td>\n",
       "      <td>3188.666667</td>\n",
       "      <td>3222.416667</td>\n",
       "      <td>3215.500000</td>\n",
       "      <td>3214.416667</td>\n",
       "      <td>3271.500000</td>\n",
       "      <td>3145.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>2</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1605.416667</td>\n",
       "      <td>1662.583333</td>\n",
       "      <td>1718.666667</td>\n",
       "      <td>1753.083333</td>\n",
       "      <td>1765.416667</td>\n",
       "      <td>1801.916667</td>\n",
       "      <td>1802.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61637</td>\n",
       "      <td>10023</td>\n",
       "      <td>3</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>3181.416667</td>\n",
       "      <td>3252.833333</td>\n",
       "      <td>3282.250000</td>\n",
       "      <td>3278.500000</td>\n",
       "      <td>3291.750000</td>\n",
       "      <td>3353.000000</td>\n",
       "      <td>3227.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>4</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>1760.416667</td>\n",
       "      <td>1769.916667</td>\n",
       "      <td>1715.750000</td>\n",
       "      <td>1703.083333</td>\n",
       "      <td>1733.500000</td>\n",
       "      <td>1752.000000</td>\n",
       "      <td>1772.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>5</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1773.333333</td>\n",
       "      <td>1837.250000</td>\n",
       "      <td>1910.666667</td>\n",
       "      <td>1939.833333</td>\n",
       "      <td>1967.083333</td>\n",
       "      <td>2014.416667</td>\n",
       "      <td>2013.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>58624</td>\n",
       "      <td>2110</td>\n",
       "      <td>9469</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>4207.000000</td>\n",
       "      <td>4426.222222</td>\n",
       "      <td>4711.636364</td>\n",
       "      <td>4829.100000</td>\n",
       "      <td>4675.000000</td>\n",
       "      <td>4800.916667</td>\n",
       "      <td>4479.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>66128</td>\n",
       "      <td>20004</td>\n",
       "      <td>9592</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>2276.400000</td>\n",
       "      <td>2323.818182</td>\n",
       "      <td>2390.727273</td>\n",
       "      <td>2423.083333</td>\n",
       "      <td>2396.833333</td>\n",
       "      <td>2415.000000</td>\n",
       "      <td>2465.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>399647</td>\n",
       "      <td>80951</td>\n",
       "      <td>9634</td>\n",
       "      <td>Colorado Springs, CO</td>\n",
       "      <td>1260.090909</td>\n",
       "      <td>1312.666667</td>\n",
       "      <td>1383.916667</td>\n",
       "      <td>1451.800000</td>\n",
       "      <td>1532.363636</td>\n",
       "      <td>1608.909091</td>\n",
       "      <td>1669.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>62128</td>\n",
       "      <td>11509</td>\n",
       "      <td>9912</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14126.000000</td>\n",
       "      <td>13123.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>84604</td>\n",
       "      <td>60602</td>\n",
       "      <td>10262</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2691.166667</td>\n",
       "      <td>2711.428571</td>\n",
       "      <td>2924.444444</td>\n",
       "      <td>2839.272727</td>\n",
       "      <td>2839.444444</td>\n",
       "      <td>2763.600000</td>\n",
       "      <td>2596.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3264 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RegionID  Zipcode  SizeRank            City/State         2014  \\\n",
       "0        61639    10025         1          New York, NY  3075.083333   \n",
       "1        84654    60657         2           Chicago, IL  1605.416667   \n",
       "2        61637    10023         3          New York, NY  3181.416667   \n",
       "3        91982    77494         4           Houston, TX  1760.416667   \n",
       "4        84616    60614         5           Chicago, IL  1773.333333   \n",
       "...        ...      ...       ...                   ...          ...   \n",
       "3259     58624     2110      9469            Boston, MA  4207.000000   \n",
       "3260     66128    20004      9592        Washington, DC  2276.400000   \n",
       "3261    399647    80951      9634  Colorado Springs, CO  1260.090909   \n",
       "3262     62128    11509      9912          New York, NY          NaN   \n",
       "3263     84604    60602     10262           Chicago, IL  2691.166667   \n",
       "\n",
       "             2015         2016          2017          2018         2019  \\\n",
       "0     3188.666667  3222.416667   3215.500000   3214.416667  3271.500000   \n",
       "1     1662.583333  1718.666667   1753.083333   1765.416667  1801.916667   \n",
       "2     3252.833333  3282.250000   3278.500000   3291.750000  3353.000000   \n",
       "3     1769.916667  1715.750000   1703.083333   1733.500000  1752.000000   \n",
       "4     1837.250000  1910.666667   1939.833333   1967.083333  2014.416667   \n",
       "...           ...          ...           ...           ...          ...   \n",
       "3259  4426.222222  4711.636364   4829.100000   4675.000000  4800.916667   \n",
       "3260  2323.818182  2390.727273   2423.083333   2396.833333  2415.000000   \n",
       "3261  1312.666667  1383.916667   1451.800000   1532.363636  1608.909091   \n",
       "3262          NaN          NaN  14126.000000  13123.000000          NaN   \n",
       "3263  2711.428571  2924.444444   2839.272727   2839.444444  2763.600000   \n",
       "\n",
       "             2020  \n",
       "0     3145.600000  \n",
       "1     1802.700000  \n",
       "2     3227.700000  \n",
       "3     1772.000000  \n",
       "4     2013.700000  \n",
       "...           ...  \n",
       "3259  4479.500000  \n",
       "3260  2465.900000  \n",
       "3261  1669.333333  \n",
       "3262          NaN  \n",
       "3263  2596.100000  \n",
       "\n",
       "[3264 rows x 11 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Businesses Data\n",
    "Data Dict: https://www2.census.gov/programs-surveys/cbp/technical-documentation/records-layouts/2018_record_layouts/county-layout-2018.txt\n",
    "<br>\n",
    "naics dict: https://www2.census.gov/programs-surveys/cbp/technical-documentation/reference/naics-descriptions/naics2017.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business_09 = pd.read_csv('../datasets/businesses/bus_09.txt')\n",
    "df_business_10 = pd.read_csv('../datasets/businesses/bus_10.txt')\n",
    "df_business_11 = pd.read_csv('../datasets/businesses/bus_11.txt')\n",
    "df_business_12 = pd.read_csv('../datasets/businesses/bus_12.txt')\n",
    "df_business_13 = pd.read_csv('../datasets/businesses/bus_13.txt')\n",
    "df_business_14 = pd.read_csv('../datasets/businesses/bus_14.txt')\n",
    "df_business_15 = pd.read_csv('../datasets/businesses/bus_15.txt')\n",
    "df_business_16 = pd.read_csv('../datasets/businesses/bus_16.txt')\n",
    "df_business_17 = pd.read_csv('../datasets/businesses/bus_17.txt')\n",
    "df_business_18 = pd.read_csv('../datasets/businesses/bus_18.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns and rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "df_business_09 = df_business_09.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_09 = df_business_09.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2010\n",
    "df_business_10 = df_business_10.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_10 = df_business_10.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2011\n",
    "df_business_11 = df_business_11.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_11 = df_business_11.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2012\n",
    "df_business_12 = df_business_12.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_12 = df_business_12.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2013\n",
    "df_business_13 = df_business_13.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_13 = df_business_13.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2014\n",
    "df_business_14 = df_business_14.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_14 = df_business_14.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2015\n",
    "df_business_15 = df_business_15.loc[:,['FIPSTATE', 'FIPSCTY', 'NAICS', 'EST']]\n",
    "df_business_15 = df_business_15.rename(columns={'FIPSTATE': 'FIPS_state', 'FIPSCTY':'FIPS_county', \n",
    "                                'NAICS':'Industry','EST':'Num_establishments'})\n",
    "# 2016\n",
    "df_business_16 = df_business_16.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_16 = df_business_16.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2017\n",
    "df_business_17 = df_business_17.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_17 = df_business_17.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n",
    "# 2018\n",
    "df_business_18 = df_business_18.loc[:,['fipstate', 'fipscty', 'naics', 'est']]\n",
    "df_business_18 = df_business_18.rename(columns={'fipstate': 'FIPS_state', 'fipscty':'FIPS_county', \n",
    "                                'naics':'Industry','est':'Num_establishments'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change FIPS codes and join together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add leading zeros to FIPS codes, and concat state and county FIPS codes\n",
    "# 2009\n",
    "df_business_09['FIPS_county'] = np.select([df_business_09['FIPS_county']<10, df_business_09['FIPS_county']<100],\n",
    "                    ['00'+df_business_09['FIPS_county'].astype(str), '0'+df_business_09['FIPS_county'].astype(str)],\n",
    "                    default= df_business_09['FIPS_county'].astype(str))\n",
    "df_business_09['FIPS_state'] = np.where(df_business_09['FIPS_state']<10, \n",
    "                        '0'+df_business_09['FIPS_state'].astype(str), df_business_09['FIPS_state'].astype(str))\n",
    "df_business_09['FIPS'] = df_business_09['FIPS_state'] + df_business_09['FIPS_county']\n",
    "\n",
    "# 2010\n",
    "df_business_10['FIPS_county'] = np.select([df_business_10['FIPS_county']<10, df_business_10['FIPS_county']<100],\n",
    "                    ['00'+df_business_10['FIPS_county'].astype(str), '0'+df_business_10['FIPS_county'].astype(str)],\n",
    "                    default= df_business_10['FIPS_county'].astype(str))\n",
    "df_business_10['FIPS_state'] = np.where(df_business_10['FIPS_state']<10, \n",
    "                        '0'+df_business_10['FIPS_state'].astype(str), df_business_10['FIPS_state'].astype(str))\n",
    "df_business_10['FIPS'] = df_business_10['FIPS_state'] + df_business_10['FIPS_county']\n",
    "\n",
    "# 2011\n",
    "df_business_11['FIPS_county'] = np.select([df_business_11['FIPS_county']<10, df_business_11['FIPS_county']<100],\n",
    "                    ['00'+df_business_11['FIPS_county'].astype(str), '0'+df_business_11['FIPS_county'].astype(str)],\n",
    "                    default= df_business_11['FIPS_county'].astype(str))\n",
    "df_business_11['FIPS_state'] = np.where(df_business_11['FIPS_state']<10, \n",
    "                        '0'+df_business_11['FIPS_state'].astype(str), df_business_11['FIPS_state'].astype(str))\n",
    "df_business_11['FIPS'] = df_business_11['FIPS_state'] + df_business_11['FIPS_county']\n",
    "\n",
    "# 2012\n",
    "df_business_12['FIPS_county'] = np.select([df_business_12['FIPS_county']<10, df_business_12['FIPS_county']<100],\n",
    "                    ['00'+df_business_12['FIPS_county'].astype(str), '0'+df_business_12['FIPS_county'].astype(str)],\n",
    "                    default= df_business_12['FIPS_county'].astype(str))\n",
    "df_business_12['FIPS_state'] = np.where(df_business_12['FIPS_state']<10, \n",
    "                        '0'+df_business_12['FIPS_state'].astype(str), df_business_12['FIPS_state'].astype(str))\n",
    "df_business_12['FIPS'] = df_business_12['FIPS_state'] + df_business_12['FIPS_county']\n",
    "\n",
    "# 2013\n",
    "df_business_13['FIPS_county'] = np.select([df_business_13['FIPS_county']<10, df_business_13['FIPS_county']<100],\n",
    "                    ['00'+df_business_13['FIPS_county'].astype(str), '0'+df_business_13['FIPS_county'].astype(str)],\n",
    "                    default= df_business_13['FIPS_county'].astype(str))\n",
    "df_business_13['FIPS_state'] = np.where(df_business_13['FIPS_state']<10, \n",
    "                        '0'+df_business_13['FIPS_state'].astype(str), df_business_13['FIPS_state'].astype(str))\n",
    "df_business_13['FIPS'] = df_business_13['FIPS_state'] + df_business_13['FIPS_county']\n",
    "\n",
    "# 2014\n",
    "df_business_14['FIPS_county'] = np.select([df_business_14['FIPS_county']<10, df_business_14['FIPS_county']<100],\n",
    "                    ['00'+df_business_14['FIPS_county'].astype(str), '0'+df_business_14['FIPS_county'].astype(str)],\n",
    "                    default= df_business_14['FIPS_county'].astype(str))\n",
    "df_business_14['FIPS_state'] = np.where(df_business_14['FIPS_state']<10, \n",
    "                        '0'+df_business_14['FIPS_state'].astype(str), df_business_14['FIPS_state'].astype(str))\n",
    "df_business_14['FIPS'] = df_business_14['FIPS_state'] + df_business_14['FIPS_county']\n",
    "\n",
    "# 2015\n",
    "df_business_15['FIPS_county'] = np.select([df_business_15['FIPS_county']<10, df_business_15['FIPS_county']<100],\n",
    "                    ['00'+df_business_15['FIPS_county'].astype(str), '0'+df_business_15['FIPS_county'].astype(str)],\n",
    "                    default= df_business_15['FIPS_county'].astype(str))\n",
    "df_business_15['FIPS_state'] = np.where(df_business_15['FIPS_state']<10, \n",
    "                        '0'+df_business_15['FIPS_state'].astype(str), df_business_15['FIPS_state'].astype(str))\n",
    "df_business_15['FIPS'] = df_business_15['FIPS_state'] + df_business_15['FIPS_county']\n",
    "\n",
    "# 2016\n",
    "df_business_16['FIPS_county'] = np.select([df_business_16['FIPS_county']<10, df_business_16['FIPS_county']<100],\n",
    "                    ['00'+df_business_16['FIPS_county'].astype(str), '0'+df_business_16['FIPS_county'].astype(str)],\n",
    "                    default= df_business_16['FIPS_county'].astype(str))\n",
    "df_business_16['FIPS_state'] = np.where(df_business_16['FIPS_state']<10, \n",
    "                        '0'+df_business_16['FIPS_state'].astype(str), df_business_16['FIPS_state'].astype(str))\n",
    "df_business_16['FIPS'] = df_business_16['FIPS_state'] + df_business_16['FIPS_county']\n",
    "\n",
    "# 2017\n",
    "df_business_17['FIPS_county'] = np.select([df_business_17['FIPS_county']<10, df_business_17['FIPS_county']<100],\n",
    "                    ['00'+df_business_17['FIPS_county'].astype(str), '0'+df_business_17['FIPS_county'].astype(str)],\n",
    "                    default= df_business_17['FIPS_county'].astype(str))\n",
    "df_business_17['FIPS_state'] = np.where(df_business_17['FIPS_state']<10, \n",
    "                        '0'+df_business_17['FIPS_state'].astype(str), df_business_17['FIPS_state'].astype(str))\n",
    "df_business_17['FIPS'] = df_business_17['FIPS_state'] + df_business_17['FIPS_county']\n",
    "\n",
    "# 2018\n",
    "df_business_18['FIPS_county'] = np.select([df_business_18['FIPS_county']<10, df_business_18['FIPS_county']<100],\n",
    "                    ['00'+df_business_18['FIPS_county'].astype(str), '0'+df_business_18['FIPS_county'].astype(str)],\n",
    "                    default= df_business_18['FIPS_county'].astype(str))\n",
    "df_business_18['FIPS_state'] = np.where(df_business_18['FIPS_state']<10, \n",
    "                        '0'+df_business_18['FIPS_state'].astype(str), df_business_18['FIPS_state'].astype(str))\n",
    "df_business_18['FIPS'] = df_business_18['FIPS_state'] + df_business_18['FIPS_county']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate rows for each type of food establishment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_09[df_business_09['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_09[df_business_09['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_09[df_business_09['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2010\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_10[df_business_10['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_10[df_business_10['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_10[df_business_10['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2011\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_11[df_business_11['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_11[df_business_11['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_11[df_business_11['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2012\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_12[df_business_12['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_12[df_business_12['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_12[df_business_12['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2013\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_13[df_business_13['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_13[df_business_13['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_13[df_business_13['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2014\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_14[df_business_14['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_14[df_business_14['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_14[df_business_14['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2015\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_15[df_business_15['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_15[df_business_15['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_15[df_business_15['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2016\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_16[df_business_16['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_16[df_business_16['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_16[df_business_16['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2017\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_17[df_business_17['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_17[df_business_17['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_17[df_business_17['Industry'].isin(wholesale)].index\n",
    "\n",
    "# 2018\n",
    "restaraunts = ['72233/', '722330', '722///', '7224//', '72241/', '722410', '7225//', '72251/', '722511', '722513', '722514', '722515']\n",
    "restaraunt_indices = df_business_18[df_business_18['Industry'].isin(restaraunts)].index\n",
    "grocery = ['445///', '4451//', '44511/', '445110', '44512/', '445120', '4452//', '44521/', '445210', '44522/', '445220', '44523/', '445230', '44529/', '445291', '445292', '445299', '4453//', '44531/', '445310', '446///', '4461//', '44611/', '446110']\n",
    "grocery_indices = df_business_18[df_business_18['Industry'].isin(grocery)].index\n",
    "wholesale = ['4244//', '42441/', '424410', '42442/', '424420', '42443/', '424430', '42444/', '424440', '42445/', '424450', '42446/', '424460', '42447/', '424470', '42448/', '424480', '42449/', '424490', '4245//', '42451/', '424510', '42452/', '424520', '42459/', '424590']\n",
    "wholesale_indices = df_business_18[df_business_18['Industry'].isin(wholesale)].index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group dataframe by type of establishment, and sum # of businesses in each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2009\n",
    "restaraunt_df = df_business_09.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_09.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_09.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_09 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2010\n",
    "restaraunt_df = df_business_10.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_10.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_10.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_10 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2011\n",
    "restaraunt_df = df_business_11.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_11.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_11.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_11 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2012\n",
    "restaraunt_df = df_business_12.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_12.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_12.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_12 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2013\n",
    "restaraunt_df = df_business_13.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_13.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_13.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_13 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2014\n",
    "restaraunt_df = df_business_14.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_14.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_14.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_14 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2015\n",
    "restaraunt_df = df_business_15.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_15.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_15.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_15 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2016\n",
    "restaraunt_df = df_business_16.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_16.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_16.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_16 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2017\n",
    "restaraunt_df = df_business_17.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_17.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_17.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_17 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n",
    "# 2018\n",
    "restaraunt_df = df_business_18.loc[restaraunt_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "restaraunt_df.rename(columns={'Num_establishments':'Num_restaraunts'},inplace=True)\n",
    "grocery_df = df_business_18.loc[grocery_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "grocery_df.rename(columns={'Num_establishments':'Num_grocery'},inplace=True)\n",
    "wholesale_df = df_business_18.loc[wholesale_indices,['FIPS', 'Num_establishments']].groupby('FIPS').sum().reset_index()\n",
    "wholesale_df.rename(columns={'Num_establishments':'Num_wholesale'},inplace=True)\n",
    "# merge three df's together\n",
    "df_food_18 = wholesale_df.merge(restaraunt_df, how='outer',on='FIPS').merge(grocery_df, on='FIPS', how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Num_wholesale</th>\n",
       "      <th>Num_restaraunts</th>\n",
       "      <th>Num_grocery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>23.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01005</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01013</td>\n",
       "      <td>8.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01015</td>\n",
       "      <td>55.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>29063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>29075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>29089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>29197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>29227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1550 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS  Num_wholesale  Num_restaraunts  Num_grocery\n",
       "0     01001           23.0            129.0        242.0\n",
       "1     01005            7.0              7.0         55.0\n",
       "2     01009            1.0             48.0         71.0\n",
       "3     01013            8.0            512.0         12.0\n",
       "4     01015           55.0            256.0        629.0\n",
       "...     ...            ...              ...          ...\n",
       "1545  29063            NaN              NaN         38.0\n",
       "1546  29075            NaN              NaN         19.0\n",
       "1547  29089            NaN              NaN         81.0\n",
       "1548  29197            NaN              NaN         17.0\n",
       "1549  29227            NaN              NaN         35.0\n",
       "\n",
       "[1550 rows x 4 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
