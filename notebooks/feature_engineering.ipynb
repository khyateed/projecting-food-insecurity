{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "## Projecting Food Insecurity Rates in 2020\n",
    "### Khyatee Desai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "pd.set_option('display.max_columns', None)\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickled/fully_cleaned_data.pickle', \"rb\") as input_file:\n",
    "    df = pickle.load(input_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derived Features\n",
    "New columns, derived from existing features\n",
    "### Demographics Percentage Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Percent_male'] = df['TOT_MALE']/df['TOT_POP']\n",
    "df['Percent_female'] = df['TOT_FEMALE']/df['TOT_POP']\n",
    "df['Percent_white'] = df['TOT_WHITE']/df['TOT_POP']\n",
    "df['Percent_Black'] = df['TOT_BLACK']/df['TOT_POP']\n",
    "df['Percent_native'] = df['TOT_NATIVE']/df['TOT_POP']\n",
    "df['Percent_asian'] = df['TOT_ASIAN']/df['TOT_POP']\n",
    "df['Percent_pacific'] = df['TOT_PACIFIC']/df['TOT_POP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workforce as a percentage of total population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent of population that is working\n",
    "df['Percent_working'] = df['Total_workforce']/df['TOT_POP']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of Food Establishments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total_food_retail'] = df['Num_wholesale']+ df['Num_restaraunts']+df['Num_grocery']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population divided by number of food establishments \n",
    "Looking at prevalence of food establishments as a function of population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Food_retail_per_person'] = df['Total_food_retail']/df['TOT_POP']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_scale = ['Rent', 'Houseless_rate',\n",
    "#        'Sheltered_rate', 'Unsheltered_rate','TOT_POP', 'TOT_MALE', 'TOT_FEMALE', 'TOT_WHITE',\n",
    "#        'TOT_BLACK', 'TOT_NATIVE', 'TOT_ASIAN', 'TOT_PACIFIC',\n",
    "#        'FI Rate', 'Weighted Annual Dollars', 'Cost Per Meal', 'Num_wholesale',\n",
    "#        'Num_restaraunts', 'Num_grocery', 'Total_workforce', 'Employed',\n",
    "#        'Unemployed', 'Unemployment_rate', 'Percent_male', 'Percent_female',\n",
    "#        'Percent_white', 'Percent_Black', 'Percent_native', 'Percent_asian',\n",
    "#        'Percent_pacific', 'Percent_workforce', 'Total_food_retail',\n",
    "#        'Food_retail_per_person']\n",
    "\n",
    "# for feat in to_scale:\n",
    "#     df['scaled_'+feat] = (df[feat] - min(df[feat])) / (max(df[feat]) - min(df[feat]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using derived percentages, removed raw counts\n",
    "continuous_features = ['Rent', 'Houseless_rate','Sheltered_rate', 'Unsheltered_rate', 'TOT_POP',\n",
    "       'Cost Per Meal', 'Num_wholesale','Num_restaraunts', 'Num_grocery',  'Unemployment_rate', 'Percent_male', \n",
    "         'Percent_female','Percent_white', 'Percent_Black', 'Percent_native', 'Percent_asian',\n",
    "       'Percent_pacific', 'Percent_working', 'Total_food_retail','Food_retail_per_person']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feat in continuous_features:\n",
    "    df[feat+'^2'] = df[feat]**2\n",
    "#     df[feat+'^3'] = df[feat]**3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate combinations of features\n",
    "y = df.dropna()[['FI Rate']]\n",
    "X = df.dropna()[continuous_features]\n",
    "interactions = list(combinations(X.columns, 2))\n",
    "interaction_dict = {}\n",
    "for interaction in interactions:\n",
    "    X_copy = X.copy()\n",
    "    X_copy['interact'] = X_copy[interaction[0]] * X_copy[interaction[1]] \n",
    "    X_copy = X_copy.replace([np.inf, -np.inf], 0)\n",
    "    model = LinearRegression() #run model with each possible interaction\n",
    "    model.fit(X_copy, y)\n",
    "    interaction_dict[model.score(X_copy, y)] = interaction # add R-squared for each interaction to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add best 60 interactions to model\n",
    "# top_interactions = sorted(interaction_dict.keys(), reverse = True)[:60]\n",
    "# for interaction in top_interactions:\n",
    "#     feature1 = interaction_dict[interaction][0]\n",
    "#     feature2 = interaction_dict[interaction][1]\n",
    "#     df[feature1+'_X_'+feature2] = df[feature1] * df[feature2] #also add to new_features df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feat in continuous_features:\n",
    "#     df['log_'+feat] = df[feat].map(lambda x: np.log(x))\n",
    "# df = df.replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dummy variables for high and low threshold programs\n",
    "# hi_thresh_dummies = pd.get_dummies(df['High Threshold Type'].astype(str), dtype=int)\n",
    "# hi_thresh_dummies['other'] = hi_thresh_dummies['Other Nutrition Program'] + hi_thresh_dummies['other nutrition pgm']\n",
    "# hi_thresh_dummies.drop(['Other Nutrition Program','other nutrition pgm','nan'],axis=1,inplace=True) # drop last col\n",
    "# hi_thresh_dummies.rename(columns = {'SNAP, Other Nutrition Programs': 'SNAP_other'}, inplace=True)\n",
    "# hi_thresh_dummies.columns = 'Hi_thresh_'+hi_thresh_dummies.columns\n",
    "\n",
    "# low_thresh_dummies = pd.get_dummies(df['Low Threshold Type'].astype(str), dtype=int)\n",
    "# low_thresh_dummies.drop('nan', axis=1,inplace=True)\n",
    "# low_thresh_dummies.rename(columns = {'SNAP, Other Nutrition Programs': 'SNAP_other'}, inplace=True)\n",
    "# low_thresh_dummies.columns = 'Lo_thresh_'+low_thresh_dummies.columns\n",
    "\n",
    "# df = pd.concat([df, low_thresh_dummies, hi_thresh_dummies],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the df with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickled/feature_engineered_data.pickle', \"wb\") as output_file:\n",
    "    pickle.dump(df, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
